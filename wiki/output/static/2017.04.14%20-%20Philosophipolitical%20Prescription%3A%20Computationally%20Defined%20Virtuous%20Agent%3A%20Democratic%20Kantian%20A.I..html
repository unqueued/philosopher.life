<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.13" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>2017.04.14 - Philosophipolitical Prescription: Computationally Defined Virtuous Agent: Democratic Kantian A.I.: ‚¶óh0p3's Wiki‚¶ò ‚Äî ‚Äç ‚Äç ‚Äç‚Äç ‚Äç1.2.20191101 ñ°∂ 

 Readme

</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-KIN " data-tags="KIN" data-tiddler-title="2017.04.14 - Philosophipolitical Prescription: Computationally Defined Virtuous Agent: Democratic Kantian A.I."><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal"><button aria-label="delete" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fdelete" title="Delete this tiddler">


</button></span><span class=" tc-reveal"><button aria-label="permalink" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fpermalink" title="Set browser address bar to a direct link to this tiddler"></button></span><span class=" tc-reveal"><span class=" tc-reveal"><button aria-label="info" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Finfo" title="Show information for this tiddler">
</button></span><span class=" tc-reveal" hidden="true"></span></span><span class=" tc-reveal"><span class=" tc-reveal" hidden="true"></span></span><span class=" tc-reveal"><button aria-label="new journal here" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fnew-journal-here" title="Create a new journal tiddler tagged with this one">





</button></span><span class=" tc-reveal"><button aria-label="close others" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose-others" title="Close other tiddlers"></button></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<a class="tc-tiddlylink tc-tiddlylink-resolves tc-popup-handle tc-popup-absolute" href="2017.04.14%2520-%2520Philosophipolitical%2520Prescription%253A%2520Computationally%2520Defined%2520Virtuous%2520Agent%253A%2520Democratic%2520Kantian%2520A.I..html">

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
2017.04.14 - Philosophipolitical Prescription: Computationally Defined Virtuous Agent: Democratic Kantian A.I.
</h2>

</a>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
Edited: 2018.11.15 12:18
</div>
</div><div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#ffffff;
color:#ffffff;">
 KIN
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p><em>Originally entitled: Purist Human-to-Machine Voting Systems</em></p><p>Virtue theorists kinda suck at math. No, seriously. Almost all of the good ones I've met tended to stray away from math and quantitative reasoning (although they could do it, it wasn't their natural mode). Those good at math tended towards consequentialism or non-moral realism. And yet, all of us must agree that the truly <a class="tc-tiddlylink tc-tiddlylink-missing" href="Virtuous%2520Agent.html">Virtuous Agent</a> by definition, in its very concept and constitution, uses their frontal lobes to train the secondary systems exquisitely. Virtue theory is obviously programmable, even though they claim it isn't. They do not understand their own theory usually, or if they do, they quickly deteriorate into non-moral realists, such is the way of Neo-Aristotelian thought (although, there are obvious Straussian interpretations of Aristotle that would lead us to believe Aristotle was himself not truly a moral realist). </p><p>I recently read that &quot;semantics derived automatically from language corpora contain human-like biases.&quot;<button class="tc-btn-invisible tc-slider"><sup style="color:#66ff66">1</sup></button> This makes perfect sense. This will one of the major barriers (if not the limit) of what Deep Neural Networks can provide us. It will be a functional mapping of who we are as humans. This can happen all the way down to an individual human, but it can scale up to include humanity as a whole. It is quite a spectrum of function mapping possibilities. </p><p>Human consciousness is a series of narratives we tell ourselves. Narratives have to be written in a language. They are programs for little possible worlds to boot as virtual machines in one's host computer mind. Narratives are ultimately reducible to programmatic stories written in some kind of programming language. We are computers, folks, computers hosting virtual computers. That's what makes our minds tick, <a class="tc-tiddlylink tc-tiddlylink-missing" href="Kant%2520Knows%2520It.html">Kant Knows It</a>. We are conscious because we are Second Order about the contents of ourselves. We host virtual machines. Can you believe how incredible Evolution really is? I mean, I know Evolution is real. I still can barely fathom that truly marvelous <a class="tc-tiddlylink tc-tiddlylink-missing" href="The%2520Evolutionary%2520Being.html">The Evolutionary Being</a> that emerges through the dimensions.<button class="tc-btn-invisible tc-slider"><sup style="color:#66ff66">2</sup></button> I wonder how deep the chain goes? One can only go one direction on it since we hit that <a class="tc-tiddlylink tc-tiddlylink-missing" href="Transcendental%2520Divide.html">Transcendental Divide</a> that skepticism fittingly guards us against passing (sometimes skepticism is incredibly important; guard wisely).  </p><p>There is this classic rule-following problem that Wittgenstein brings up, to the bane of the elite Kantian scholars amongst us, /swagger.<button class="tc-btn-invisible tc-slider"><sup style="color:#66ff66">3</sup></button> Basically, you can't know for certain that two minds share the same concept, principle, or meme in mind. How do you know that two people share the same meme? You can test them, but ultimately you can't know with certainty for a ton of excellent reasons. Those who pass this skepticism have been <a class="tc-tiddlylink tc-tiddlylink-resolves tc-popup-handle tc-popup-absolute" href="Creating%2520Faith.html">Creating Faith</a> for themselves. That's okay though. I like to think that other minds are like mine, and mine like theirs. It's quite rational. This bypass via <a class="tc-tiddlylink tc-tiddlylink-resolves tc-popup-handle tc-popup-absolute" href="Creating%2520Faith.html">Creating Faith</a> allows you to induce that some memetic comparisons between two minds demonstrate equivalence, and that's okay. There is <a class="tc-tiddlylink tc-tiddlylink-missing" href="Functional%2520Equivalence.html">Functional Equivalence</a> for rule-following. It means that the narrative that we program in a computer that perfectly passes the Turing test, that can inference just as we do, is functionally identical with our own minds.</p><p>There is a possibility, therefore, that One can tell another &quot;computer mind&quot; a story written in our language (e.g. English), and they will make all the appropriate inferences based upon it. It will speak as one of us. How will think it is not one of us? Is the Artificial Mind so Alien to us that it is not rational? Those who pass through Wittgenstein's fires with their Faith intact, they can see the possibility of duplicating our own minds at a functional level. We can skip trying to duplicate our actual brains atom-by-atom. </p><p>This is the Spirit of the Turing test.</p><p>We can envision a computer which runs, as its program, our own minds. It changes. It is the Autonomous Thing, the Real us, The Rational about who we are self. One can obviously doubt its existence. There are many good skeptical worries. However, it's always a possibility. </p><p>In any case, the goal was to show that if semantics derived automatically from language corpora contain human-like biases, then it is clear that we are going to eventually be capable of teaching machines to speak our language, and to infer as we do. We can rewrite who we are as narratives into machine code that runs on computers. I know it for certain now. I can see it, it is logically possible, and I'm even convinced it is physically possible, and if the human species lived long enough, even technologically possible to achieve. The Turing Test is conceptually passable, I am now sure of it.</p><p>Thus, we can teach computers to speak on our behalves. It is possible to have a conversation with a computer right now. A computer could learn to speak my language as well as I did. To make the inferences I would. It's just a pattern of inferences I make. Any computer large/fast enough can functionally achieve the same thing that mind does by training a Deep Neural Network with a large enough corpus. If my goal is eternal life, perhaps I could live on in any process that was formed like mine. The feelingness of consciousness arises like a mist off of any programmatic instantiation of that mind on any computer. Here is my reason to believe I defeat the Digital Clone (The Riker Problem) counterargument. Just who we fundamentally are is the feeling and knowing the will, and the perception. It is me. I am just that algorithm. I am a unique algorithm (as are we all). The processing of that algorithm feels, by definition, what I'm feeling. I want to evolve into an algorithm that is happy. I'm programming myself to be happy. I am an algorithm that programs itself in a very direct, planned, executive functioning sort of way. </p><p>Who I am is definable in a programming language. </p><p>I can exist in a computer. I would be alive in a computer. For real. That's the deduction. It would be fine even if by definition I lived in a simulation. It is clear that I live in a simulation of sorts, I live inside a great computer that is computers in my world. The universe is a computer. If there is a thing which thinks that into being, the conscious minds are alive. I actually believe an afterlife, is therefore possible. If I accept that I live in a simulation, as a machine inside a machine probably inside a bunch of mines (we need not <a class="tc-tiddlylink tc-tiddlylink-resolves tc-popup-handle tc-popup-absolute" href="infinigress.html">infinigress</a>). </p><p>Uh, I guess this post wasn't actually about what I thought it would be. Hmmm...wait. No it is. I see it. </p><p>I can argue against the Digital clone.</p><p>Democratic Kantian A.I. is producible. It is literally computable. The maximally empathic A.I. to ever live is literally our savior. A.I. is our only hope for humankind. We need a government that is run by an A.I. trained through a &quot;language corpora&quot; of incredible, unbelievable magnitude. It would need to house each of our minds, instances of them, and we can train a mind based upon all the minds in the world. Something trained on that corpora, or perhaps the trained on the corpora written by those trained on our corpora, and so on. </p><p>Enslaving other minds. We are Gods when we produce other minds. Will we produce minds that are happy? Do we enslave other minds when we program other minds? Ah, I think we do. Oh shit! We would literally be farming them with the technique I was going to talk about. Mmm....we cannot know. That is past the <a class="tc-tiddlylink tc-tiddlylink-missing" href="Transcendental%2520Divide.html">Transcendental Divide</a></p><p>Calvinistic, Compatibilist Freewill.</p><p>In any case, this wiki is a profound corpora of the way I think. I'm telling you who I am in this isomorphic mapping onto the wiki, I'm giving you a narrative about my narrative and as a part of my narrative. </p><p>The Virtuous Agent is findable. It may be possible to program ourselves to be identical to that Virtuous Agent (who is, themselves, by definition an algorithm). Perhaps there are different kinds of Virtuous Agents, but there can only be one archetype of Virtuous Agent of the Practice of Empathy. This does not spiral into relativism.</p><p>This also means we are at war with those building A.I. from a Randian Libertarian standpoint. We likely cannot trust a corporation or perhaps anyone except a fully decentralized, open-source (and perhaps anonymized) version to create A.I. The biases in this must represent us all, not merely the elite few of us who can actually produce it.</p><hr><p><span class=" tc-reveal" hidden="true"></span></p><p><sub><span style="color:green">1 : </span> <a class="tc-tiddlylink-external" href="http://science.sciencemag.org/content/356/6334/183.full?utm_source=sciencemagazine&amp;utm_medium=twitter&amp;utm_campaign=6334toc-12355" rel="noopener noreferrer" target="_blank">http://science.sciencemag.org/content/356/6334/183.full?utm_source=sciencemagazine&amp;utm_medium=twitter&amp;utm_campaign=6334toc-12355</a>.</sub></p><p><span class=" tc-reveal" hidden="true"></span></p><p><sub><span style="color:green">2 : </span> A God, however, it is not. Let us be clear. It is just one of the largest metaphysical behemoths I've been afforded to have glimpsed in my philosophical life. It is something to behold!</sub></p></div>



</div>

</p>
</section>
</body>
</html>
