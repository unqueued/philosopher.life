<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.13" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>2010.12.02 - Symbolic Logic Notes: â¦—h0p3's Wikiâ¦˜ â€” â€ â€ â€â€ â€1.2.20191101 ğ–¡¶ 

 Readme

</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-LSU " data-tags="LSU" data-tiddler-title="2010.12.02 - Symbolic Logic Notes"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal"><button aria-label="delete" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fdelete" title="Delete this tiddler">


</button></span><span class=" tc-reveal"><button aria-label="permalink" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fpermalink" title="Set browser address bar to a direct link to this tiddler"></button></span><span class=" tc-reveal"><span class=" tc-reveal"><button aria-label="info" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Finfo" title="Show information for this tiddler">
</button></span><span class=" tc-reveal" hidden="true"></span></span><span class=" tc-reveal"><span class=" tc-reveal" hidden="true"></span></span><span class=" tc-reveal"><button aria-label="new journal here" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fnew-journal-here" title="Create a new journal tiddler tagged with this one">





</button></span><span class=" tc-reveal"><button aria-label="close others" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose-others" title="Close other tiddlers"></button></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<a class="tc-tiddlylink tc-tiddlylink-resolves tc-popup-handle tc-popup-absolute" href="2010.12.02%2520-%2520Symbolic%2520Logic%2520Notes.html">

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
2010.12.02 - Symbolic Logic Notes
</h2>

</a>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
Edited: 2018.10.30 23:59
</div>
</div><div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#ffffff;
color:#ffffff;">
 LSU
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p>Notes â€“ August 31, 2010</p><p>Functionâ€™s bring about more complex constants or referring expressions.</p><p>father(me) = My father</p><p>mother(father(me)) = My fatherâ€™s mother = Mother of my Father</p><p>+(2,3) = 5</p><p>Both predicate and function symbols have Arity.</p><p>Infix notation is acceptable when it is conventional - e.g. 2+3 = 5</p><p>Term = intuitively, it is an expression that serves to pick out an individual object. I.e. a Referring expression.</p><p>Individual constants are part of the set of all Terms. Individual constants are simple terms.</p><p>There are two types of terms. 1.) Simple (individual constants), and 2.) Complex.</p><p>Complex terms are the results of function symbols applied to a term. Obviously, complexity ranges.</p><p>Father(gwb) is different from father(gwb). Note the difference in capitalization. Both are well-formed expressions in our formal language, but they are very different. The latter is a function, also a complex term. Its job is to refer. The former contains a predicate (and a subject); it is an atomic sentence. It has a truth value.</p><p>â€œA is a cubeâ€ can be written as Cube(a).</p><p>â€œC is between a and dâ€ can be written as Between(c, a, d). Choosing the order of terms matters, particularly as these are related in the sentence. When translating, try to stay as close as possible to the surface grammar that you are translating. So, while Between(c, d, a) is also true, Between(c, a, d) matches the original grammar better.</p><p>From 1.12:</p><p>Claireâ€™s father is taller than Maxâ€™s father.</p><p>John is Maxâ€™s father. (Apparently, better than â€œJohn is identical to Maxâ€™s fatherâ€)</p><p>Claire is taller than her maternal grandmother.</p><p>Maxâ€™s maternal grandmother is taller than his paternal grandmother.</p><p>Melanie and Claire have the same mother.</p><p>Argument = a collection of statements, one of which is called the conclusion. It is intended to follow from (be a consequence of) or be supported by the remaining statements. The remaining sentences are known as the premises.</p><p>There are signals in normal English for which argumentative sentences are which.</p><p>Conclusion: therefore, thus, hence, so</p><p>Premises: since, after all, because</p><p>All humans are Mortal. Socrates is human. So, Socrates is Mortal.</p><p>Lucretius is human. After all, all humans are mortal and Lucretius is mortal.</p><p>Fitch format down below. Note the â€œfitch barâ€ which separates the premises from the conclusion.</p><p>| All humans are mortal.</p><p>| Socrates is human.</p><p>|â€”</p><p>| Socrates is mortal.</p><p>| All humans are mortal.</p><p>| Lucretius is mortal.</p><p>|â€”</p><p>| Lucretius is human.</p><p>(Obviously, 2 isnâ€™t valid)</p><p>An argument is logically (aka, deductively) valid iff (if and only if) its conclusion must be true if its premises are true. Thus, it is also impossible for the premises to be true and the conclusion false.</p><p>The conclusion of a logically valid argument is said to be a logical consequence of the argumentâ€™s premises.</p><p>Logical consequence and Logical validity are brothers.</p><p>Modal logics have to do with possibility and necessity. You must think about whether or not it is possible for the premises to be true and the conclusion false, independent of the actual truth or falsity.</p><p>Actual worlds and possible worlds (possible truth values).</p><p>George Bush is President and Hillary Clinton is Secretary of State. Therefore, Hillary Rodham Clinton is Secretary of State.</p><p>If you suppose the premise is true, then the conclusion MUST be true. This is logically valid. Notice that the premise is actually false, but the conclusion is true.</p><p>All humans are mortal. Obama is human. Therefore, Obama is mortal.</p><p>Valid. Actual truth values: true as well.</p><p>All humans are mortal. Obama is immortals. Therefore Obama is not human.</p><p>Valid. 1 premise and 1 conclusion is actually false though.</p><p>Logical validity and actual truth values do not track each other.</p><p>Moving from actually true premises to an actually false conclusion is time where â€œtrackingâ€ can show the invalidity of an argument.</p><p>An argument is â€œsoundâ€ iff both 1.) it is logically valid and 2.) its premises are all true.</p><p>True in, true out = Truth preservation.</p><p>Soundness is practical.</p><p>Notes â€“ September 2, 2010</p><p>A proof is a step by step demonstration that one statement (say S) is a logical consequence of some statements (say p1,â€¦.,pn).</p><p>Note that individual statements can easily prove themselves.</p><p>Formal Proofs must be in a formal language using explicitly specified rules.</p><p>Informal Proofs do not necessarily need explicitly specified rules and methods. Linguistic competence (syllogistic logic) is much like it.</p><p>Formal and informal only differ in style only, but donâ€™t differ in rigor. Rigor, meaning, each step of the proof follows from previous steps by/of necessity. It is part of truth preservation. Start with true stuff necessarily ends up with true stuff.</p><p>Cube(b)</p><p>c = b</p><p>â€“</p><p>Cube(c)</p><p>[Spâ€™ = suppose (or assume)]</p><p>Spâ€™ Cube(b) and c=b.</p><p>We need to show Cube(c)</p><p>Informal proof:</p><p>Since c=b, c and b have exactly the same properties (are identical) , but b is a cube (i.e. Cube(b)), and since being a cube is a type of property, (so) c is also a cube (Cube(c)).</p><p>Formal proof (fitch style):</p><p>Cube(c)</p><p>c=b</p><p>â€“</p><p>3. Cube(b) = Elim: 1,2</p><p>Indiscernability of identicals (Leibniz principle):</p><p>If a=b, then a and b have exactly the same properties.</p><p>Things which are identical are indiscernible (you canâ€™t tell them apart). They are the same thing.</p><p>This is basis of the identity elimination rule in our formal language.</p><p>Identify is reflexive. Everything is self-identical. a=a</p><p>This principle underwrites the â€œidentity introductionâ€ (Id intro) rule.</p><p>Identity is symmetric and transitive.</p><p>Symmetry: for all a and b, if a=b, then b=a</p><p>Transitivity: for all a,b, and c; if a=b, and b=c, then a=c</p><p>Informal argument for symmetry:</p><p>Let a and b be arbitrary. Spâ€™ a=b. Show: b=a</p><p>By reflexivity of = (identity), we have a=a. But, by the indiscernibility of identicals, a and b have exactly the same properties. So, it follows that b=a.</p><p>In our block-language, SameSize is reflexive, symmetrical, and transitive.</p><p>Every block is the same size as itself, if you have two blocks of the same size, then they are symmetrical, and if you have a,b,c with Same Size between any 2 sets of these, then all 3 are transitively the same size.</p><p>If you have Reflexitivity, Symmetry, and Transivity, then you have an Equivalence (of relation in these cases).</p><p>Inverses: consider Larger and Smaller. Example of an inverse relationship:</p><p>Larger(a,b) iff Smaller(b,a)</p><p>Deductive systems are necessary for presenting formal proofs.</p><p>We will be using â€œscriptâ€ â€œFâ€. This is a Fitch style deductive system. (Hence, the â€œFâ€)</p><p>| 1. P1</p><p>| 2. P2</p><p>| .</p><p>| .</p><p>| n. Pn</p><p>|â€“</p><p>| n+1. S1	(justification for n+1)</p><p>| n+2. S2 (justification for n+2)</p><p>| .</p><p>| .</p><p>| n+k. Sk</p><p>| n+k+1. S</p><p>Justification shows the legitimacy of writing down the line; the application of the rules.</p><p>n+1 and n+2 are intermediate conclusions. They bridge the gap between what you are given as premises and what you are trying to prove in the end.</p><p>Rules of Script F:</p><p>Identity Introduction or abbrev. (=Intro)</p><p>| k. n=n</p><p>Where n is any term.</p><p>At any point in the argument overall, you may assert the above.</p><p>Identity Elimination or (= Elim)</p><p>| k. P(n)</p><p>| l. n=m</p><p>| q. P(m) = Elim: k, l</p><p>P(n): any sentence in which the term n appears.</p><p>Order matters.</p><p>Replace occurrences of n in P(n) with m â€“ the proof isnâ€™t the other way around</p><p>P(n) is the property statement</p><p>State the property statement first in â€œ= Elim: k, lâ€ assuming â€œkâ€ is the property statement.</p><p>Reiteration Rule or (Reit)</p><p>| k. p</p><p>| .</p><p>| l. p Reit: k</p><p>| 1. a = b (b = a, symmetry of identity)</p><p>|â€“</p><p>| 2. a=a (ïƒŸProperty statement) =Intro</p><p>| 3. b=a =Elim: 2, 1</p><p>| 1. SameRow(a,a) (show SameRow(b,a))</p><p>| 2. b=a (canâ€™t replace any â€˜bâ€™ with â€˜aâ€™ because no bâ€™s here)</p><p>|â€“</p><p>| 3. b=b =Intro</p><p>| 4. a=b =Elim: 3, 2</p><p>| 5. SameRow(b, a) =Elim: 1, 4</p><p>Property statements are the statement in which are replacing occurences.</p><p>Notes â€“ September 7, 2010</p><p>Nonconsequence (canâ€™t always prove this).</p><p>To prove S is no a consequence of P1â€¦Pn:</p><p>Show itâ€™s possible for the Pâ€™s to all be true and S to be false. You can do this by showing a counterexample.</p><p>A counterexample is a possible situation/circumstances/world in which P1â€¦Pn are all true and S is False.</p><p>| Joe Biden a politician. T</p><p>| Few politicians are honest. T</p><p>|â€“</p><p>| Biden is not honest. F</p><p>Let the world be such that Biden is a politician, and Few politicians are honest, and Biden among the honest politicians. (This is the specification, later weâ€™ll need to do verification.)</p><p>2.13 on pg 53.</p><p>| SameSize(a, b)</p><p>| Larger(a, c) ïƒ  Smaller(c, a)</p><p>| Smaller(d, c)</p><p>|â€“</p><p>| Smaller(d, b)</p><p>Spâ€™ â€˜aâ€™ and â€˜bâ€™ are the same size, â€˜aâ€™ is larger than â€˜câ€™, and â€˜dâ€™ is smaller than â€˜câ€™. Show: â€˜dâ€™ is smaller than â€˜bâ€™.</p><p>Since â€˜aâ€™ is larger than â€˜câ€™, â€˜câ€™ is smaller than â€˜aâ€™.</p><p>So, by transitivity of â€˜Smaller thanâ€™, â€˜dâ€™ is smaller than â€˜aâ€™.</p><p>But, â€˜aâ€™ and â€˜bâ€™are the same size, hence â€˜dâ€™ is smaller than â€˜bâ€™.</p><p>Boolean Connectives/Operators:</p><p>Negation Â¬</p><p>It is not the case thatâ€¦</p><p>Not or un-</p><p>Youâ€™ll always want to know a languageâ€™s syntax and semantics. Syntax is how a symbol works with language you already have to form new expressions. Syntax is grammar. Semantics asks, under what conditions is using that new piece of language true or false?</p><p>Syntax for Â¬:</p><p>If p is a sentence, then so is Â¬p.</p><p>Semantics for Â¬: Â¬P is true iff P is not true. P is false.</p><p>P | Â¬P</p><p>-â€” -â€”</p><p>T | F</p><p>F | T</p><p>Truth functional connectives.</p><p>A â€˜literalâ€™ is a sentence which is either atomic or negated atomic.</p><p>Conjunction ^ (or &amp;, but not in this class) or âˆ§</p><p>And, but, moreover</p><p>Bob and Jim are tall.</p><p>Tall(bob) âˆ§ Tall(jim)</p><p>â€˜Tall(bob)â€™ is a conjunct (same for â€˜Tall(jim)â€™).</p><p>Same rested and listened to music.</p><p>Rested(sam) âˆ§ Music(sam)</p><p>Jill is a tall woman.</p><p>Tall(jill) âˆ§ Woman(jill)</p><p>Not every use of â€œandâ€ is the conjunction.</p><p>Same brushed his teeth and (then) went to bed. â€œandâ€ has a temporal meaning beyond mere truth functional conjunction.</p><p>The truth functional conjunction, you should be able to flip the order of the conjuncts and arrive at the same meaning.</p><p>Syntax for âˆ§: If P and Q are sentences, then so it Pâˆ§Q</p><p>Semantics for âˆ§: Pâˆ§Q is true iff both P is true and Q is true.</p><p>P Q | Pâˆ§Q</p><p>-â€” -â€” -â€”</p><p>T T | T</p><p>T F | F</p><p>F T | F</p><p>F F | F</p><p>Notes â€“ September 9, 2010</p><p>Disjunction - âˆ¨ - or</p><p>Bob or Kim is Married.</p><p>Married(bob) âˆ¨ Married(kim)</p><p>Inclusive or</p><p>One or the other or both</p><p>Disjuncts are joined by a Disjunction to make a Disjunctive sentence</p><p>Bob may have either soup or salad with his meal.</p><p>(Soup(bob) v Salad(bob)) ^ ~(Soup(bob) v Salad(bob))</p><p>If P and Q are sentences, then so is P v Q.</p><p>Sentences for âˆ¨: P v Q is true iff at least one of P, Q is true.</p><p>P Q | P v Q</p><p>â€” â€” â€” â€”</p><p>T T | T</p><p>T F | T</p><p>F T | T</p><p>F F | F</p><p>Grouping â€“ â€œgroupersâ€</p><p>(), [], {}</p><p>Ted is dead and Bob is tall or Kim is home.</p><p>Dead(ted) ^ (Tall(bob) v Home(kim))</p><p>(Dead(ted) ^ Tall(bob)) v Home(kim)</p><p>Dead(ted) ^ Tall(bob) ^ Home(kim) ïƒŸ Doesnâ€™t need groupers</p><p>Dead(ted) v Tall(bob) v Home(kim) ïƒŸ Doesnâ€™t need groupers</p><p>Bob kicked the ball.</p><p>The ball was kicked by Bob.</p><p>These sentences are logically equivalent. They are logically equivalent if they necessarily have the same truth value.</p><p>(DN) â€“ Double Negation - <strike>P &lt;==&gt; P

(DM^) - Demorganâ€™s Law of conjunction - ~(P ^ Q) &lt;==&gt; ~P v ~Q

(DMv) â€“ Demorganâ€™s Law of Disjunction - ~(P v Q) &lt;==&gt; ~P ^ ~Q



Good translation preserves meaning. It must match as closely as possible. Meaning of a statement are its truth conditions. Truth conditions are the circumstances under which the statement is true. You are looking for logical equivalence between that which is translated and the translation.

A translation of a sentence S1 into a sentence S2 is correct if S1 and S2 have the same truth conditions.

Any possible situation (not just one or some) in which one is true the other is true as well. (Logically equivalent)



Stylistic considerations:

    Match the surface syntax as closely as possible.

    Maximize naturalness (even colloquial)



    Not either/Neither, Nor ~(P v Q)

    Either not ~P v ~Q

    Not both ~(P ^ Q)

    Both not ~P ^ ~Q

1 and 4 are equivalent; 2 and 3 are equivalent.



    Neither e nor a is to the right of and to the left of b.

~((Rightof(e, c) ^ Leftof(e, b)) v (Rightof(a, c) ^ Leftof(a, b))

    Either a is small or both c and d are large.

Small(a) v (Large(c) ^ Large(d))



Notes â€“ September 14, 2010

Either the President supports campaign reform and the House adopts universal health care or the Senate approves missile defense.

(S(a)^A(b))vM(c)

Not both Hertz and Avis rent limousines.

~(R(h)^R(a)) ïƒ  Demorganâ€™s, ~R(h) v ~R(a)

Both hertz and Avis do not rent limousines.
~R(h)^~R(a)



Either Motrin or Advil cures headaches.

C(m)vC(a)



Not either Mylanta or Pepcid cures headaches.

~(C(m)v(C(p))



Neither Mylanta nor Pepcid cures headaches.

~(C(m)v(C(p))



Either Mylanta or Pepcid does not cure headaches.

~C(m) v ~C(p)



~, ^, v - these are truth-functional connectives. The truth values of the atomics of a sentence containing Boolean connectives define the truth value of those connectives.

It is necessarily the case that (or, â€œit is necessaryâ€) â€“ modal operators. Beyond truth value of the sentence in the actual world, but even possible worlds. This isnâ€™t a truth-functional connective. The word â€œbecauseâ€, likewise, isnâ€™t a truth-functional connective because it depends on more than the current truth values of the atomics in the sentence using the word â€œbecauseâ€.



Logical Statuses (Stati?, Stats?):

Logical consequence

Logical truth

Logical equivalence



Truth Tables help define the Statuses?

A sentence S is a logical truth iff it is logically impossible for S to be false. Aka. Necessary Truth (and Logically necessary truth).

A = A

Tet(a) v ~Tet(a)



Physical Possibility: doesnâ€™t violate physical law

TW Possibility (Tarski World Possibility) ïƒŸspecific to our book: can be built within the Tarski block world.

Facts:

    Every TW-possible sentence is logically possible.

    Some logically possible sentences are not TW-possible.

        ~(Tet(b) v Dedec(b) v Cube(b)) (e.g. canâ€™t make a sphere)



Truth Table for a Sentence: A truth table for a sentence P is an arrangement of truth values that shows the truth value of P in every possible situation as determined by the truth values of the atomic sentences occurring in P.

Main Connective: The main connective of a non-atomic sentence is that connective such that no other connective operates on a larger (i.e., more complex) part of the sentence than it does.

S, Q are true; R is False



(S ^ ~Q) v </strike>R</p><p>T T F</p><p>F T .</p><p>F .</p><p>F .</p><p>F .</p><p>Put in values for atomics, Rotate between negations and connectives until you reach the main connective. The main connectiveâ€™s truth value will tell you the full Truth Value of the sentence.</p><p>If there are n different atomic sentences occurring in P, then the truth table for P will have 2Â­n rows.</p><p>S Q R || (S ^ ~Q) v <strike>R

T T T || F F T T F

T T F || F F F F T

T F T || T T T T F

T F F || T T T F T

F T T || F F T T F

F T F || F F F F T

F F T || F T T T F

F F F || F T F F T





Notes â€“ September 16, 2010



Tet(b) || Tet(b) v ~Tet(b)

T || T F

F || T T



This is a tautology. Logical truth which can be shown via truth table (some logical truths canâ€™t be demonstrated this way).



A: Cube(a)

B: Cube(b)

C: Cube(c)



A B C || (A ^ B) v ~C

T T T || T F

T T F || T T

T F T || F F F

T F F || F T

F T T || F F F

F T F || F T

F F T || F F F

F F F || F T



Contingent sentence because the truth values of atomics matter to which world we are in.



Tet(b) || ~[Tet(b) v ~Tet(b)]

T || F T F

F || F T T





Something which is false is every situation is necessarily false or contradiction.

Every logically necessary sentence is TW-Necessary.



Convention for truth tables on chained â€œorâ€ or â€œandâ€ is to group from the left

(((A ^ B) ^ C) ^ D) ^ E



Every tautology is logically necessary.

Some logical necessities are not tautologies.



Truth tables are insensitive to â€œlargerâ€ or Identity statements. They canâ€™t show all logically necessary statements because of this, only tautologies.



TT=Truth Table



A sentence S is TT-possible iff S is true on at least one row of its truth table.



TT-Possible is â€œconsistentâ€ or internally consistent, but this is only a subspecies of â€œconsistenciesâ€

TT-Necessary = Tautology

TT-Impossible=Contradiction



Joint truth table: a truth table built for more than one sentence.



A B || ~(A ^ B) | ~A v ~B

T T || F T | F F F

T F || T F | F T T

F T || T F | T T F

F F || T F | T T T



Compare the truth values of each sub-table.



The above table shows that both sentences are tautologically equivalent because they agree (have the same truth value) on every row under the main connective in their truth table.

Tautological equivalence is a subspecies of logical equivalence.



Truth tables tell you about the meanings of truth-functional connectives, which is why we can see proofs of tautology in TTs.



Every Tautological equivalent pair of sentences is logically equivalent.

Some logically equivalent pairs are not tautologically equivalent pairs.



S is a logical truth iff S is a logical consequence of any set of sentences.

S and Sâ€™ are logically equivalent iff S is a logical consequence of Sâ€™ and vice versa.



TT give us a way to define the notion of tautological consequence.

S is a tautological consequence of P1â€¦Pn iff the joint truth table for S and P1â€¦Pn has no row where each of the Pâ€™s is true and S is false.



Tautological consequence is a subspecies of logical consequence.



Tautology = Truth Table = Truth-functional connectives relationships are fully understood/described



Tautological consequence, equivalence, and truth relate to each other in the same that way Logical consequence, equivalence, and truth relate to themselves.



Tautological consequence relates to logical consequence in the same way that Tautological equivalence relates to logical equivalence in the same way that Tautological truth relates to logical truth.





Notes â€“ September 21



Any instance of tautological consequence is an instance of logical consequence.



Some instances of logical consequences are not instances of tautological consequence. E.g. a=b &amp; b=c, therefore a=c. This is a logical consequence, but not tautological consequence because tautological consequence can be captured in truth tables and can only use truth-connectives. Some logical consequence use non-truth-connectives.



S is a tautology iff S is a tautological consequence of any set of premises.



S and Sâ€™ are tautologically equivalent iff S and Sâ€™ are tautological consequences of each other.



Chapter 5



An inference step is a move from one or more sentences to a sentence in a process or pattern of reasoning. E.g. P ^ Q -&gt; P



Valid inference step just in case it is truth preserving. If the sentences you start from in the inference step, then so must the sentence you step to (the outcome of that inference step). Truth in, truth out; Truth preserving.



3 Simple valid inference steps:



    From a conjunction of any number of sentences, one may infer any one of the conjuncts.

From P1 ^ P2 ^ Pn, infer Pi (where â€˜iâ€™ is between 1 and â€˜nâ€™)

Conjunction Elim rule (^ Elim)

    From any number of sentences, one may infer the conjunction of these sentences.

From truth of all of P1, P2, Pn -&gt; infer P1 ^ P2 ^ Pn

Conjunction intro rule (^ Intro)

    From any sentence, one may infer a disjunction of any number of sentences containing that sentence as a disjunct.

From P, infer P v Q, P v Z, P v Q v Z v S

Disjunction intro rule (v Intro)



Every step of a proof (formal or informal) should be easily understandable and significant.

Easily understood -&gt; Easy to see the step is valid. Obviously, this is audience sensitive.

Significance must move the proof forward (metaphorically speaking).



Proof by Cases.

(Cube(c) ^ Small(c)) v (Tet(c) ^ Small(c))

â€“

Small(c)



p.f.. Spâ€™ (Cube(c) ^ Small(c)) v (Tet(c) ^ Small(c))

Show: Small(c)

There are two cases to consider.



Case 1 â€“ Cube(c) ^ Small(c) -&gt; Small(c)

Case 2 â€“ Tet(c) ^ Small(c) -&gt; Small(c)

This exhausts the possibilities. So, Small(c)



Proof by Cases: To prove S from P1 v P2 v Pn: Show that S is a consequence of each Pi (where â€˜iâ€™ is between 1 and â€˜nâ€™)

Proof by Cases is specific to disjunctions. Proof by cases underwrites disjunction elimination (v Elim)



Notes â€“ September 23, 2010

To prove S from P1 v P2 v Pn, prove S from each Pi

Indirect proof/proof by contradiction/ reduction ad absurdum

To prove ~S from sentence P1...Pn, assume S and derive a contradiction.

Contradiction = a sentence which is necessarily false.

P1 T

. T

Pn T

S ?

â€“

X F

Thus, S must necessarily be false. We know which one to blame, since the Pâ€™s are already taken to be true in this study, only S is left, and it must be False. QED, ~S is true!

Contradiction must be necessarily false from these.



Show: B != C follows from Cube(c) v Dodec(c), and Tet(b).

Assume:

Cube(c) v Dodec(c)

Tet(b)

Assume for reductio that b = c. (I,e, ~[b!=c])

Since Cube(c) v Dodec(c), there are two cases to consider.

Case 1: Cube(c) ïƒ  Then we have Cube(c) and Tet(b). But, since b=c, we have a Tet(c). It is impossible for Cube(c) and Tet(c) to be true at the same time.

Case 2: Dodec(c) ïƒ  Then we have Dodec(c) and Tet(b). But, since b=c, we have Tet(c). It is impossible for Dodec(c) and Tet(c) to be true at the same time.

Since this exhausts the cases, the premises plus b=c lead to impossibility. So, b!=c

This is an inconsistent set.

âŠ¥: Absurd, Surd, bottom, falsity, the false, contradiction

Fact: S is a contradiction iff ~S is a logical truth



Chapter 6

We are expanding F in this chapter.



Conjunction elimination - ^ Elim

|k. P1 ^ Pi ^ Pn

|.

ïƒ  |n. P1 ^Elim: k



Conjunction introduction â€“ v Intro

|k. P1

|.

|km. Pm

ïƒ |n. P1 ^ P2^â€¦^Pm ^Intro: k., k2â€¦km

The references for ^Intro need to match the order in which you put the conjuncts.



Examples:

|1. A ^ B ^ C Prove: C^B

â€“

|2. B ^Elim: 1

|3. C ^Elim:1

|4. C^B ^Intro: 3, 2



Beware of groupers, you may need to remove them to avoid ambiguity.

Example:

|1. A v B

|2. C

|â€“

|3. (A v B) ^ C ^Intro: 1, 2



Disjunction Introduction â€“ v Intro

|k. Pi

|.

ïƒ |n. P1 vâ€¦v Pi vâ€¦ v Pn	v Intro: k



Disjunction Elimination â€“ v Elim

Subproof: A proof that occurs inside a larger proof



|1. (A ^ B) v (C ^ D)	Show: B v D

| |2. A^B

| |3. B ^ Elim:2

| |4. B v D v Intro:3

| |5. C ^ D

| |6. D ^ Elim: 5

| |7. B v D v Intro: 6

|8. B v D v Elim:1, 2-4, 5-7

Notes â€“ September 28

Negation Elimination - ~Elim

|k. </strike>P</p><p>|.</p><p>|n. P ~Elim: k</p><p>Negation Introduction - ~Intro</p><p>| |k. P</p><p>| |.</p><p>| |n. âŠ¥</p><p>| n+1. ~P ~Intro: k-n</p><p>Surd Introduction - âŠ¥ Intro</p><p>|k. P</p><p>| .</p><p>| l. ~P</p><p>| .</p><p>|n. âŠ¥	âŠ¥ Intro: k, l</p><p>Non-negated line goes first.</p><p>Surd Elimination - âŠ¥ Elim</p><p>|k. âŠ¥</p><p>| .</p><p>| n. P âŠ¥ Elim: k</p><p>Where P is ANY sentence of the language. This is similar to a Counterfactual.</p><p>Proof Strategies:</p><p>Try an informal proof</p><p>Think about what the sentences actually mean</p><p>Work backwards by identifying the middle/intermediate goals.</p><p>You should (not can) only start a subproof when you know what rules you wish to employ and what you intend the last line of that proof to look like.</p><p>|~P v ~Q</p><p>|â€“</p><p>| ~(P ^ Q)</p><p>Spâ€™ ~P v ~Q. Show: ~(P ^ Q)</p><p>Assume for reduction: P^ Q. Then both P and Q are true. Now consider either two cases:</p><p>Case 1: <strike>P holds. Then P and ~P ïƒ ïƒŸ

Case 2: ~Q holds. Then Q and ~Q ïƒ ïƒŸ



Notes â€“ September 30, 2010

| Dodec(e)

| Small(e)

| ~Dodec(e) v Dodec(f) v Small(e)

|â€“

| Dodec(f)

Not deductively valid, where is the counterexample?

Consider a world in which e is a small dodec and f is a cube.

The First premise is true in this world, since e is a dodec.

The Second premise is also true in this world, since e is small.

The Third premise is true in this world, since e is small and Small(e) is one of the disjuncts of this premise.

But, the conclusion is false in this world because f is not a dodec.



Notes â€“ October 5, 2010

    De Es

    Trans

    TT

    Proofs/Counterexample



Material Condition - â†’

If P, then Q

P only if Q

Q if P

Q if only P

Q provided that P

P is sufficient for Q

Q is necessary for P

The above are written as: P ïƒ  Q



Syntax for ïƒ 

If P and Q are sentences, then so is Pïƒ Q

This is called a conditional.

Within a conditional, such as P ïƒ  Q, P is the antecedent and Q is the consequent.



Semantics for ïƒ 

P ïƒ  Q is true if either P is false or Q is true.

P Q | P ïƒ  Q

T T | T

T F | F

F T | T

F F | T



Notice how the only time P ïƒ  Q is false is when P is true and Q is false. False P will always make P ïƒ  Q true.



If Max had been at home, then Carl would have been there too. (This isnâ€™t a material condition because the antecedent is false, and the entire conditional is false, which is not possible according to the truth table for material conditional).

Indicative mood and subjunctive mood will demonstrate which English sentences are material conditionals and which arenâ€™t.



P unless Q â€“ this is written as - ~Q ïƒ  P

Ted will die unless Bob helps him.

If Bob doesnâ€™t help him, Ted will die.

~Helps(bob, ted) ïƒ  Dies(ted)



Corresponding Conditional (Associated conditional)

With any argument, you can write a conditional which corresponds to it.

|P1

|P2

|.

|Pn

|-

| C

(P1 ^ P2 ^ â€¦ ^ Pn) ïƒ  C



An argument is deductively valid iff its corresponding conditional is a logical truth.



Material Biconditional - â†”

P iff Q

P just in case Q

P is necessary and sufficient for Q

P â†” Q

P and Q are logically equivalent iff P â†” Q is a logical truth.



Syntax for â†”

If P and Q are sentences, then so is P â†” Q



Semantics for â†”

P â†” Q is true iff the truth values of P and Q match



P Q | P â†” Q

T T | T

T F | F

F T | F

F F | T

Where they match, obviously, the biconditional is true. Where they donâ€™t have matching truth values, this statement is false. Material biconditionals have the same truth values and are logically equivalent.



P â†” Q is logically equivalent to (P ïƒ  Q) ^ (Q ïƒ  P)



Conversational implicatur

(from Paul Grice)

Sometimes you communicate things in a sentence which arenâ€™t a part of its truth conditions.

â€œJoeâ€™s great, heâ€™s never drunk on Thursdays.â€ This implies heâ€™s drunk the rest of the time.

It is conversationally implied, but not logically implied.

This should be kept in mind when translating natural language into formal language.

Any part of what is communicated by a speaker in asserting S that can be canceled out by the speakerâ€™s elaborating on what she without contradicting herself is an implicature of S and not part of Sâ€™s truth conditions.

Notes â€“ October 12, 2010

Proofs with ïƒ  and ïƒŸïƒ 

Informal methods:

From: If P, then Q; and P, we may infer Q.

From Pïƒ Q, P infer Q

Modus ponens.

Conditional Elimination



From P and either P iff Q or Q iff P, one may infer Q.

P ïƒŸïƒ Q

P

Infer

Q

Biconditional Elimination



Equivalences of Note:

P ïƒŸïƒ  </strike>P</p><p>(P ïƒ  Q) ïƒŸïƒ  (~Q ïƒ  ~P)</p><p>(P ïƒ  Q) ïƒŸïƒ  (~P | Q)</p><p>~(P ïƒ  Q) ïƒŸïƒ  (P &amp; Q)</p><p>~(P ïƒ  Q) ïƒŸïƒ  (P &amp; ~Q)</p><p>(P ïƒŸïƒ  Q) ïƒŸïƒ  [(P ïƒ  Q) &amp; (Q ïƒ  P)]</p><p>(P ïƒŸïƒ  Q) ïƒŸïƒ  [(P &amp; Q) | (~P &amp; ~Q)]</p><p>Conditional Proof</p><p>To prove a conditional, say P ïƒ  Q: Assume P and derive (or prove) Q.</p><p>Requires proof by cases.</p><p>Biconditional Proof</p><p>To prove a biconditional P ïƒŸïƒ  Q: Prove Pïƒ Q and Qïƒ P</p><p>Rules for F</p><p>Conditional Rulesâ€”</p><p>Conditional Elimination ( ïƒ  Elim)</p><p>|k. Pïƒ Q</p><p>|.</p><p>|l. P</p><p>|.</p><p>|n. Q ïƒ Elim: k, l</p><p>Conditional Introduction ( ïƒ  Intro)</p><p>| |k. P</p><p>| | .</p><p>| |n. Q</p><p>|n+1. Pïƒ Q ïƒ Intro: k-n</p><p>Biconditional Rules</p><p>Biconditional Elimination (ïƒŸïƒ  Elim)</p><p>|k. P ïƒŸïƒ  Q</p><p>|.</p><p>|l. P</p><p>|.</p><p>|n. Q ïƒŸïƒ : k, l</p><p>Biconditional introduction (ïƒŸïƒ  Intro)</p><p>| |k. P</p><p>| |.</p><p>| |l. Q</p><p>| |i. Q</p><p>| |.</p><p>| |j. P</p><p>|j+1. P ïƒŸïƒ  Q ïƒŸïƒ  Intro: k-l, i-j</p><p>That which can be proven with no starting premises is a logical truth.</p><p>Notes â€“ October 14</p><p>When stuck, use negation introduction.</p><p>|~Q</p><p>| surd</p><p>\</p><p>Notes â€“ October 19</p><p>Chapter 9</p><p>Quantificational logic â€“ Quantifiers</p><p>~, |, &amp;, ïƒ , ïƒŸïƒ  are our logical connectives. (Truth functional connectives)</p><p>Once you introduce quantifiers, you leave truth functional connectives behind. They still exist in their own realm, but quantifies are non-truth functional.</p><p>Basic Sentences</p><p>Noun phrase + verb phrase</p><p>Ted is dead. (â€œTedâ€ is the noun phrase) (â€œis deadâ€ is the verb phrase)</p><p>Every person Ted knows is alive. (â€œEvery person Ted knowsâ€ is the noun phrase) (â€œis aliveâ€ is the verb phrase)</p><p>Sentence (1) can be handled in truth-functional logic â€“ Dead(ted)</p><p>Sentence(2), however, canâ€™t be handled by truth functional logic. The noun phrase is the problem. Specifically, â€œEvery personâ€ canâ€™t be captured within truth functional logic. â€œEveryâ€ is a determiner. â€œPersonâ€ is a common noun. â€œEvery personâ€ is a quantifier expression.</p><p>Example Determiners:</p><p>All, some, every, each, most, at least then</p><p>Determiner + common noun = quantifier expression</p><p>â€˜Everyâ€™ + â€˜personâ€™ = â€˜Every personâ€™</p><p>E.g. â€“ â€˜Some dogsâ€™, â€˜Each childâ€™, â€˜All catsâ€™, â€˜Most cellistsâ€™, â€˜At least ten studentsâ€™</p><p>The quantity of the particular circumstance helps to determine the truth value of a quantified expression.</p><p>Quantifiers arenâ€™t truth functional, clearly. The quantity of something is not a truth value or facts about truth conditions?</p><p>We will use 2 quantifiers for now:</p><p>Universal Quantifier - âˆ€ - Every, each, for all, all, everything</p><p>Existential Quantifier - âˆƒ - Some, there exists, exists, at least one, something</p><p>Logical - =, ~, |, &amp;, ïƒ , ïƒŸïƒ , âˆ€, âˆƒ; (Individual variables) t, u, v, w, x, y, z (with or without subscripts)</p><p>Non-logical â€“ predicate symbols, function symbols, individual constants</p><p>Variables, like individual constants, are lower case letters. A-F constants, T-Z variables. They arenâ€™t the same though.</p><p>Large(a), Smaller(b, c), father(george) â€“ where individual constants can occur.</p><p>Syntactically, variables work just like constants. Anywhere one can appear, so can the other.</p><p>Large(x), father(y,) â€“ variables</p><p>So, they are syntactically identical. Semantically, they are very different.</p><p>The semantic role of an individual constant â€“ it picks out an individual thing.</p><p>Variables, however, donâ€™t pick out anything.</p><p>Large(a) has a truth value. Large(x) doesnâ€™t because x doesnâ€™t pick anything out.</p><p>father(george) picks someone out (it is a referring expression), father(x) doesnâ€™t pick anyone out. We donâ€™t know who x is.</p><p>Large(x) is not a sentence. Large(a) is a sentence.</p><p>Up until now, we had defined term has something which picks out. This is no longer true now that we have variables. We need to think of terms syntactically now.</p><p>Variables are simple terms (like individual constants). Complex terms, of course, are the results of function symbols applied to terms.</p><p>Atomic wff: an n-ary predicate symbol followed by n terms enclosed in parentheses and separated by commas (if necessary).</p><p>Wff: well-formed formula.</p><p>Wffâ€™s are very much like sentences; syntactically, they look like sentences, except a wff can have a free variable (in which case it doesnâ€™t actually say anything).</p><p>All atomic sentences are atomic wffs, but not the other way around. Atomic sentences are atomic wffs with no free variables. Let us call those atomic wffs with free variables, â€œmere wffsâ€.</p><p>Home(x)</p><p>Between(x, y, george)</p><p>5 = sum(u, 3)</p><p>You can take any atomic wff and operate on them with truth functional connectives, and the result will be a wff.</p><p>~Home(x) is a wff.</p><p>Home(x) &amp; (5=sum(u, 3)) is a wff (it isnâ€™t an atomic wff).</p><p>Wff â€“</p><p>All atomic wffs are wffs.</p><p>If P is a wff, so is ~P</p><p>If P and Q are wffs, then so are:</p><p>(Pïƒ Q)</p><p>(PïƒŸïƒ Q)</p><p>If P1, P2,â€¦,Pn are wffs, then so are:</p><p>(P1 &amp; P2 &amp;â€¦&amp; Pn)</p><p>(P1 | P2 |â€¦|Pn)</p><p>If P is a wff and â€˜vâ€™ (nu) is a variable, then âˆ€vP is a wff (and any occurrence of v in P is said to be bound).</p><p>If P is a wff, and v is a variables, then âˆƒvP is a wff(and any occurrence of v in P is said to be bound).</p><p>You never get a quantifier without a variable.</p><p>âˆ€xHome(x)</p><p>Bound and free are opposities.</p><p>âˆ€xHome(x) â€“ the 1st x binds the second. For all x, x is home. Notice that there are no free variables, thus this is a sentence.</p><p>Sentence = wff with no free variables (if there are variables, they must be bound)</p><p>âˆƒy(x) is a wff, but x is not bound, it is free. This is a mere wff, and clearly, not a sentence. The y, however, is bound.</p><p>âˆƒy âˆ€xP(x,y) â€“ this is a sentence. The â€œoccurrenceâ€ (that which is in parentheses) of both x and y are bound.</p><p>Notes â€“ October 19</p><p>Chapter 9</p><p>Quantificational logic â€“ Quantifiers</p><p>~, |, &amp;, ïƒ , ïƒŸïƒ  are our logical connectives. (Truth functional connectives)</p><p>Once you introduce quantifiers, you leave truth functional connectives behind. They still exist in their own realm, but quantifies are non-truth functional.</p><p>Basic Sentences</p><p>Noun phrase + verb phrase</p><p>Ted is dead. (â€œTedâ€ is the noun phrase) (â€œis deadâ€ is the verb phrase)</p><p>Every person Ted knows is alive. (â€œEvery person Ted knowsâ€ is the noun phrase) (â€œis aliveâ€ is the verb phrase)</p><p>Sentence (1) can be handled in truth-functional logic â€“ Dead(ted)</p><p>Sentence(2), however, canâ€™t be handled by truth functional logic. The noun phrase is the problem. Specifically, â€œEvery personâ€ canâ€™t be captured within truth functional logic. â€œEveryâ€ is a determiner. â€œPersonâ€ is a common noun. â€œEvery personâ€ is a quantifier expression.</p><p>Example Determiners:</p><p>All, some, every, each, most, at least then</p><p>Determiner + common noun = quantifier expression</p><p>â€˜Everyâ€™ + â€˜personâ€™ = â€˜Every personâ€™</p><p>E.g. â€“ â€˜Some dogsâ€™, â€˜Each childâ€™, â€˜All catsâ€™, â€˜Most cellistsâ€™, â€˜At least ten studentsâ€™</p><p>The quantity of the particular circumstance helps to determine the truth value of a quantified expression.</p><p>Quantifiers arenâ€™t truth functional, clearly. The quantity of something is not a truth value or facts about truth conditions?</p><p>We will use 2 quantifiers for now:</p><p>Universal Quantifier - âˆ€ - Every, each, for all, all, everything</p><p>Existential Quantifier - âˆƒ - Some, there exists, exists, at least one, something</p><p>Logical - =, ~, |, &amp;, ïƒ , ïƒŸïƒ , âˆ€, âˆƒ; (Individual variables) t, u, v, w, x, y, z (with or without subscripts)</p><p>Non-logical â€“ predicate symbols, function symbols, individual constants</p><p>Variables, like individual constants, are lower case letters. A-F constants, T-Z variables. They arenâ€™t the same though.</p><p>Large(a), Smaller(b, c), father(george) â€“ where individual constants can occur.</p><p>Syntactically, variables work just like constants. Anywhere one can appear, so can the other.</p><p>Large(x), father(y,) â€“ variables</p><p>So, they are syntactically identical. Semantically, they are very different.</p><p>The semantic role of an individual constant â€“ it picks out an individual thing.</p><p>Variables, however, donâ€™t pick out anything.</p><p>Large(a) has a truth value. Large(x) doesnâ€™t because x doesnâ€™t pick anything out.</p><p>father(george) picks someone out (it is a referring expression), father(x) doesnâ€™t pick anyone out. We donâ€™t know who x is.</p><p>Large(x) is not a sentence. Large(a) is a sentence.</p><p>Up until now, we had defined term has something which picks out. This is no longer true now that we have variables. We need to think of terms syntactically now.</p><p>Variables are simple terms (like individual constants). Complex terms, of course, are the results of function symbols applied to terms.</p><p>Atomic wff: an n-ary predicate symbol followed by n terms enclosed in parentheses and separated by commas (if necessary).</p><p>Wff: well-formed formula.</p><p>Wffâ€™s are very much like sentences; syntactically, they look like sentences, except a wff can have a free variable (in which case it doesnâ€™t actually say anything).</p><p>All atomic sentences are atomic wffs, but not the other way around. Atomic sentences are atomic wffs with no free variables. Let us call those atomic wffs with free variables, â€œmere wffsâ€.</p><p>Home(x)</p><p>Between(x, y, george)</p><p>5 = sum(u, 3)</p><p>You can take any atomic wff and operate on them with truth functional connectives, and the result will be a wff.</p><p>~Home(x) is a wff.</p><p>Home(x) &amp; (5=sum(u, 3)) is a wff (it isnâ€™t an atomic wff).</p><p>Wff â€“</p><p>All atomic wffs are wffs.</p><p>If P is a wff, so is ~P</p><p>If P and Q are wffs, then so are:</p><p>(Pïƒ Q)</p><p>(PïƒŸïƒ Q)</p><p>If P1, P2,â€¦,Pn are wffs, then so are:</p><p>(P1 &amp; P2 &amp;â€¦&amp; Pn)</p><p>(P1 | P2 |â€¦|Pn)</p><p>If P is a wff and â€˜vâ€™ (nu) is a variable, then âˆ€vP is a wff (and any occurrence of v in P is said to be bound).</p><p>If P is a wff, and v is a variables, then âˆƒvP is a wff(and any occurrence of v in P is said to be bound).</p><p>You never get a quantifier without a variable.</p><p>âˆ€xHome(x)</p><p>Bound and free are opposities.</p><p>âˆ€xHome(x) â€“ the 1st x binds the second. For all x, x is home. Notice that there are no free variables, thus this is a sentence.</p><p>Sentence = wff with no free variables (if there are variables, they must be bound)</p><p>âˆƒy(x) is a wff, but x is not bound, it is free. This is a mere wff, and clearly, not a sentence. The y, however, is bound.</p><p>âˆƒy âˆ€xP(x,y) â€“ this is a sentence. The â€œoccurrenceâ€ (that which is in parentheses) of both x and y are bound.</p><p>Notes â€“ October 26, 2010</p><p>A sentence is a wff with no free variables (free occurrences of variables).</p><p>Semantics for quantifiers</p><p>An object o satisfies a wff P(x) (whereby x is free) iff o has the property expressed by P.</p><p>Ex: o satisfies Cube(x) iff o is a cube.</p><p>o satisfies Home(x) &amp; Hungry(x) iff o is at home and hungry</p><p>If a names o, think of o satisfying P(x) in terms of P(a) being true.</p><p>Spâ€™ o has no name. Then o satisfies P(x) iff P(a) is true, where â€˜aâ€™ is a new name temporarily introduced into the language to name o.</p><p>Semantics for quantifiers:</p><p>âˆƒxS(x) is true iff there is at least one object which satisfies S(x).</p><p>âˆ€xS(x) is true iff every object satisfies S(x)</p><p>Ex: âˆƒx(Red(x) &amp; Truck(x)) â€“ Some trucks are red. A truck is red. I have a red truck. At least one truck is red.</p><p>âˆ€x(Cube(x) ïƒ  Small(x)) â€“ All cubes are small. Every cube is small. For anything you take to be a cube, it is small.</p><p>Domain of discourse; universe of quantification â€“ when we use quantifier expressions we have tacitly in mind some collection of objects in mind over which we are quantifying.</p><p>Every student took the test â€“ it is understood we arenâ€™t talking about all students around the world, only all the student registered for the class. The things we intuitively mean to be talking about.</p><p>Thus, the rules are a bit different, because of this domain issue.</p><p>âˆƒxS(x) is true iff there is at least one object in the domain which satisfies S(x).</p><p>âˆ€xS(x) is true iff every object in the domain satisfies S(x)</p><p>A domain is a non-empty (must contain one thing) collection of objects.</p><p>Every quantifier must be relative to a domain.</p><p>Translating:</p><p>All Pâ€™s are Qâ€™s</p><p>Some Pâ€™s are Qâ€™s</p><p>No Pâ€™s are Qâ€™s</p><p>Some Pâ€™s are not Qâ€™s</p><p>âˆ€x(P(x)ïƒ Q(x))</p><p>âˆƒx(P(x) &amp; Q(x))</p><p>âˆ€x(P(x) ïƒ  ~Q(x)) or ~âˆƒx(P(x) &amp; Q(x))</p><p>âˆƒx(P(x) &amp; ~Q(x))</p><p>Noun phrases naturally translated using the existential quantifier typically start with a determiner such as a, an, some.</p><p>e.g. A man on the bus fainted.</p><p>Some Pâ€™s are Qâ€™s</p><p>Some man on the bus fainted.</p><p>âˆƒx(Man(x) &amp; Bus(x) &amp; Fainted(x))</p><p>Man(x) &amp; Bus(x) is our P(x)</p><p>Fainted(x) is our Q(x)</p><p>Some prime is even.</p><p>âˆƒx(Prime(x) &amp; Q(x))</p><p>Noun phrases naturally translated using the universal quantifier typically start with a determiner such as all, every, or each.</p><p>Eg: Every man on the bus fainted.</p><p>âˆ€x((Man(x) &amp; Bus(x))ïƒ  Fainted(x))</p><p>Every prime is even.</p><p>âˆ€x(Prime(x) ïƒ  Even(x))</p><p>Max owns a small, happy dog.</p><p>âˆƒx(Small(x) &amp; Happy(x) &amp; Dog(x) &amp; Owns(max, x))</p><p>Small(x) &amp; Happy(x) &amp; Dog(x) is P(x)</p><p>Owns(max, x) is Q(x)</p><p>Claire knows every member of congress.</p><p>âˆ€z(Congress(z) ïƒ  Knows(claire, z))</p><p>Notes â€“ October 28, 2010</p><p>âˆ€x(P(x)ïƒ Q(x))</p><p>All Pâ€™s are Qâ€™s.</p><p>This is true if there are no Pâ€™s. Every object in the domain satisfies that wff, namely P(x)ïƒ Q(x). For any object in the domain, if a names that object, then the sentence P(a) ïƒ  Q(a) is true.</p><p>Either P(a) is false or Q(a) is true</p><p>Either ~P(a) is true or Q(a) is true</p><p>If there are no Pâ€™s, the claim that P has some further property is true.</p><p>âˆ€x(P(x)ïƒ Q(x)) is false iff there is at least one object o in the domain such that o is P, but not Q.</p><p>A sentence of the form âˆ€x(P(x)ïƒ Q(x)) which is true because there are no Pâ€™s said to be vacuously true.</p><p>Some sentences can only be vacuously true.</p><p>A sentence of the form âˆ€x(P(x)ïƒ Q(x)) which is never true unless it is vacuously true is said to be inherently vacuous.</p><p>Ex: âˆ€x(Cube(x)ïƒ Tet(x))</p><p>âˆ€x(P(x)ïƒ Q(x)) can conversationally imply that there are some Pâ€™s.</p><p>Ex: Every student who asked for help received it.</p><p>This has conversational implicature â€“ it implies that there were actually students who had asked for help, which isnâ€™t necessarily true. One can say, â€œbut no student asked for helpâ€ without contradicting the previous statement.</p><p>âˆƒx(P(x) &amp; Q(x)) can conversationally imply that not every P is Q.</p><p>Ex: Some students passed the test.</p><p>There is a strong suggestion here that not everyone passed the test, as if some students failed the test. This isnâ€™t necessarily true though. Perhaps all students passed the test, and we could still say the above without contradicting ourselves.</p><p>âˆƒx(P(x) ïƒ Q(x)) is a really weak statement</p><p>âˆƒx(~P(x) | Q(x)) is the same thing, and it is really too easy to satisfy.</p><p>Every even number is prime. = âˆ€x(Even(x) ïƒ  Prime(x))</p><p>No even number is prime = âˆ€x(Even(x) ïƒ ~Prime(x))</p><p>Some prime is even. = âˆƒx(Prime(x) &amp; Even(x))</p><p>Some prime is not even = âˆƒx(Prime(x) &amp; ~Even(x))</p><p>Every prime is either odd or equal to 2 = âˆ€x(Prime(x) ïƒ  (~Even(x)| x=1+1)</p><p>There are no medium-sized cubes = âˆ€x(Cube(x) ïƒ  ~Medium(x))</p><p>Nothing is in front of b = ~âˆƒx(FrontOf(x, b))</p><p>Every cube is either in front of or in back of e = âˆ€x(Cube(x) ïƒ  (FrontOf(x, e) | BackOf(x, e)))</p><p>No cube is between a and c. = âˆ€x(Cube(x) ïƒ  ~Between(x, a, c))</p><p>Everything is in the same column as a, b, or c. = âˆ€x(SameCol(x, a) | SameCol(x, b) | SameCol(x, c))</p><p>Notes â€“ November 2, 2010</p><p>Chapter 10</p><p>Logic of a 1st order logic, logic of quantifiers, quantification of logic, logic that you get once you throw in the quantifiers.</p><p>Why is it called first order logic? In Fol, Domains are only allowed to hold objects. You can quantify over property, for example, redness. A higher order logic could quantify over property, but not FoL. FoL is only allowed to quantify over objects.</p><p>âˆ€x(Cube(x))</p><p>âˆ€x(Small(x))</p><p>â€“</p><p>âˆ€x(Small(x) &amp; Cube(x))</p><p>This is valid, but not tautologically true.</p><p>Note that if we changed all the universal quantifier to the existential quantifier in the above argument, we wouldnâ€™t have a valid argument. Obviously the quantifiers are doing the heavy lifting here. Validity or invalidity of these arguments rested upon the quantifiers.</p><p>P(a) | ~P(a) - This is tautologically true. It relies only on truth functional connectives.</p><p>âˆƒxP(x) | âˆƒx~P(x) â€“ This is logically true, but it isnâ€™t tautologically true because it doesnâ€™t rely upon the truth functional connectves in the end. We need to turn to the quantifiers.</p><p>âˆ€xP(x) | âˆ€x~P(x) â€“ It is possible for this to be false, not a logical truth. Clearly, the meaning of the quanitifers mattered.</p><p>If changing the quantifiers changes the truth values of a logically true sentence, the reason that an argument is logically true before rested upon quantifiers. Therefore, this couldnâ€™t be tautologically true. If it were tautologically true, then you could switch the quantifiers and it wouldnâ€™t change the fact that the sentence is still logically true.</p><p>âˆƒxP(x) | ~âˆƒxP(x) â€“ Tautologically true.</p><p>âˆ€xP(x) | ~âˆ€xP(x) â€“ Tautologically true.</p><p>Note how the quantifiers do not impact the logical truth of the statement. You can switch them, and it is still logically true. Thus, this is tautologically true.</p><p>(~P | Q ) ïƒ  (P ïƒ  Q)</p><p>(~(A &amp; B) | (C ïƒŸïƒ ~A))ïƒ ((A &amp; B) ïƒ  (CïƒŸïƒ ~A))</p><p>I can uniformly replace the terms and still come out with what is tautologically true. Note P = (A &amp; B), Q =(CïƒŸïƒ ~A)</p><p>A sentence with the same truth functional form as a tautology is also a tautology. It doesnâ€™t matter if the substitutions, then have quantifiers in them.</p><p>(~âˆ€xS(x) | âˆƒyT(y)) ïƒ  (âˆ€xS(x) ïƒ  âˆƒyT(y))</p><p>To find the truth functional form-â€”</p><p>Given a sentence S of FoL:</p><p>Step 1- Identify and label all atomic sentences and quantified sentences of S.</p><p>Step 2- Replace each atomic and quantified sentence with its label.</p><p>(~âˆ€xS(x) | âˆƒyT(y)) ïƒ  (âˆ€xS(x) ïƒ  âˆƒyT(y))</p><p>A B A B</p><p>(~A | B) ïƒ  (A ïƒ  B)</p><p>Note how the the appropriate (not all, necessarily will) truth functional logical connectives stay in place, but the rest of the equation can be substituted.</p><p>~(Tet(d) &amp; âˆ€xSmall(x)) ïƒ  (~Tet(d) | ~âˆ€ySmall(y))</p><p>~(A &amp; B) ïƒ (~A | ~C)</p><p>Note how âˆ€xSmall(x) and âˆ€ySmall(y) are equivalent, but because they have different variables, they are different sentences. Sentences are syntactic objects, so we need to differentiate these in our substitution process. Note how the first becomes B and the latter becomes C.</p><p>A sentence of FoL is a tautology iff its truth functional form is a tautology.</p><p>Two sentences of FoL are tautologically equivalent iff their truth functional forms tautologically equivalent.</p><p>A sentence S of FoL is a tautological consequence of FoL sentences P1â€¦Pn iff the â€˜tffâ€™ (truth functional form) of S is a tautological of tffâ€™s of P1â€¦Pn.</p><p>Propositional Logic = Truth Functional Logic</p><p>Propositional Logic
	</p><p>First-Order Logic
	</p><p>General Notions</p><p>Tautology
	</p><p>??
	</p><p>Logical truth</p><p>Tautological consequence
	</p><p>??
	</p><p>Logical consequence</p><p>Tautological equivalence
	</p><p>??
	</p><p>Logical equivalence</p><p>Just as propositional logic has these relationship with the general notions, specifically as a sub-species, FoL also has the same sorts of relationships.</p><p>Propositional Logic
	</p><p>First-Order Logic
	</p><p>General Notions</p><p>Tautology
	</p><p>FO validity
	</p><p>Logical truth</p><p>Tautological consequence
	</p><p>FO consequence
	</p><p>Logical consequence</p><p>Tautological equivalence
	</p><p>FO equivalence
	</p><p>Logical equivalence</p><p>Tautologically consequence sits inside FO consequence which sits inside logical consequence.</p><p>Tautological consequence is logical consequence because of (considering only) the semantics of truth functional connectives.</p><p>FO consequence is logical consequence because of (considering only) the logical functional connectivesâ€”essentially excluding the non-logical functional connectives. Think of the non-logical functional connectives as LeftOf(x, y) and RightOf(y, x).</p><p>FO Validity: a sentence which is logically true considering only truth-functional connectives, identity (â€˜=â€™), and quantifiers.</p><p>â€œScarlet is Red.â€ Isnâ€™t FO valid, but it is logically true. Note the logical truth making relationship between Scarlet and Red simply canâ€™t be explained in FO logic.</p><p>FO equivalence: Sentences S1, S2 which are logically equivalent considering only truth functional connectives, identity, and quantifiers. (I.e. Ignore facts about non-logical language).</p><p>FO Consequence: logical consequence considering only [truth functional connectives, identity, and quantifiers].</p><p>To tell the difference between these 3 species, Proposition, FO and general logic, one must understand what is required to be considered in order for it to attain the logical status.</p><p>Notes â€“ November 4</p><p>Two techniques for ignoring non-logical vocabulary:</p><p>Nonsense words method</p><p>Dummy Letters method</p><p>You can tell whether or not the truth value of a sentence relies upon the truth value and meaning of predicate via this method. These methods allow you to tell if the sentence, while perhaps logically true based upon the meaning of the predicate, obviously isnâ€™t FO valid because the logical truth is true because of the meaning of the predicate.</p><p>Nonsense words method (words from jabberwocky):</p><p>âˆ€xSameSize(x, x) becomes âˆ€xOutgrabe(x,x) â€“ clearly, the meaning of the predicate â€œOutgrabeâ€ is necessary to the truth value of this sentence</p><p>âˆ€xCube(x) ïƒ  Cube(b) becomes âˆ€xTove(x) ïƒ  Tove(b) â€“ this is true, regardless of what the predicate â€œToveâ€ means. Thus FO valid.</p><p>(Cube(b) &amp; b =c) ïƒ  Cube(c) becomes (Tove(b) &amp; b = c) ïƒ  Tove(c) â€“ this is true, regardless of the meaning of the predicate. Thus, FO valid.</p><p>Dummy Letters replaces the predicate with just a plain letter rather than nonsensical words.</p><p>âˆ€x(Tet(x) ïƒ  Large(x))</p><p>~Large(b)</p><p>-â€”Therefore-â€”</p><p>~Tet(b)</p><p>âˆ€x(T(x) ïƒ  L(x))</p><p>~L(b)</p><p>â€”Thereforeâ€”</p><p>~T(b)</p><p>FO counterexamples:</p><p>Here is a FO counterexample to the FO equivalence. Weâ€™ll use the â€œreplacement method.â€</p><p>~âˆƒxLarger(x, a)</p><p>~âˆƒxLarger(b, x)</p><p>Larger(c, d)</p><hr><p>Larger(a, b)</p><p>(Specification)</p><p>~âˆƒxR(x, a)</p><p>~âˆƒxR(b, x)</p><p>R(c, d)</p><hr><p>R(a, b)</p><p>Let the domain consist ofâ€”</p><p>a = Al</p><p>b = Bob</p><p>c = Claire</p><p>d = Debbie</p><p>Interpretation of R relationship is R(x, y): x like y</p><p>So, a specification of the counterexample is this:</p><p>No one likes Al</p><p>Bob doesnâ€™t like anyone</p><p>Claire likes Debbie</p><p>Al doesnâ€™t like Bob (his is the false version of the conclusion, so we have a counterexample)</p><p>(Verification)</p><p>On this interpretation:</p><p>The first premise is true. It says no one likes Al, as specified.</p><p>The second premise is true. It says Bob likes no one, as specified.</p><p>The third premise is true. It says Claire likes Debbie, as specified.</p><p>The conclusion is false. It says Al likes Bob, but in the interpretation, Al doesnâ€™t like Bob.</p><p>10.3 â€“ Concerning a notion of logical equivalence among â€˜mereâ€™ wffs.</p><p>Say wffs P(x), Q(x) are logically equivalent iff they are satisfied by exactly the same objects in every possible situation (or world).</p><p>Think about this in terms of P(a) ïƒŸïƒ Q(a) for any new name a.</p><p>Substitution principle â€“</p><p>Let P, Q be wffs (mere or sentences). Let S(P) be any sentence in which P appears as a part. (Similarly for S(Q)). Then if P and Q are logically equivalent so are S(P) and S(Q).</p><p>For example:</p><p>P ïƒ  Q is equivalent to ~P | Q</p><p>Consider S(P) as âˆ€x(A(x)ïƒ B(x)) - where A(x)ïƒ B(x) is P</p><p>Consider S(Q) as âˆ€x(~A(x) | B(x)) where ~A(x) | B(x) is Q</p><p>Substitution principle gives us a way of proving FO Equivalence.</p><p>Notes â€“ November 9, 2010</p><p>P ïƒŸïƒ  Q</p><p>S(P) ïƒŸïƒ S(Q)</p><p>Show: âˆ€x(P(x) ïƒ Q(x)) ïƒŸïƒ  âˆ€x~(P(x) &amp; ~Q(x))</p><p>âˆ€x(P(x) ïƒ Q(x)) ïƒŸïƒ  âˆ€x(~P(x) | Q(x)) ïƒŸïƒ  âˆ€x(~P(x) | <strike>Q(x)) ïƒŸïƒ  âˆ€x~(P(x) &amp; ~Q(x))

Chain of Equivalences



â€œDeMorganâ€™s for Quantifiersâ€

~(P | Q) ïƒŸïƒ  ~P &amp; ~Q ~âˆ€xP(x) ïƒŸïƒ  âˆƒx~P(x)

~(P &amp; Q) ïƒŸïƒ  ~P | ~Q ~âˆƒxP(x) ïƒŸïƒ  âˆ€x~P(x)



Suppose we have a fixed k-membered domain (it is finite).

A1, a2,â€¦ak

[âˆ€xP(x)] is true iff [P(a1) &amp; P(a2) &amp; â€¦&amp; P(ak)] is true.

Likewise, with negations:

~[âˆ€xP(x)] is true iff ~[P(a1) &amp; P(a2) &amp; â€¦&amp; P(ak)] is true.

Demorganâ€™s works with ~[P(a1) &amp; P(a2) &amp; â€¦&amp; P(ak)], thus [~P(a1) | ~P(a2) | â€¦| ~P(ak)]

[~P(a1) | ~P(a2) | â€¦| ~P(ak)] is equivalent to âˆƒx~P(x)



Show: ~âˆ€(P(x)ïƒ Q(x)) ïƒŸïƒ âˆƒx(P(x) &amp; ~Q(x))

~âˆ€(P(x)ïƒ Q(x)) ïƒŸïƒ âˆƒx~(P(x))ïƒ Q(x))

ïƒŸïƒ âˆƒx~(~P(x) | Q(x))

ïƒŸïƒ âˆƒx(</strike>P(x) &amp; ~Q(x))</p><p>ïƒŸïƒ âˆƒx(P(x) &amp; ~Q(x))</p><p>Or</p><p>~âˆ€(P(x)ïƒ Q(x)) ïƒŸïƒ âˆƒx~(P(x))ïƒ Q(x))ïƒŸïƒ âˆƒx(P(x) &amp;~Q(x))</p><p>Substitution/TFF examples:</p><p>âˆ€x(Cube(x) &amp; Small(x)) ïƒ  âˆ€x(Small(x) &amp; Cube(x))</p><p>A ïƒ  B</p><p>âˆ€xCube(x) ïƒ  ~âˆƒx~Cube(x)</p><p>A ïƒ  ~B</p><p>(âˆƒxCube(x) | âˆƒyDodec(y)) ïƒ  âˆƒxCube(x)</p><p>(X | Y) ïƒ  X</p><p>Cube(a) &amp; Cube(b)</p><p>Small(a) &amp; Large(b)</p><p>âˆƒx(Cube(x) &amp; Large(x) &amp; ~Smaller(x, x))</p><p>A &amp; B</p><p>S &amp; L</p><p>E</p><p>Clearly, not a tautological consequence. Letâ€™s try, instead of substitution, try replacement (nonsense) method to test of FO consequence.</p><p>P(a) &amp; P(b)</p><p>Q(a) &amp; L(b)</p><p>âˆƒx(P(x) &amp; L(x) &amp; R(x, x))</p><p>This is not FO consequent, and only logical consequence. It obviously rests upon the meaning of the predicate â€œSmaller.â€ Thus, we need an FO counterexample.</p><p>Let our domain consist of two objects, a small cube, a, and a large cube, b.</p><p>P(x): x is a cube</p><p>Q(x): x is small</p><p>L(x): x is large</p><p>R(x, y): x is the same size as y</p><p>Verify each of the premises and conclusion</p><p>Premise 1 is true, because A is a cube and B is a cube.</p><p>Premise 2 is true because A is small and B is large</p><p>The conclusions is False is there is nothing in the domain which is not the same size as itself.</p><p>Notes â€“ November 11</p><p>Someone likes everyone.</p><p>âˆƒxâˆ€yLikes(x,y)</p><p>Every cube is to the left of every tetrahedron.</p><p>âˆ€xâˆ€y((Cube(x) &amp; Tet(y)) ïƒ  LeftOf(x, y))</p><p>Some dog chased a cat.</p><p>âˆƒxâˆƒy(Dog(x) &amp; Cat(y) &amp; Chased(x, y))</p><p>When all the quantifiers are at the front, this form of writing equations is called â€œPrenex normal formâ€ or just plain â€œPrenex Formâ€ â€“ There are other ways to formulate many sentences though. E.g:</p><p>Every cube is to the left of every tetrahedron.</p><p>âˆ€xâˆ€y((Cube(x) &amp; Tet(y)) ïƒ  LeftOf(x, y))</p><p>âˆ€x(Cube(x) ïƒ  âˆ€y(Tet(y) ïƒ  LeftOf(x, y)))</p><p>Caution: Distinct variables does not entail distinct objects. E.g.:</p><p>âˆƒxâˆƒy(Tet(x) &amp; Tet(y))</p><p>This sentence only requires 1 object in the domain (a single tet) for the sentence to be true. X and y do not need to refer to two different things.</p><p>âˆƒx(Tet(a) &amp; Tet(x))</p><p>Tet(a) &amp; Tet(a) is an example that satisfies the sentence.</p><p>Notice how this is different:</p><p>âˆƒxâˆƒy(Tet(x) &amp; Tet(y) &amp; x != y)</p><p>This shows that x is not y, thus we know there must be at least 2 tets in order for the sentence to be true.</p><p>âˆ€xâˆ€yP(x, y)</p><p>âˆ€xP(x, x)</p><p>âˆƒxP(x, x)</p><p>âˆƒxâˆƒyP(x, y)</p><p>11.2</p><p>Mixed quantifiers are when you have multiple quantifiers whereby the quantifiers arenâ€™t all the same.</p><p>âˆ€x(Cube(x) ïƒ  âˆƒy(Tet(y) ïƒ  LeftOf(x, y))) ïƒŸïƒ </p><p>âˆ€xâˆƒy(Cube(x) ïƒ  (Tet(y) ïƒ  LeftOf(x, y))), but it is not equivalent to</p><p>âˆƒyâˆ€x (Cube(x) ïƒ  (Tet(y) ïƒ  LeftOf(x, y)))</p><p>Swapping the order of different quantifiers changes the meaning. However, swapping the order of the same quantifiers does not change the meaning.</p><p>âˆ€xâˆ€yLikes(x, y) ïƒŸïƒ  âˆ€yâˆ€x Likes(x, y)</p><p>Notice, they have the same meaning. â€œEveryone likes everyoneâ€ and â€œEveryone is liked by everyoneâ€.</p><p>âˆ€xâˆƒyLikes(x, y) â€“ Everyone likes someone â€“ a likes b, b likes c, c likes a</p><p>âˆƒyâˆ€xLikes(x, y) â€“ Someone is liked by everyone â€“ a likes c, b likes c, c likes c</p><p>âˆƒxâˆ€yLikes(x, y) â€“ Someone likes everyone â€“ a likes a, a likes b, a likes c</p><p>âˆ€yâˆƒxLikes(x, y) â€“ Everyone is liked by someone. â€“ a likes a, b likes b, c likes c</p><p>These are all distinct, they arenâ€™t equivalent. Some are implied by others, but not the other way around. You can produce counterexamples between any two to show why they are not equivalent. Order clearly matters when your quantifiers are different.</p><p>âˆƒxâˆƒy( x != y &amp; Tet(x) &amp; Tet(y))</p><p>The existential/numerical quantification allows us to say:</p><p>At least n</p><p>At most n</p><p>Exactly n</p><p>Sp, we want to say: At least two students passed the test.</p><p>âˆƒxâˆƒy(âˆ®(x) &amp; âˆ®(y) &amp; x != y)</p><p>So (1) is translated</p><p>âˆƒxâˆƒy(S(x) &amp; P(x) &amp; S(y) &amp; P(y) &amp; x != y)</p><p>Where S(x): x is a students, P(x): x passes the test.</p><p>If you have multiple identity statements or negations of identity, relating multiple objects, you can loop carefully.</p><p>X is not y, x is not z, x is not a; y is not z, y is not a; z is not a</p><p>Spâ€™: At most two students failed the test.</p><p>âˆ€xâˆ€yâˆ€z((âˆ®(x) &amp; âˆ®(y) &amp; âˆ®(z)) ïƒ  (x = y | x =z | y =z))</p><p>So this is translated:</p><p>âˆ€xâˆ€yâˆ€z((S(x) &amp; F(x) &amp; S(y) &amp; F(y) &amp; S(z) &amp; F(z)) ïƒ  (x = y | x =z | y =z))</p><p>Where, S(x): x is a student, F(x): x fails the test.</p><p>This strategy generalizes: to say that at most n things are âˆ®, say that for any x1, x2,â€¦.,xn+1, if each xi (1 &lt;= i &lt;= n +1) is âˆ® then xj is identical to xk for some 1 &lt;= j, &lt;= n+1.</p><p>Note that negation of at least will give at most.</p><p>Exactly â€“ join at least and at most.</p><p>For exactly two things are phi.</p><p>Notes â€“ November 16, 2010</p><p>Each cube is to the left of a tetrahedron.</p><p>Go through and identify quantifier expressions.</p><p>â€œEach cubeâ€ and â€œa tetrahedronâ€</p><p>âˆ€x(Cube(x) ïƒ  x-is-to-the-left-of-a-tet)</p><p>âˆ€x(Cube(x) ïƒ  (âˆƒy(Tet(y) &amp; LeftOf(x, y))))</p><p>Every small cube is in back of a large cube.</p><p>â€œEvery small cubeâ€ and â€œa large cubeâ€</p><p>âˆ€x((Small(x) &amp; Cube(x)) ïƒ  in-back-of-a-large-cube)</p><p>âˆ€x((Small(x) &amp; Cube(x)) ïƒ âˆƒy(Large(y) &amp; Cube(y) &amp; BackOf(x, y)))</p><p>Some cube is in front of every tetrahedron.</p><p>â€œSome cubeâ€ and â€œevery tetrahedronâ€</p><p>âˆƒx(Cube(x) &amp; is in front of every tet)</p><p>âˆƒx(Cube(x) &amp; âˆ€y(Tet(y) ïƒ  Front(x, y))</p><p>Nothing is larger than everything.</p><p>~âˆƒxâˆ€yLarge(x,y)</p><p>Everything to the right of a large cube is small.</p><p>âˆ€x(x is to the right of a large cube ïƒ  Small(x))</p><p>âˆ€x(âˆƒy(Large(y) &amp; Cube(y) &amp; RightOf(x, y)) ïƒ  Small(x))</p><p>Anything with nothing in back of it is a cube.</p><p>â€œAnythingâ€ and â€œnothingâ€ â€” notice that â€œis a cubeâ€, the determiner â€œaâ€ doesnâ€™t make this a quantified expression.</p><p>âˆ€x(if nothing is in back of x ïƒ  Cube(x))</p><p>âˆ€x((~âˆƒy(BackOf(y, x))ïƒ Cube(x))</p><p>Paraphrasing Englishâ€”</p><p>If a freshman takes a logic class, then he or she must be smart.</p><p>If you attempt to translate step by step, you get:</p><p>âˆƒx(Freshman(x) &amp; âˆƒy(LogicClass(y) &amp; Takes(x, y))) ïƒ  Smart(x)</p><p>Not a sentence, it has a free variable â€œSmart(x)â€</p><p>â€œEvery freshman who takes a logic class is smartâ€</p><p>âˆ€x[(Freshman(x) &amp; âˆƒy(LogicClass(y) &amp; Takes(x, y))) ïƒ  Smart(x)]</p><p>Every farmer who owns a donkey beats it.</p><p>(These are called â€œDonkey sentencesâ€)</p><p>âˆ€x(Farmer(x) &amp; âˆƒy(Donkey(y) &amp; Owns(x, y)) ïƒ  Beats(x, y))</p><p>Note that â€œBeats(x, y)â€ has a free variable, namely y.</p><p>â€œEvery donkey owned by any farmer is beaten by them.â€</p><p>âˆ€x(Donkey(x) ïƒ  âˆ€y((Farmer(y) &amp; Owns(y, x) ïƒ  Beats(y, x)))</p><p>Sometimes you have to paraphrase. Donkey sentences are good examples. Otherwise, you wonâ€™t be able to apply the step-by-step method.</p><p>Use double arrow for chain of equivalences.</p><p>Notes â€“ November 18</p><p>13.1</p><p>âˆ€ Elim â€“ Universal Elimination</p><p>k. âˆ€xS(x)</p><p>.</p><p>n. S(c) âˆ€ Elim: k</p><p>Here x is any variable. c is any individual constant. Clearly, if everything is S, then c is S.</p><p>General conditional proof (âˆ€ Intro)</p><p>Remember before where if we want to prove â€˜If P, then Qâ€™. Assume P, derive Q.</p><p>||j. [c] P(c)</p><p>||---â€”</p><p>||.</p><p>||k. Q(c)</p><p>|k+1. âˆ€x(P(x) ïƒ  Q(x)) âˆ€ Intro. J-k</p><p>[c] is a boxed constant. A boxed constant introduces a constant into your proof on a temporary basis. Let c be an arbitrary thing such that c satisfies P(x). If you can arbitrarily prove that a constant c which has P would have Q, then you can also prove that all things which have P also have Q. If it doesnâ€™t matter what you choose at the constant, then you could choose them all, thus the universal claim works here.</p><p>It is like saying, choose any marble from this bag, and Iâ€™ll prove it is red. Thus, all the marbles in the bag are red.</p><p>CAVEAT: Importantly, c cannot occur outside the subproof in which it is introduced. If you were able to use it outside, then it wasnâ€™t arbitrary because you had information about that particular constant already. We need arbitrariness in order to guarantee that we could simply choose anything and the proof would hold.</p><p>âˆ€ Intro</p><p>||j.[c]</p><p>||.</p><p>||k.P(c)</p><p>|k+1. âˆ€xP(x)</p><p>Let c be arbitrary. Note, that this does not have a property or predicate like the previous form a âˆ€ intro.</p><p>We must instantiate the quantified sentences using the constant we have arbitrarily assumed in the subproof.</p><p>13.2</p><p>Existential introduction ( âˆƒ Intro)</p><p>k. S(c)</p><p>.</p><p>n. âˆƒxS(x) âˆƒ Intro: k</p><p>c is any constant. x is any variable. Clearly, there is a particular thing which has S, and satisfies the wff S, namely c. Thus, we know that at least one thing (something) has S.</p><p>Existential Elimination (âˆƒ Elim)</p><p>|j. âˆƒxS(x)</p><p>||k1. [c] S(c)</p><p>||.</p><p>||kn. Q</p><p>|kn+1 Q âˆƒ Elim: j, k1-kn</p><p>Again, c can only appear in the subproof in which it is introduced.</p><p>Something is S, call that thing c. Something (arbitrarily chosen) being S meaning Q, means Q is true.</p><p>Notes â€“ November 23, 2010</p><p>For Existential Elim:</p><p>This is very much like disjunction elim because you have to do a subproof over each of the disjuncts. In the case of existential elim, you are technically doing a subproof over each of the â€˜disjunctsâ€™ or over each thing in the domain to demonstrate that you can arbitrarily choose an object in your domain and it will satisfy the wff.</p><p>Generally, when you have ExSome(x) in your premises, youâ€™ll generally want to make use of Existential Elim.</p><p>In the example of Existential Elim, you canâ€™t be any boxed constants out of the subproof. You can only have variables come out.</p><p>13.3</p><p>âˆƒx(Tet(x) &amp; Small(x))</p><p>âˆ€x(Small(x) ïƒ  LeftO(x, b))</p><p>âˆƒxLeftOf(x, b)</p><p>Informal Proof:</p><p>Something is a small tet, by the first premise.</p><p>Call that thing a, by the second premise anything that is small is also to the left of b. So, a is to the left of b. Hence, something is to the left of b, viz. (namely) a.</p><p>There are signposts for which proof rules to use here.</p><p>â€œCall that thing aâ€ starts an Existential Elim subproof. We have temporarily given this thing a name.</p><p>â€œanything that is small is also to the left of bâ€ is can application of Universal Elim and also ïƒ Elim and also &amp;Elim</p><p>â€œsomething is to the left of b, viz. (namely) a.â€ is an application of existential intro.</p><p>|1. âˆƒx(Tet(x) &amp; Small(x))</p><p>|2. âˆ€x(Small(x) ïƒ  LeftO(x, b))</p><p>|----â€”</p><p>||3. [a] Tet(a) &amp; Small(a)</p><p>||-----â€”</p><p>||4. Small(a) ïƒ  LeftOf(a, b) âˆ€ Elim: 2</p><p>||5. Small(a) &amp; Elim: 3</p><p>||6. LeftOf(a, b) ïƒ Elim: 4, 5</p><p>||7. âˆƒxLeftOf(x, b) âˆƒ Intro: 6</p><p>|8. âˆƒxLeftOf(x, b) âˆƒ Elim: 3-7</p><p>If you are stuck, you negation intro. Proof by contradiction.</p><p>Notes â€“ November 30</p><p>Universal quantified premises donâ€™t give us any strategy.</p><p>Notes â€“ December 2</p><p>Final-</p><p>9 sections</p><p>Definitions</p><p>T/F</p><p>Truth Tables</p><p>Truth functional forms</p><p>Classifying sentences</p><p>Translations</p><p>Counterexamples</p><p>2 Sections on Proofs</p><p>2 hours. 2 Bluebooks, 1 is for scratch, the other the answer booklet.</p><p>Counterexample:</p><p>âˆ€y[Cube(y) | Dodec(y)]</p><p>âˆ€x[Cube(x) ïƒ  Large(x)]</p><p>âˆƒx~Large(x)</p><p>âˆƒx[Dodec(x) &amp; Small(x)]</p><p>Specify and Verify</p><p>Specify meanings for the language, and then specify your world.</p><p>Replacement method with dummy variables.</p><p>âˆ€y(P(y) | Q(y))</p><p>âˆ€x(P(x)ïƒ S(x))</p><p>âˆƒx~S(x)</p><p>âˆƒx(Q(x) &amp; T(x))</p><p>P(x): x is a cube</p><p>Q(x): x is a dodec</p><p>S(x): x is large</p><p>T(x); x is small</p><p>Consider a world containing only a medium Dodec.</p><p>Verification time, bitches:</p><p>Premise 1 is true because everything is either a cube or a dodec. The only object in the domain is a dodec.</p><p>Premise 2 is true, vacuously true even. Everything in the world is such that if it is a cube, then it is a Large. As there are no cubes, this can be satisfied.</p><p>Premise 3 is true because there exists something which isnâ€™t Large, namely our Dodec is medium.</p><p>The conclusion, however, is false because there isnâ€™t a Large dodec in our domain. The dodec is medium.</p><p>âˆ€x[Cube(x) | (Tet(x) &amp; Small(x))]</p><p>âˆƒx[Large(x) &amp; BackOf(x, c)]</p><p>âˆ€x[Small(x) ïƒ  ~BackOf(x, c)]</p><p>Specify language meanings, Specify domain:</p><p>Let the blocks language have its normal meanings.</p><p>Consider a world containing two small tets, and c, and a large cube. Let a be behind b and c, and let b behind c.</p><p>Premise 1 is true because everything in the domain is either a cube or a small tet, a and c being the small tets and c being the cube.</p><p>Premise 2 is true because a Large cube, b, is in back of c.</p><p>The conclusion, however, is false because not everything which is small is not in the back of c, namely the small tet a is in back of c.</p><p>âˆ€x[Cube(x) | Dodec(x)]</p><p>âˆ€x[Cube(x) ïƒ  (Large(x) | LeftOf(c, x))]</p><p>âˆ€x[~Small(x) ïƒ  Tet(x)]</p><p>âˆƒzDodec(z)</p></div>



</div>

</p>
</section>
</body>
</html>
