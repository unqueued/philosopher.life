created: 20180518002515737
creator: h0p3
modified: 20181031035931164
modifier: h0p3
tags: Tulane
title: 2012.12.11 - Epistemology: Class Notes

Berker’s Handout 1



Clifford: ““It is wrong always, everywhere, and for anyone, to believe anything upon insufficient evidence.”



What counts as insufficient evidence?





Clifford: “It is wrong always, everywhere, and for anyone, to form beliefs without seeking any readily available evidence that is relevant to them.”



What counts as readily available evidence?

Relevant to the beliefs/forming of beliefs, right?



Is this coin biased? How many times do I have to flip it to form a valid belief?





When acted upon, they directly lead to harm. [Even when true?]



Not always. The method may not maximize utility overall (averaging all circumstances, etc.), but I might find exceptions. Possible: The indirect claims are flawed if the direct claim is flawed.





Haack



Haack may be assuming a model of human flourishing, rather than other models ethics/morality (pg. 22). This is fine, but I think it brings a lot of baggage to the table. Flourishing has more components than merely “what is right or wrong, as it also contends with the human good, which isn’t always a moral matter. For example, a starving person isn’t fully partaking of the human good (isn’t achieving eudaimonia), but this may not be an issue of “should or ought,” as perhaps the starving person has no choice in the matter. My worry is that the non-moral components of a model of human flourishing may cloud the issue about the relationship between epistemic and moral normativity.



Further, this highlights a larger problem, namely that the relationship between the epistemic and the moral is complicated and defined by whichever approach or model of morality we assume. It would make it a lot easier if we could just choose one model, and work from there. Perhaps that is what Haack has in mind. Note that her teleological language might bridge to Clifford’s instrumental considerations.





In Haack’s second argument against the special-thesis, we are asked to deny that a “straightforward sense [of] voluntary” choice in coming to believe something prevents one from being responsible or culpable for coming to believe something. If one cannot be responsible for an action, then that action seems to be outside the scope of morality (assuming we aren’t compatibilists, etc.), and thus the epistemic appraisal would not be a subset of moral appraisal. Again, I would like to highlight just how many moral and metaethical assumptions have to be made in these critiques. A systematic view on this topic requires a lot of substantive material on both sides, the epistemic and the moral, before we can effectively attempt to bridge them.



The “in due course” rebuttal to the second argument against the special-thesis seems appropriate. It makes me think we should slow down in the epistemic side of the conversation, and to break down and chronologize the aspects and steps of belief and coming to believe. With that in hand, it would be much easier to sort out which (if any) components are also moral ones. We would still be left with many questions about the relationship between the epistemic and the moral, but clarity on these matters wouldn’t hurt.



It seems as if we are wondering whether or not the claim “a person is epistemically unjustified in a particular belief” is the same thing as saying that “a person should not have a particular belief.” Further, in what sense do we mean “a person should not have that belief?” If Haack’s criticism of the special-thesis, there is the sense of an “epistemic should” and a “moral should.” Perhaps one could be epistemically at fault, but not necessarily morally at fault, and epistemic appraisal is then separated from (and is not a subset of) moral appraisal to some extent. I think the hope of the critique is that that we can maintain two distinct kinds of normativity (or something like that), one being epistemic and the other moral.



I’m trying to think of an example where one is epistemically unjustified or epistemically “should not” believe in something, but holding that belief is morally acceptable or obligated. In the scenarios I’ve considered, it seems that the epistemic “should” is outweighed by or takes a backseat to other salient moral considerations, perhaps similar to the rebuttal of the first criticism of the special-thesis. Does anyone have a clear example which elucidates and compels me to agree to the third criticism?



The reinterpretation of the special-case seems, at first glance, fairly compelling. Haack’s criticism is that only some of the epistemic requirements are ethical, but not all. Those epistemic requirements which are overridden by other requirements are presumed not to be ethical. I still find that reinterpretation persuasive, and my response to Haack would be something like this:



The sense of “epistemic should not” doesn’t exist or isn’t relevant. I don’t see how the “epistemic should not” holds the normative weight that the criticism assumes it does. Epistemic justification is important insofar as it is a moral consideration, but there isn’t some kind of epistemic normativity outside of moral normativity. The simple and bare claim that a belief is epistemically unjustified is a morally neutral or decontextualized claim, it lacks normativity. All else being equal, or given no other moral considerations, I may agree that epistemic justification or lack thereof does bring with it a corresponding moral duty to believe or not to believe. But I don’t have to agree that epistemic justification has any independent, stand-alone normative force that the criticism pushes us towards.





Berker on James



“Whenever one faces a genuine option that is not settled by the evidence , one may (both in the sense that it is possible for one to, and in the sense that it is permitted for one to) decide based on one’s “passional nature” which hypothesis to believe.”



What does it mean “not settled?” Could one have more evidence for one of the other, but since it isn’t certain or definitive or sufficient, then it doesn’t matter? And, why should I think that?






Class – Clifford



Act Utility/Rule Utility is analogous jump for particular instance of epistemic judgment vs. a rule or method of epistemic judgment .



I have an obligation to myself as an autonomous, rational, epistemic agent to form beliefs on the basis of sufficient evidence (and never on insufficient evidence).





Difference between:



I believe it, but it is not true.

I believe it, but it may not be true. (Bayesian)



If you deny the 2nd, then you have infallible beliefs.





How close is the gap between belief and acton? One way to judge if someone has a belief, rather than a mere opinion, is whether or not they act on that belief (perhaps consistently and continually) in all situations. If they don’t have act on it in those cases, then we might be prone to say they don’t really believe it.





Bonjour



Case 1, Samantha the Clairvoyant – Why should we think that “Samantha is being thoroughly irrational and irresponsible in disregarding cogent evidence that the President is not in New York City on the basis of a clairvoyant power which she has no reason at all to think that she possesses?”



I’m not sure I really like the use of Claivoyance here. It brings with it too many connotations that we may have a hard time shaking off. Maybe that’s the point of the argument though.



A thermometer. Reliable indicator.



The analogy between epistemic normativity and moral normativity is fascinating. It seems to hold (at least on the surface) even if one agrees to what Haack refers to as the special-thesis.



Moral Justification (e.g. an action leads to the best overall consequences [p. 371]) vs. Epistemic Justification (a law-like connection between a person’s belief and the state of affairs that makes it true [p. 368]) – Neither is enough to say that one has chosen to act (Moral) or believe (Epistemic) rightly. Responsibility and duty, in each case of justification, requires a second clause. Namely, intent and belief in acting or believing rightly matters.





Bonjour offers us

Perhaps I have greatly misunderstood the Lottery Paradox (forgive me if I have). The Lottery Paradox doesn’t seem so obviously problematic to me. It may, in the end, actually demonstrate a problem somehow, but it doesn’t do it well, in my view. At the very least, the way in which Bonjour presents the Lottery Paradox seems unfair.



Let me reconstruct the Paradox as Bonjour presents it and (very briefly) try to evaluate whether it does the work Bonjour thinks it does.



Assume there is a fair lottery with 100 tickets sold. For each possible n, where n >= 1 and n <= 100, “Ticket number n will lose” has a .99 probability of being true. The probability there will be a winning ticket (from these 100) is 1.00, and the probability of any particular ticket winning is 0.01.



Further, if we assume that “a belief is adequately justified to satisfy the requirement for knowledge if the probability its truth, relative to its justification, is 0.99 or greater,” then for any particular n, believing “Ticket number n will lose” is adequately justified to satisfy the requirement for knowledge.



Bonjour’s critical assumption is this: If we are epistemically justified in believing the statement “Ticket number n1 will lose” and the statement “Ticket number n2 will lose,” then we are epistemically justified in believing the conjunction of these statements.



I believe this is essentially what Bonjour is claiming:



On the left side, we have a standard proposition logic substituting for the statements to their right.



A [Ticket number n1 will lose]

B [Ticket number n2 will lose]

A & B [Ticket number n1 will lose] & [Ticket number n2 will lose]



By exaggerating this through multiple conjunctions, an absurdity supposedly emerges. It is thought to look something like this:



A [Ticket number n1 will lose]

B [Ticket number n2 will lose]

C [Ticket number n3 will lose]

D [Ticket number n4 will lose]

.

.

.

A & B [Ticket number n1 will lose] & [Ticket number n2 will lose]

A & B & C [Ticket number n1 will lose] & [Ticket number n2 will lose] & [Ticket number n3 will lose]

.

.

.



The conjunction of the logical propositions is pretty basic. If 100 propositions are true [P1, P2, . . ., P100], then the conjunction of all 100 propositions, e.g. [P1 & P2 & . . . & P100], is also true. The idea of the Lottery Paradox is thought to be similar to propositional logic. The right hand process, seen above, is continued until we arrive at the following claim, which I will refer to as X:



X = [Ticket number n1 will lose] & [Ticket number n2 will lose] & . . . & [Ticket number n100 will lose]



What is X saying? X is the claim that Ticket numbers 1 through 100 will all be losing tickets. If one is epistemically justified in holding any particular [Ticket number n will lose], then Bonjour claims we are, on this account, epistemically justified in holding the conjunction of all particular [Ticket number n will lose]. Thus, we would be epistemically justified in holding X.



But, X is contradictory to the initial information about the game, namely, there is 1.00 probability that one of the 100 tickets will win. Given that fact about the game, X is both justified (through this conjunctive process) and unjustified given the contradiction. This is taken to be a serious problem for a probabilistic satisfaction of the requirements of knowledge.



I don’t, however, agree to what is happening here.



The mistake is thinking that logical inference is wholly analogous to the process of probabilistic inference. For example, at least in classical thought (set aside fuzzy logics, etc.), A is either true or false. There isn’t a degree in between. [Ticket number n1 will lose] is dealing in degrees and probability. Yes, it either true or false that [Ticket number n1 will lose], but the probability that it true or false isn’t binary, it comes in degrees, 0.99 in this case. Because of this, probabilistic inference doesn’t appear to inherit the kind truth functionality we see in logic. Forget the conjunctions, they are the wrong tools for this problem.



While I agree with these moves:



A a.k.a. “A is true”

B a.k.a. “B is true”

A & B a.k.a. “A is true, and B is true”



I can’t agree with these moves:



[Ticket number n1 will lose] This has a 0.99 probability, thus belief is epistemically justified

[Ticket number n2 will lose] This has a 0.99 probability, thus belief is epistemically justified

[Ticket number n1 will lose] & [Ticket number n2 will lose] This has a 0.99 probability, thus belief is epistemically justified



[Ticket number n1 will lose] & [Ticket number n2 will lose] does not have a 0.99 probability.



Note that at the last stage of the argument, we are doing math when infer that the probability of X is 0.00 – that’s how Bonjour could arrive at the contradiction in the first. But, I can infer the probability X, then why can’t I also infer the probability of [Ticket number n1 will lose] & [Ticket number n2 will lose], which is 0.98. Clearly, the conjunction of these two beliefs falls below the threshold of satisfaction required for knowledge. Surely, there is no contradiction or obvious absurdity that arises.



Granted, all this is not to say that logical inference (such conjunctions) have no meaning in a probabilistic account of knowledge. Logical inference is just awkward when working in a theory based on probabilistic satisfaction of the requirements of knowledge.













Class – Bonjour



Externalist about justification or about knowledge. Most have externalist theories of knowledge (rather than justification).



Evidentialist Externalist say that justification must consist entirely of mental states.



Basic Externalist – you do not have to have access to that which makes you justified, i.e. the justifiers. Rather, you have to be in the right relation to the external world.



The externalist is represented as a pretty strong view by Bonjour, namely regarding the law-like connection, between the fact represented by your belief and your belief itself. For example, I can judge there is a water bottle in front of me because it is externally justified as literally being there in front of me.



What Goldman says, you have to have true belief, and you have to have brought it about by a reliable process. Thermometer. Belief has to be true with a great probability.



Why be an externalist? The focus has, to some extent been on the regress problem, but also on others, such as the Animal and Children problem.



Animals and children problem. The way we use the word the word “know” with Dog, as in “the dog knows the bowl is in the corner.” It has a propositional attitude. That makes total sense to us. Similarly, even for quite small children, we say that “Susie knows that mommy is home.” We ascribe to both of these “knowledge.” We don’t normally think that these entities have justification available to them, at least not the kind of justification that the internalist requires.



The regress problem is a problem for internalism, and it isn’t supposed to be a problem from externalists. Others include: “how do you deal with stored knowledge?”



Internalism- it is a necessary condition for having knowledge or for having the right kind of justification for knowledge that you have access to that justification.





Regress-



Foundationalist answer: Non-inferential belief, or basic belief, or some belief that has intrinsic merit on its own. These might include a priori beliefs.



Coherentist answer – belief is justified because it fits into the best account of the web of beliefs. The Ptolemaic model eventually became, overall, not the most coherent system, when compared to the Copernican model. What coheres best with our overall set of beliefs?



Back to Basic beliefs, a Puzzle:



How do you know the watch in front of you is Silver? Don’t you already have to know what silver is and what it is like when objects look Silver? Don’t we have to have previous knowledge about this? This seems to be a worry for the foundationalist perspective. The externalist point seems to solve this problem (at first glance).



The clairvoyant’s ability to recognize that sensation, the ‘voyance,’ can only be justifiers once we have a number of concepts about that object of voyance. Mere sensations or intuitions, without knowing how to apply concepts, how do you know how to describe those sensations or intuitions? This is a worry for foundationalism. In order to play that foundational role, don’t you need something else to describe it?



Can Johnny the Clairvoyant who doesn’t know he is Clairvoyant claim to have knowledge? No. Does it he have knowledge, yes. He just can’t say he does.



The Duty/Utility mixup is bad.





There is a difference between saying Norman has knowledge (as we look down upon him), and saying that knowledge must be connected to action.



We must distinguish between:



Whether someone knows?

Whether they know that they know?

Whether they have the right to claim they know?

Whether someone should say they know?

Whether we should say they know?

Whether someone is being epistemically irresponsible?





To know something directly, you know it without inference. Basic beliefs, of externalism, are directly known. Internalism holds that we need direct access…?



As an internalist, you have to appeal to beliefs that you are conscious of or you formed in the past. You don’t remember those times in specific. You have to be able to explicitly lay out adequate justification, or itisn’t knowledge.



What about ordinary people’s knowledge? They can’t make it explicit. Do they not have knowledge?



Coherentist doesn’t need to be crazy about having everything so explicit.





Foley



Pascalian wager (direct) vs. Indirect pragmatic (moral) considerations

Indirect- how much research or consideration should we give in forming a belief? How important is that belief? Sandwich vs. Heart surgery – I should spend more time investigating one over the other.



Internalists need to be able to answer: How much investigation is required?



Getting out of the infinite regress:



We can claim that eventually we don’t have a justification, but it is okay. (I think of this as special justification, but then we have an incompleteness problem).



We can also see if our beliefs aren’t leading to practical problems for us. Justifying by saying, “it practically worked.”



Treat the method (of coming to believe something) as the ‘best explanation.’



I’m fine with keeping the standard of justification for knowledge very high. But, I don’t see why we can’t have fairly low standards for saying one merely has justified belief in certain contexts. A context in which I have to “tell you” what I believe, well, don’t I have an obligation to give you an idea of the strength of my justification.perhaps I might even be justified in a belief, but when asked about it, I might not respond with what I believe because I know that justification is so low that it doesn’t merit me communicating it to you.





Infintite regress – our minds are finite. It seems that we have to be justified witout access to that justification (not internalism), and some non-internal thing justifies it, and it is external.



Unjustified regress



Circular regress



??? something





Fumer?



Epistemic claims may be expressivist/emotivist/non-cognitivist. If so, there isn’t a normativity, right?





Schaeffer



Consider a brain in a vat that is consistently and systematically confused, but has every piece of evidence that we do. Is externalism somehow wrong? The brain in the vat seems to have the same kind of evidence (data), and so is this an internal justification, as clearly there is no external justification.



When I claim someone else has knowledge, it means that if I were in their shoes, I would certainly have the same belief.





Williams



5 features of belief

    Beliefs aim at truth (what does that mean?)

    Beliefs are basically assertions

    Uh, beliefs are assertions of your belief being true?

    Factual beliefs are based on evidence

    Beliefs are explanatory?

The claim that “I believe that P, but P is not true” is not a technical contradiction, but it does seem paradoxical. Is that really a belief? Is that a emote, in which I “want P” even if it isn’t true. Or maybe, I continually find myself ‘acting as if P’ even though it isn’t true. Or, maybe it isn’t simultaneous, it is sometimes I believe P, and sometimes it is not true (and I don’t believe). Or, it may be just an unjustified belief that you know is unjustified.

Of course we can be insincere in our beliefs.



Hieroynmi

Dispositional sense of belief.

We have beliefs we don’t talk about. We recognize we have it dispositionally. There are other beliefs we don’t recognize that we have dispositionally.

E.g. – There is not a 3-inch purple monster on the table.

I’m not acting like there is a monster on the table. I’m not trying to look at it. I’m not acting surprised. My not having that belief shows up in my dispositions.

We have lots of pre-reflective beliefs (ready-to-hand).



Settiya

Can’t choose to be in a state, and belief is a ‘state.’



We act on beliefs. Focusing on assertions of beliefs seems to miss the point. Beliefs tend to respond to evidence.



Williams

Because belief is aimed at representing truth and reality, we form beliefs exclusively about what we take to be true, and thus we cannot take it to be true or choose to be true.

Internalism is sometimes linked to deontic standards. And, it seems that if you are a responsibility to have certain beliefs, we may need to assume that they are free to choose those beliefs.

Even if you wanted to believe X, you’d somehow need to already commit yourself to that the truth X before you could really get yourself to belief X. You don’t seem to get the essence of belief if you think of it as an action in your control.

Brower wants to develop this position:

Can the skeptic decide to belief? Can he really only ‘act as if’ the external world doesn’t exist, but really believe that there isn’t an external world? Or, is it by his systematic actions that he should be said to believe in the external world?

If a lab assistant says there is water in the flask, and I want my plants to look good, and I’m not sure enough about the claim that water is in the flask, can I choose whether or not to believe there is water it in, and that is part of why I don’t water the plants with the flask?

Internalist is right that we believe without thinking about it. However, when we are being serious about, can we pull back from the evidence and say “I’m not going to believe that?” We can agree that when we believe we are making a commitment.



You can’t control desires, but you can form intentions about what you will do.

Beliefs are a lot like desires. We don’t seem to have much direct control over them.

Ways to be in control of beliefs:

Skepticism, Wife adultery example, indirect control, and compatibilism.

Compatibilism – the beliefs that are rational and in some sense voluntary are those that are brought about in the appropriate way.

Alston doesn’t seem to refute the long-range control.

Foley and Kelly



Propositional attitudes, world to mind, might have a representational information state. We test to see if they are successful by seeing if the world really is the way they are represented. The other kind of information state might be a “goal directed” state, such as a desire. The way to be successful on these is to see if they have impact on the world, and adequately changes the world or the world ‘just is’ in a certain way (we can want things we can’t or don’t want changed) as the person meant.



Do practical considerations matter?





Standard Response – ways to bring beliefs about. “Turning the light on” in a bet about believing the light is on. Pascal’s wager, and indirectly bringing it about through practicing and acting as if, so as it condition.



Of course, we can have indirect control over our belief (turning on light example). Kelly makes a point about the basing relation.



Tony telling me that the Emancipation was signed in the 19th century is the basis of me coming to believe it. Not the fact that I told her that the Emancipation was signed in 1863. Nor would my own inference be that.



If A causes B, that does not mean that A is the basis for B. It has to be the right kind of causation.



There is an inferential basis available, and there is a testimonial basis.



Turning light off example. I can’t will myself to believe the light is on when it is actually off. But, when I turn the light off, and the light goes off, then I can believe. My throwing the switch is not the basis, however. We can manipulate our belief indirectly, but what directly caused me to believe that the light is off is not the flicking of the switch, but the perception (and the evidence) that the light is off.



The basis, on Kelly’s view, of belief is good ol’ fashioned epistemic justification.



Beliefs can’t be “based” on practical consideration on Kelly’s view.





Kelly – regret is had on a basis. The basis for regret cannot be something that would be a mere practical result of my having the regret. We can’t regret because we believe “it would be good to regret for this reason.” Regret is like belief in this regard.



Can one desire to like Eggplant at will? Do we have full, direct control over our desires?


Is there a direct desiderative voluntarism?







Intrinsic value vs. Extrinisic value.



Intrinsic value does not have instrumental value (usual thought). It has value in itself. Not only isn’t it an instrument to something, perhaps it doesn’t get its value from being a part of a valuable whole. ??



A priori argument: if nothing has intrinsic value, then nothing has value. You can’t beat the regress without some intrinsic value backing up that chain of instrumental values.



It seems hard to grant that anything has intrinsic value, other than intuition.







She should have said as a virtue theorist:



The good life is the reflective life. We should be rational, be aware, ponder the nature of things, asking questions, etc. In doing that, one comes to care not just being reliable (like an animal), but also knowing about being reliable (internalist justification). You want to be a reflective person that not only have a reliably formed knowledge, but also second order knowledge (knowing that we know something), and other reflective capacities, and being able to share knowledge with others in the community. We want to be able to get assurance in our testimonies. Eric and I can both participate in a community as reflective members of the community. Eric can trust me, is aware that I have knowledge, that I’m not merely a thermometer.



Is knowledge an epistemic goal?

Is is intrinisically valuable (or merely instrumentally valuable)?

It is valuable in every instance?

In what makes instrumental knowledge valuable a thing which is intrinsically or instrumentally valuable?





The Moral Realist’s Speech Act Thesis: Some moral discourse is assertoric.



This seems to be a defense of cognitivism. In at least some cases, moral claims are not mere expressions of attitudes, and they are not open to a non-cognitivist account, but rather at least some moral claims (many of, in fact), i.e. our speech acts of declaring moral claims, are true or false.



This is what my post was about, apparently. Be didn’t go far enough, and should have been more limiting in what counts as a satisfactory moral realist theory.



The Moral Realist’s Alethic Thesis: The contents of some predicative moral claims are true and, if the contents of such claims are true, then they are true in the realist sense.



Russellian proposition: an arrangements of things in the world.



“The dog is fat.”

There is a property of fatness. There is a dog. They are out there in the world. The proposition, “The dog is fat” is about the dog and the fatness being connected, literally, out there in the world. The proposition literally contains the objects in the world. The ‘truth-maker’ in this account ??



Otherwise, Propositions are a mode of a way the world might possibly be.

Truth-maker is separate from the proposition on this theory.



Correspondence theory of truth. Fact that corresponds to the proposition to make truth.



He rules out highly deflationary theories of truth. Such as, “to say that something is true is merely a redundancy,” e.g. Sentences that say “that is true” are like pronouns for the thing which they refer to as being true. Another deflationary theory would be (Quine’s): P is true, there is a hidden disquotation, they are just making a metalevel claim about some high level thing?? “P” is true iff P is true. “P” is true iff P. It is a device of disquoting. It functions in our ordinary language as a way of talking about what someone else said in a metalanguage. Truth isn’t a real property out there in the world, on these views.



The contents are really true in a realist sense, on Cuneo’s view. Moral language expresses something that is rich, and tells us that there are facts.



The Moral Realist’s Ontic Thesis: There are irreducible moral facts.



The behaviorism example is NOT about Skinner, etc.



“Eric believes there is water in the fountain” is reduced to a set of behaviors which indicate it, such as “if he wants water, he drinks at the fountain” – but, notice that “want” is psychological, and it can’t be described in behaviors, so we can’t reduce psychological events to non-psych events.







Nihilism – error theory

Expressivism –

Traditional views

-There isn’t even a minimal sense in which moral claims can be true. Full blown non-cognitivism

Non-Traditional Views

-Minimal - Quasi-realism, etc. there is some truth to moral discourse, but it is very -deflationary

-Maximal

Reductionism –

There are moral properties, but they are reduced to other values/properties.

Utility seems that way. X is right if it maximizes happiness…..





Platitudes in epistemology – what epistemic realism is…
