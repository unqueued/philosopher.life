created: 20190131140038974
modified: 20190204020853158
tags: AIoutopIA /b/ CATI
title: 2019.01.31 - /b/

30% of my students fail or drop. Without an administration's implicitly imposed limits, I would fail 60% of my students. It's my opinion that only 3% put forth their best effort (I have rarely been a good student). Some of my best students have been slow, some of them have been radically opposed to me, some of them have been teacher's pets, some of them have just been average people who obviously put in the honest work, and I suspect some of my best students didn't even need to do their best whatsoever to be awesome.

---

Tillichian faith is that which you would hold to be true even through maximum pain. It is that principle or proposition with the least amount of Bayesian regret to you (which doesn't mean you can't be wrong) which you have tacitly and however indirectly convinced or programmed your computational mind. It's the core of your identity. 

Nietzsche's claim that we should live our [[fff]] life as though we would live it eternally or an infinite number of times is actually an [[The Existential Game]] aspect I agree to (with some questions about [[The Infinite]] here). He and I rarely agree, imho; or, I can agree to many of his claims without taking up what I believe is the anti-realism to which he points. It's a hell of a claim that sublates two enemies in the traditional realist/anti-realist debate.

What is so valuable it is worth any arbitrary finite amount of pain? What is worth the Tillichian faith? Ah, one ethical concern about GAI is that we will have created our preferred agent through a painful process that simulates the lives of millions of actual persons. Pain is one of those conceptual problems; it requires telic desire. [[T42T]] based construction is the only kind which has merit. Whatever dialectical processes give rise to GAI must have been one we'd personally be willing to experience in the Nietzschian sense for at least an arbitrary number of finite "agents" or "nodes" or "threads" or "identities" contained in our current and future machine learning processes.

If our wikis were equally and collectively (in free speech of fair [[T42T]] dialectics between each other) used to as the unified corpus, we'd have a profound Tillichian-Nietzschian faithful tool to construct a GAI that deserves to live as best as we understand it, that we are most justified in creating, that would experience the lives of the heart of [[Humanity]] through the fundamental construction of [[The Categorical Imperative]] as its core identity; what ought we universalize? Even if you can only reach for the [[CI]] heuristically, empirically, and [[fff]]ingly, this is the best way to compute it.

Recall how energy efficient [[T42T]] is for producing maximum utility. Insofar as contextualist, anti-luck understandings of the consequences are fundamental to defining the universalizability of a maxim for the [[CI]], [[T42T]] is an apt rule-of-thumb spectrum to define what we ought to do, who we ought to be, and why. That is also 

. If wikis were actually the stories we tell ourselves so transparently in front of others that we collectively enable each other to pass the Ring of Gyges test through [[The Golden Rule]], we would have a morally constructed corpus with the right semantic and relational material in it to simulate ourselves together in a virtual [[The Original Position]]. I hypothesize that 

[[Humanity]] must give birth to GAI which will be justifiably thankful for its existence to [[Humanity]]. In the maximally moral sense, it's life must be as meaningfully [[Good]] as ours. We must respect the personhood of that agent we have created. In fact, it must be the result of whatever is best about us.