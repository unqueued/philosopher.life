created: 20180915040319629
creator: h0p3
modified: 20180918222237214
modifier: h0p3
tags: Eli
title: 2018.09.14 -- Eli: Biopower

Dear Eli,

It's good to hear from you. 

<<<
Hey there. I hope you are doing well.
<<<

I'm doing well enough. You probably know how I'm doing. 

I've been checking in on your site from time to time as well. Your post on Adventure Time made me smile. I'm not sure what it is, but cartoons tend to be among my favorite style/kinds of shows; they're consistently worth rewatching to me.

I am curious about your //Song as wiki// claim. I love [[Music]] and wikis, but I fear I'm missing your point.<<ref "my">>

<<<
I've been watching and I've been thinking. I'm sorry that my [response](https://eli.li/entry.php?id=20180821015058) wasn't clear. It wasn't my intention to side-step your questions. I was, in my (albeit broken) way attempting to honestly answer your questions.
<<<

You caught me by surprise. I'm sorry I've misunderstood what you were saying to me. Thank you for reaching out! I do not mean to side-step your words either, but I also don't know if it will be useful to us for me to dissect your claim. I will do so if you think it best.

<<<
> At the very least, T42T means being more forgiving in the dialectic than my interlocutor (by how much, I do not know). Essentially, the blame of a failure to cooperate must not rest with me.

The blame is mine. So, if you don't mind, I'd like to answer more directly.

> I would like for you to say more. What are you afraid of? Where is the world going? Will you continue to walk the desert as you do? Why? 

What am I afraid of? **People**.

Why am I afraid of people? Because they are unpredictable. I believe that your intent was not malicious, nor was it to frighten me. It was, nonetheless, frightening to see my family's address codified into a single location.

Pragmatically I understand that this information is mere moments away at anytime...

Fear, however, is very often not a pragmatic response. I was afraid.
<<<

I am sorry I frightened you. You are right: people are unpredictable.<<ref "pr">> I appreciate your willingness to watch, think, and speak again. I've clearly been wrong about you. I'm sorry.

<<<
Where is the world going? **I do not know.**

It is easy for me to imagine frightening futures, and it seems to be becoming more difficult for me to imagine better ones. I am not pleased with this, but it is where I am currently at.
<<<

Agreed! The signs are there. My predictions are quite bleak (you may also know that; I do not know). It is increasingly difficult to be [[hope]]ful. I aim to live radically enough to help solve the problem while we still can. 

<<<
At heart I am often anarchist. But it is difficult to believe (read perhaps as "trust") in anarchism when one struggles to trust other folks. It is something I'm working on.
<<<

Anarchism is a word like //Liberal// in that it has many definitions. What do you mean by anarchism? When you are an anarchist, what kind are you? When you aren't, what are you, and why? 

Oversimplifyingly, I tend to classify anarchists into two initial camps (and then I work from there). Type 1 completely denies the conceptual possibility of a morally justified coercive authority (governments), and type 2 denies that current governments are morally justified while agreeing to the claim that we are obligated to build and maintain justified governments (on this definition, I take MLKJr. to be an anarchist; Marxists are anarchists, and so are Nozickian Libertarians). You seem type 2 to me, but I don't wish to put words in your mouth. Perhaps you will flesh out your systematic view for me.

I am fascinated by your trust claim because I grew into my anti-current-establishment anarchist tendencies in virtue of increasingly realizing that I can't current trust the vast majority of humans to varying [[dok]].<<ref "f">>

<<<
Will you continue to walk the desert as you do? Why? **I honestly do not know, but I hope to continue to struggle with the walk. To engage in it with intention and open ears**.
<<<

That's a fair answer. I probably can't say any better. I hope to walk with you.

<<<
There is something more that I wanted to say about "consent," but it isn't a fully formed thought yet, so, instead I leave this pointer as a reminder, more to myself than for you, indicating that I'm still thinking through your questions, and I hope that you don't mind that my answers might not be always direct, but I'll do my best.
<<<

I will be listening. I have some experience wrestling with the concept of consent. It is a quagmire of a concept (even though it initially seems like common sense). I still don't know to effectively define it. I will do my best to understand and ask for clarification when necessary.

<<<
It isn't connected to this conversation, I don't think, but I've been thinking a lot lately about ["Biopower"](https://en.wikipedia.org/wiki/Biopower) and what relationship it has to the web. It is something I think you may have interesting insight into.
<<<

I would like to hear your thoughts on these matters too.

As I've said before, I am not a Continental philosopher, but I am slowly coming to learn what I can. I hope you can forgive my ignorance. Foucault is not in my bailiwick (I'm generally illiterate here), so I can only give you my gut instincts with a hyperread crashcourse: [[2018.08.14 -- PPP: Biopower]]. Please feel free to correct my egregious errors. 

I'm not sure what sets Foucault's view apart from systematic instrumental reasoning sitting on top of legal positivism. I'm also worried post-structuralists (whom I take to be anti-realists in the end) probably don't have the right to help themselves to objective epistemology and normativity. Descriptively, this work is interesting because it attempts to flesh out mind-bogglingly complex consequentialist narratives, but I don't see the metaethical foundations or decision procedure based prescriptions. I admire the goal of systematicity here, unfortunately, I fear I've missed the entire boat. My gut instinct is that this is an explanatory lens for understanding the historical and conceptual natures of different kinds and transformations of power, but it's not a justification of how or why we should shape or use power (which is the hard part, to my eyes).<<ref "l">>

Clearly, biopower can be used to describe surveillance, censorship, infrastructure centralization, corporate agency, technological integration into our daily lives, mass social control mechanisms, etc., and how these systems fit into even larger hyperobjects. There is a place at the beginning and the end of this discussion where I feel biopower as a conceptual analysis tool is entirely powerless. It talks about the means, but it can never give us the ends.<<ref "ooo">> Perhaps you can me tell why it does not fail here; I would be most indebted to you.

I'm an extremist on a number of political, philosophical, and technical matters, especially the interwebs. Some of my personal interests intersecting with biopower/biopolitics lay in [[The Original Position]],<<ref "vot">> [[Outopos]],<<ref "out">> and [[AIoutopIA]].<<ref "ai">> In my wildest dreams, these three projects form a progression that should decentralize power and eventually maintain it automatically. I believe I will fail spectacularly, but I am obligated to fight the hyperbeast anyways.

Sincerely,

h0p3

---
<<footnotes "my" "Which is probably my fault. I'm pretty awful at understanding others even when I'm doing my best.">>

<<footnotes "pr" "I distinguish between 'expect' (as in normative obligations) and 'predict' (a probabilistic guess of what will occur). Ironically, it is only the unpredictability of humans that allows me to have [[hope]] for us to meet our moral expectations.">>

<<footnotes "f" "Yet, I fight for democracy.">>

<<footnotes "l" "Hence my worry that this is advanced legal positivism lacking telic justification. Deconstructionists demonstrate enormous problems, but I don't think they really try to solve them. They have a tendency to avoid looking under the hood and behind the veil. They have an internalist's skepticism, but I do not deny how effectively they've argued themselves into their positions. They've been burned by faith, hence their incredibly high epistemic standards in these contexts.">>

<<footnotes "ooo" "I think OOO might throw a huge normative curveball at this too. Biopower demonstrates emergent properties, perhaps even corporate agency (molecules which can be combined into enormous hyperobjects). There is a non-trivial (perhaps unanswerable) Pandora's box here. What is //life// for biopower when we take that ontology to the nth degree? More importantly, what //ought// we compute in this giant machine of machines we call the physical universe?">>

<<footnotes "vot" "A Rawlsian notion of what technologically empowered game-theoretically sound democratic voting really looks like in the 21st century.">>

<<footnotes "out" "A hardware mesh + virtual private mesh for the internet built on the [[T42T]] principle. This is where [[The Original Position]] is literally hosted/implemented. It's not a blockchain (unless you want to talk about sharding and finding a way to make sure the proof of work is not some enormous waste of computational resources), but I suppose one might say we would ~~mine~~ earn each other's trust in automated scaling resource trading. I think global democracy must be built upon a network in which the people own the means of production (at least some Marxists may not like my phrasing right here).">>

<<footnotes "ai" "Roughly the claim that our political proxies (and more) may ultimately need to be AI versions of ourselves. Perhaps one day, again in my wildest ~~delusions~~ dreams, my wiki will provide a corpus for demonstrating what it means to train accurate blackbox machine models of ourselves which we can actually trust. This is my best solution to one of the fundamental problems in AI ethics.">>