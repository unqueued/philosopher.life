created: 20180518132049132
creator: h0p3
modified: 20200221045805505
modifier: h0p3
tags: [[School Notes]] Tulane
title: 2013.02.20 - Moral Psych: Week 6 Reading Notes

Moral Intuition = Fast and Frugal Heuristics? - Gerd Gigerenzer


Social pressures outweigh our moral intutions

Default rules oughtweigh moral preference.



Heuristics bear heavily upon (even if they don’t replace) moral deliberation.



Pg 4. – Adaptive Toolbox, Ecological rationality, and Design of heuristics and environments.



Heuristics are context-sensitive, embedded in social environments. Descriptive, not normative.



Fast and Frugal moral heuristics seems to be akin to rule utility (particularly when we take into account the design of heuristics because we expect the population will perform better actions in virtue of the heuristic rather than from moral reasoning and moral motivations).



Heuristics can (1) explain moral action and (2) modify moral action



Heuristics exploit human brains.



3 hypotheses:

* Moral intuitions are moral heuristics

* Moral heuristics are the same kind as non-moral heuristics

* Moral heuristics are generally unconscious

Methodological implications:

* Study social groups in addition to isolated individuals

* Study natural environments in addition to hypothetical problems

* Analyze moral behavior in addition to self-reports



Bail study – pg 13

Binary search tree – frugal and fast.



Rationalist and nonrationalist theories of moral judgment. Rational says reasoning precedes moral intuition (a product of reasoning), while social intuitionism sees reasoning as post-hoc explanation of our moral intuitions.

Heuristics point out a distinction between unconscious, heuristic reasons and post-hoc reasons.



Heuristics seem like always-second-best prescriptions me. Theoretically, there seems to be a better answer. Perhaps practically, it is the best answer, or rather it is a stop-gap until we figure out how to get to the theoretical answer.

Prescriptive heuristics are more like institutional design, not really a decision theory in the moment.

Simplistic genetic algorithms solving game theory problems. We don’t know precisely why it works, but it does.





Fast, Frugal, and (Sometimes) Wrong - Cass R. Sunstein

Good moral heuristics are complex

* Rule consequentialist makes sense of heuristics

* Consequentialist is broad, not necessaril utilitarian

* Not all folks are consequentialists

Moral heuristics may not functional well.



Moral Heuristics and Consequentialism - Julia Driver and Don Loeb

“While following the heuristics can lead to success, attend-ing to them may well lead to failure.”

Hard to show that unconscious reasoning is actually reasoning at all. You can describe it as such, but it doesn’t seem like it is really any sort of deductive process. It isn’t clear.

---

If the “emotional dog” wags the “rational tail,” and essentially if we aren’t really employing any actual reasoning (except post hoc, which is rationalization and not really reasoning at all) in our moral judgments, are normative theories which rely upon rational moral judgments undermined and implausible? Even if these normative theories aren’t undermined, is accepting this perhaps Humean and social intuitionist model tantamount to denying that we are moral beings?

The lawyer’s closing argument example intensely reminds me of virtue theory, particularly the virtuous perception, sensitivity, and that capacity to pick out what is morally salient or relevant in circumstances where others cannot. This virtuous perception or sensitivity seems to be a set of implicit, impulsive, unconscious, non-cognitive (many virtue ethicists would not be happy with my qualifier – I’m looking at you, John McDowell), attuned to the context, and intuitive snap-judgments which guide the virtuous agent. In contrast, we the vicious haven’t trained and adapted our sensitivity and dispositions appropriately. The somewhat virtuous intuition of the lawyer is trained and habituated, oddly opposing some of her conscious and educated habits, and her affective responses steered her correctly even where her explicit reasons didn’t. Doesn’t virtue theory look more and more enticing from the perspective of these kinds of examples? (Ah, I wrote this before I got to the section on Aristotle. Not that anyone doubted Aristotle’s genius before, but I am continually amazed at how much Aristotle anticipated. The author is guiding us well! I should note that on page 13, Railton takes up a particular position on the relationship between the virtuous agent’s attunement found between intuition and reasons at hand. Hursthouse, just as an example, might give a different account of this relationship. The matter is up for debate, I think.)

I think one of the fundamental (cognitivist) questions at stake here is this: Can one be said to be “reasoning” or acting upon good reasons in any sense that isn’t explicit and conscious? Can one make inferences and have good reasons for something even if one isn’t able to articulate those reasons and even if such inferences don’t exactly mirror the kinds of usual, explicit inferences we make? If so, there seems to be a middle ground or path for the cognitivist wherein these snap moral judgments have a semblance of reasoning going on, even if that process is very different from the sort of explicit and articulate reasoning we consciously employ.

As with that fundamental question I’ve asked, sections (7) and (8), on warrant, remind me of how many significant epistemology problems bear upon and intersect with the issues we are dealing with in this article. Railton’s unique version of the traditional epistemic regress and likely foundationalist solution (a foundation of intuitions) is a good example. Since I lack adequate answers to so many epistemological worries, I feel like I’m standing on quicksand. Railton distinguishes warranted attitude from warranted judgment, attitudes being intuitive, and judgment being cognitive, explicit reasoning. Similar to my previous question: Should we take responses based upon emotions and attitudes as having the same valid guiding force, both in an epistemic and in an ethical sense, as explicit reason?

Is affect or “feeling” really the natural place for Kant to look for an account of the direct “mental attunment” to value found in the “moral feeling” (CJ 5:267-268)? I’m may ask Sensen about it tonight.

In Section (10), Railton describes two systems, and essentially tells us that the affective system has primacy. Affective responses are potent, shaping our higher order cognition and beyond. As hinted in the beginning, my worry is an incompatibilist + cognitivist worry: Are we morally responsible for emotional, affective, and non-cognitive reactions beyond our immediate control? Railton seems to be pointing out that our affective system is complex, rich, flexible, adaptive, and not as hard-wired, simple, crude, and “point and shoot” as might initially think. But, is this really enough to cross the gap into moral responsibility? It all seems too indirect to me.

Damnit it all, I don’t know how to define cognition or rationality anymore. I don’t have a clue.

S16, Causal structure of act confounded by moral assessment

Knobe, Causal/Moral Assessment Examples,

Boardroom: judge intentional harm in the first scenario, and unintentional help in the other. How to explain this?

Time to employ some Post Hoc Reasoning up this bitch: We have a duty to not harm the environment, a duty that presumably is known by the VP. By saying “I don’t care about harming the environment” and acting upon that maxim (of sorts), he has done something wrong. His intention was not to follow the moral law, whether or not he failed or succeeded is a matter of moral luck to some extent. In Boardroom II, he’s not violating the duty necessarily. Perhaps there is a duty to help the environment, but that is different.

Asymmetry between helping and harming.

Harold’s Bus example, Bus is like switch not footbridge, in terms of our intuitions.

I’m not sure if all my intuitions are acceptable. Some might be wrong. How do I know when they are wrong? I suppose when I get to think about them. Intuitions in the split-second decision aren’t questioned really. What I would do and what I should do are different things. Intuitions tell me what I would do, and perhaps some of the time, that split-second would do’s tell me something morally salient, and sometimes they don’t.

Marred by all these situations. No choice is a good one, but perhaps there is a right one. Should you feel guilty for doing the right thing, even if it is a bad thing?

Railton claims the difference between Bus and Footbridge is a social, empathy one. Where others on the bus will exhibit more empathy that in the footbridge example.

It seems to me that the examples aren’t equal. My pushing the fatman doesn’t guarantee he dies on the bus example. It does on the on the footbridge.