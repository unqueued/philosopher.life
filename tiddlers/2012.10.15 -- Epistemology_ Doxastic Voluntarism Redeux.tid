created: 20180518001037966
creator: h0p3
modified: 20180518001138933
modifier: h0p3
title: 2012.10.15 -- Epistemology: Doxastic Voluntarism Redeux

Belief is integral to moral choice and action. As such, to take up one doxastic foundation over another will have a lot of impact on which moral theories (and their variations) will sink or swim, and such a selection will also outline the limits of these theories. The issue of doxastic voluntarism seems especially relevant to moral theories grounded in a libertarian sense of freewill (which I wish to defend, as I can’t buy into compatibilism, but as you will see, I don’t know how).

I confess, my post goes off on a tangent, but I think it is a relevant and worrisome set of concerns.

Consider the classic ethics question: "What should I do?" I take it that however we go about answering this question (or ones like it, such as "Who should I be?"), our answer is a kind of belief or set of beliefs. If we are to fully deny any control over our beliefs, then it seems as if we do not have a choice about which answers we accept, deny, or withhold when we face these basic ethical questions. 

At first glance, this doesn’t appear to be a problem. We might not have freedom of belief, but we may accept freedom of action, where we choose whether or not we will act upon our beliefs or not. If we try to collapse the space between action and belief, and we deny doxastic voluntarism, then it seems as if libertarian freewill is jeopardized. 

But, when we open this space up, it seems as if we could satisfy freewill libertarians, as though our actions are still ultimately ‘up to us’ and moral responsibility can still be maintained. 
Action appears to be a kind of endorsement or commitment to those beliefs which motivate their corresponding actions. Freedom of action would mean that we are free to endorse or commit ourselves to our beliefs which motivate our actions. On this language, it does appear as if some notion of freewill can be packed into the concept of endorsement or commitment to a belief. 

I’m forced, however, to consider what it means to initially form a belief on this account. It is almost as if action is re-endorsing or re-committing oneself to a belief, but this time it is the kind of endorsement or commitment that is actually in my control. And, if action is the ultimate endorsement or commitment, then the original formation of the belief seems to be a weak or not very meaningful kind of commitment in the first place. We might be begging the question here, and we’ve inserted doxastic voluntarism into the freedom of action. Even if that isn’t the case, I’m not even sure what this is supposed to look like:

Say I have a set of ethical beliefs (about what I should do) that aren’t up to me. I then deliberate about whether or not I will act on those beliefs, about whether or not I will ultimately endorse or commit myself to those beliefs. On what grounds do I deliberate and make this choice? In particular, I’m worried that this choice is made from my beliefs. If it is based upon my beliefs, and I’m not in control of those beliefs, then how am I really in control over this choice?

Further, this deliberation is odd. It is like asking: “Should I act upon the belief that I should do X?” That requires a belief. Do we hit an infinite regress? And, if we don’t, do we have some kind of ab initio problem? I must act on some motivating force that is “up to me,” but it can’t be beliefs. What are they then?

Additionally, to choose not to act X on the belief that I should do X, or conversely, to choose to act X on the belief I should not do X, is almost paradoxical. In some sense, just as it might be paradoxical to say: “I believe X, but X is not true,” it seems very awkward to “act X, but at the same time believe I should not do X.” 

Can one rationally act against one’s beliefs? If you say ‘no,’ then it looks as if we might be bound to some weak version of psychological determinism (something unacceptable to most freewill libertarians). But, so far, it seems hard to believe that the answer could be ‘yes.’
Lastly, and to continue my worry about having a space between action and belief: if a belief is not efficacious (where we expect it to be efficacious), do I really hold that belief? Consider the following:

I might have beliefs right now that I’m fat and I shouldn’t eat unhealthy foods, such as pizza, for the foreseeable future (I have ample evidence for this). When I consider the question “Should I eat pizza?,” the answer is: “No. I should not eat pizza.” Those beliefs aren’t directly up to me on this account. Now, a proponent of free action would point out that I can still eat pizza if I really want to, claiming there is this space between action and belief in which I have the freedom to choose, and that space is what accounts for me going out and eating pizza an hour from now, even though I believe I shouldn’t. 

I feel like I can arguments which point out how there is supposedly space between action and belief, and collapse that space, such that my action is just pointing out those beliefs I actually have (with no space in between). Instead of saying that I chose not to act on my belief that I should not eat pizza, I would say that I simply changed my beliefs. Perhaps it would go something like this:

In an hour, my desire for pizza in particular will be profound. 

Presumably, this desire isn’t in my control. In this case, the desire is so strong that it influences my belief/answer to the ethical question regarding whether or not I should eat pizza. My desire is so strong that fulfilling it becomes more salient and valuable to me than other moral considerations (like my health). In that moment, it seems as if I would answer “Should I eat pizza?” in the affirmative, even when I wouldn’t otherwise. This change in belief is not up to me. And, further, my eating this pizza was acting from my belief that I should eat pizza. 

On this account, I do not see how my prevailing and most salient beliefs are not by definition efficacious in motivating my actions. I also don’t see much space between action and belief.
Anyways, as odd as it sounds, I’m hoping I’ve screwed up a bunch of times here and/or that I’m missing some important arguments. I’m very interested in having a theory of epistemology which is harmonious with a robust moral realist theory that includes libertarian freewill.
