created: 20161130225946533
modified: 20181115190624897
modifier: h0p3
revision: 0
tags: Retired
title: 2018.04.27 - Retired: The Good

//See: [[The Right]] and [[The Beautiful]]//

---

//The God of the Philosophers//


---

Moral. 

---

[[Freewill|Freewill]]

I've been honing, digging-for, and isolating the concept of perfection for a long time. Perfection is a maximal manifestation of the Good. To say X is perfect is to say X is a maximally good. But, we must ask, "good for what?" Good in itself, good instrumentally?

In //Searching for Meaning: Idealism, Bright Minds, Disillusionment, and Hope//, they claim:

Our illusions can become 

I don't think I'm seeing illusions. I think I'm seeing reality. It is not my depression that causes me to think the world sucks; it is the fact that the world sucks that causes my depression.


----------------------------

I’ve been considering for many years an odd problem (that seems to pop up over and over again). The problem goes something like this:

In any given circumstance, are we morally responsible for doing the “golden standard” right thing (such that everyone should do that) or something which scales to the particular circumstance, including facts about who we are (such that only we are should do it, but others may not be obligated in the same way)? 

Traditionally, the answer is something like the golden standard. What one ought to do in any circumstance is what anyone ought to do in that circumstance. I think Virtue, Kantian, and Utilitarian thought, as solid examples, really point toward a golden standard of right and wrong (there are exceptions in versions of these theories, but I’m generalizing). 

The problem is that it isn’t clear what we mean by the scope of a circumstance. How specific will it be? As we focus upon the scope of circumstances for moral responsibility, it becomes clearer and clearer that the golden standard just can’t be quite right, and we are pushed toward a “scaling standard” of right and wrong.

For instance, someone with a person with an IQ of 60 might not be able to figure out what one ought to do in a general circumstance, as perhaps it requires an IQ of 120. Can we really hold that person responsible for doing what is “golden” right? Surely not. Ought implies can, and “can” requires a rational ability to identify the right, and this person simply can’t. Thus, we not only can’t hold them morally responsible for not doing the “golden” right thing, but they aren’t even obligated to do that original golden right thing. O -> C is equivalent to ~C -> ~O. If you can’t, then you not ought. How does the moral philosopher (of any breed) make sense of this?

It seems that the circumstance was too general, and rather, we need to include the IQ of the person in question as part of the circumstance. Essentially, what the 60 IQ person ought to do in the general circumstance will be different from what the 120 IQ person ought to do in that general circumstance. The reason is that they are two different specific circumstances. So, in a sense, moral responsibility and “right and wrong” will scale, but we need not completely throw away the golden standard. The golden standard, however, appears to be reduced to particularism. Moral particularism, however, seems to be problematic for the generalization of any moral theory (although not necessarily defeating); we might worry that is spirals into a kind of moral relativism. 

Somehow, the golden standard seems lost. Some part of me wants to say: “given all the possible intellectual resources, what should one do?” That is the real golden standard, not the particularistic approach. Perhaps the golden standard looks like “the good” not the right. I’m not sure.

So, let us assume moral responsibility is scaling, and thus morality is scaling with specific or particularistic circumstances. Fine. What of it? Other old and weird issues seem to creep up, and I worry that moral responsibility might not even be real. Let me start with an anecdote.

Take someone who is a highly conditioned racist. I can look upon their life, and I see why they’ve become what they’ve become. Now, perhaps it is possible that the racist could employ their reason and (allow me to assume) libertarian free will to become not a racist (let us even deny direct doxastic voluntarism and assume it must be habituated, etc.). But, in all likelihood, the racist simply won’t. 

Is the racist responsible for being racist here, and what is the right thing to do for the racist? Racism might be “bad” (in the good/bad distinction), but it isn’t necessarily (and bear with me folks) “wrong” (consider the case of someone with a very low IQ). 

The scaling standard should force us into the shoes of other people. How would most people who were forced into the shoes of the racist (shedding their previous identities, and acquiring the racist’s identity and past) behave and choose? I think we would be no different. In fact, we should empathize with the racist’s racism. We should consider that person a victim in some very twisted sense. At the very least, we would hold the racist less responsible for being racist in this case, and maybe they didn’t do “as wrong” as someone who didn’t have such conditioning.

But, notice that we seem to be able to tell the same sort of story for any act of immorality, right? Why should we hold a person responsible when in all likelihood nobody else would have done differently in those exact circumstances, standing in the exact shoes of that person? 

What one ought to do in a particular circumstance isn’t necessarily the same as what everyone would do in that circumstance. That has to be the only answer the scaling standard can give to vindicate moral responsibility. But, it isn’t satisfying. 

In some weird way, whether we did the right or wrong thing just doesn’t feel “up to us” upon the empathetic scaling standard view. Even if it is up to us, it seems as though evaluating how virtuous or vicious a person may be just isn’t very relevant or meaningful because we wouldn’t be anything different either. Virtue and vice, right and wrong, and moral responsibility all particularize or scale so effectively that they seem to lose meaning.  

Even if the scaling standard maintains its robust moral realism, despite being particularistic, and we can maintain moral responsibility, and even if we could figure out what others ought to do (epistemic flaws in utilitarianism apply to almost all particularistic theories), it seems like we now actually have a good reason not the “judge” anyone else. Yeah, they did what was wrong, but you wouldn’t have been any better, almost nobody would. 

Morality and moral responsibility lose their bite.