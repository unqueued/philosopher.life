created: 20200112215656911
modified: 20200114034104086
tags: [[Antipleonasm Analysis]]
title: 2020.01.12 - Antipleonasm Analysis: GPT-2

!! Respond to the following gem:

<<<
If your objection is that GPT-2 doesn’t really know what it’s saying (I.e. it has no “model of the world,”) then I partly agree. You can see it get confused sometimes and switch its own gender, or refer to someone that doesn’t exist. But I think the way that you sample from GPT-2 matters. You can build a model of the world on top of GPT-2. It’s a probability generator; apply some rules to it.

The trouble with saying it’s “not really AI” is that we haven’t actually created AI yet. Every AI / ML seems to suffer from this same philosophical issue: you have to craft some sort of rules somewhere. For now, machines aren’t able to craft their own rules (but that is a field I imagine will become very important soon, and is a personal interest of mine).
<<<

I suppose there may be different kinds of knowledge, some of which may not require consciousness. Even conscious awareness of one's beliefs (including beliefs about justifications for one's beliefs) comes in [[dok]]. It may have some kind of model of the world though, but it's another leap to say it has [[SO]] modeling over models of the world (and yet another to say it has conscious access to such a thing). I do not see why fallibility and even the incoherence which may arise from probabilistic inference demonstrates that it doesn't know, but The Lottery Paradox points to an unintuitive result.

If we buy that epistemic justification can be entirely external (ultimately, at least part must be), and having internal reasons for why one holds their beliefs isn't necessary (although obviously radically preferred) for at least minimal knowledge (though, I'm willing to retract this low contextualist standard), then maybe GPT-2 does have knowledge of some kind (which, again, is not to claim awareness or [[phenomenology]]).

You'll have to tell me what counts as applying some rules to it. If it's just a matter of throwing functions on top, then maybe it's already meeting some trivial definition. The probability generator is a rule, and what kind of rule can we apply to it that would enable us to all of the sudden call it knowledge when we couldn't before? Perhaps there are many kinds.

Choosing its own rules, however sounds like autonomy (self-legislation). But, we are many, many steps beyond knowledge here. I am interested in that problem too.