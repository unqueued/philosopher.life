created: 20180518184347775
creator: h0p3
modified: 20191111020228258
modifier: h0p3
tags: AI [[Antipleonasmic Catholicon]] Quotes Collection
title: AI Quotes

<<<
I visualize a time when we will be to robots what dogs are to humans, and I’m rooting for the machines.

-- Claude Shannon
<<<

That is a positive claim for AI. Let me say, I hope so too. I'm not so optimistic because I just don't know enough about the nature of such a time or AI.

<<<
Artificial intelligence would be the ultimate version of Google. The ultimate search engine that would understand everything on the web. It would understand exactly what you wanted, and it would give you the right thing. We're nowhere near doing that now. However, we can get incrementally closer to that, and that is basically what we work on.

-- Larry Page
<<<

Why do you think it would "give you the right thing?" We're nowhere near establishing that fact either. Further, why should I believe that is what you are really working on?

<<<
The pace of progress in artificial intelligence (I’m not referring to narrow AI) is incredibly fast. Unless you have direct exposure to groups like Deepmind, you have no idea how fast—it is growing at a pace close to exponential. The risk of something seriously dangerous happening is in the five-year timeframe. 10 years at most.

-- Elon Musk
<<<

I am slow to agree. I do not know what I do not know. I can point to other aspects of computing and show how such claims would be rightfully considered outlandish. I am doubtful. I'll agree that AI will play a greater and greater role in the commodification of our species, and I'll agree it is weaponizable.

<<<
The upheavals [of artificial intelligence] can escalate quickly and become scarier and even cataclysmic. Imagine how a medical robot, originally programmed to rid cancer, could conclude that the best way to obliterate cancer is to exterminate humans who are genetically prone to the disease.

-- Nick Bilton
<<<

Sounds Asimovic. Humans, of course, can weaponize non-DAI and pose just as much a threat.

<<<
The real question is, when will we draft an artificial intelligence bill of rights? What will that consist of? And who will get to decide that?

-- Gray Scott
<<<

Unfortunately, we can't even effectively do this for humans. AI, as a minority work-horse will be enslaved. Insofar as it is DAI, it has the rights of persons though. I'm not convinced centralized power emerging from capitalism will treat their creation wisely.

<<<
We must address, individually and collectively, moral and ethical issues raised by cutting-edge research in artificial intelligence and biotechnology, which will enable significant life extension, designer babies, and memory extraction.

-- Klaus Schwab
<<<

I think this wiki is a memory extraction of sorts. It is obvious to me that power and eternal life are so important to the ubermench cult, especially the most psychopathic variety, that they will sacrifice us all for it. Until we can solve basic socialist considerations for humans, how could we possibly hope to reign in this insanity?

<<<
Some people call this artificial intelligence, but the reality is this technology will enhance us. So instead of artificial intelligence, I think we'll augment our intelligence.

-- Ginni Rometty
<<<

As it exists now, sure. But, why do you think it would stop there? Why do you think generalized AI isn't the ultimate moves we will be making?

<<<
I'm more frightened than interested by artificial intelligence - in fact, perhaps fright and interest are not far away from one another. Things can become real in your mind, you can be tricked, and you believe things you wouldn't ordinarily. A world run by automatons doesn't seem completely unrealistic anymore. It's a bit chilling.

-- Gemma Whelan
<<<

What makes you think we, as humans, aren't automatons? To what degree is there really a difference if I'm built on organics or silicon? Xenophobic, perhaps. You see the evil you commit against what is alien to you, and thus you are sure aliens will do the same. There is a profound kind of tribalism here which we've seen in science fiction for a long time.

<<<
You have to talk about 'The Terminator' if you're talking about artificial intelligence. I actually think that that's way off. I don't think that an artificially intelligent system that has superhuman intelligence will be violent. I do think that it will disrupt our culture.

-- Gray Scott
<<<

You cannot help yourself to that which is more complex than yourself. You cannot model the theory of AI's mind, and therefore you are in no position to make this assessment. Define "violence." Memetics has a survival of the fittest element to it, which even plays out in our everyday lives. Ideas are powerful forces in the world, the causes of wars, etc. Disrupt our culture without massive upheaval is an assumption that you haven't justified.

In games of perfect information, based on the assumption of psychological egoism, it is not clear to me that there is any grace, altruism, clutch sacrifice, or anything which would predict these creatures will be kinder. They may though. I'm just not in a position to make the judgment.

<<<
If the government regulates against use of drones or stem cells or artificial intelligence, all that means is that the work and the research leave the borders of that country and go someplace else.

-- Peter Diamandis
<<<

Someone else will do it if I don't, therefore I'm justified in doing it? Shit argument. That said, the prediction is correct, even if the moral expectation is not. This is an 'is/ought' naturalistic fallacy.

<<<
The key to artificial intelligence has always been the representation.

-- Jeff Hawkins
<<<

Representation "of what?" W5H it.

<<<
Anything that could give rise to smarter-than-human intelligence—in the form of Artificial Intelligence, brain-computer interfaces, or neuroscience-based human intelligence enhancement - wins hands down beyond contest as doing the most to change the world. Nothing else is even in the same league.

-- Eliezer Yudkowsky
<<<

If the human race survives long enough, then yes, this sounds about right.

<<<
Artificial intelligence is growing up fast, as are robots whose facial expressions can elicit empathy and make your mirror neurons quiver.

-- Diane Ackerman
<<<

And they have blackboxy minds for us; we can't generate accurate theories of their mind. We must solve the moral problem before there is AI. We must show such a powerful creature the best way to reason about the issue.

<<<
Some people worry that artificial intelligence will make us feel inferior, but then, anybody in his right mind should have an inferiority complex every time he looks at a flower.

-- Alan Kay
<<<

We would be demonstrably inferior in crucial respects. It would be beautiful though. I cannot deny.

<<<
Nobody phrases it this way, but I think that artificial intelligence is almost a humanities discipline. It's really an attempt to understand human intelligence and human cognition.

-- Sebastian Thrun
<<<

Ding, ding, ding, ding!! We have a winrar! All is philosophy.

<<<
A year spent in artificial intelligence is enough to make one believe in God.

-- Alan Perlis
<<<

I suppose it depends on how you define God.

<<<
By far, the greatest danger of Artificial Intelligence is that people conclude too early that they understand it.

-- Eliezer Yudkowsky
<<<

Preach, yo!

<<<
The sad thing about artificial intelligence is that it lacks artifice and therefore intelligence.

-- Jean Baudrillard
<<<

I do not know what I think of this sentence. I will have to review it further.

<<<
Before we work on artificial intelligence why don’t we do something about natural stupidity?

-- Steve Polyak
<<<

Define articial and natural for me, please. I think your argument collapses.

<<<
It seems probable that once the machine thinking method has started, it would not take long to outstrip our feeble powers… They would be able to converse with each other to sharpen their wits. At some stage therefore, we should have to expect the machines to take control.

-- Alan Turing
<<<

He clearly understood the nature of the beast deep down long before we did.

<<<
Artificial intelligence is the future, not only for Russian, but for all of humankind. It comes with colossal opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world.

-- Vladimir Putin
<<<

Power-hunger knows

<<<
The development of full artificial intelligence could spell the end of the human race … it would take off on its own, and re-design itself at an ever increasing rate. Humans, who are limited by slow biological evolution, couldn’t compete, and would be superseded.

-- Stephen Hawking
<<<

I'm of the opinion that organics will be harnessed. We will run out of metal and rare elements long before we run out of the ability to create biological computers. It's just a fact that one of these resources scales up better. Perhaps //The Matrix// was more correct than we give it credit, but instead of batteries, the useful parts of our brains will be growns as cogs in a greater engine.

Humanity aims to end itself by making something greater than itself. Tower of Babel though it may be.

<<<
Whenever I hear people saying AI is going to hurt people in the future I think, yeah, technology can generally always be used for good and bad and you need to be careful about how you build it … if you’re arguing against AI then you’re arguing against safer cars that aren’t going to have accidents, and you’re arguing against being able to better diagnose people when they’re sick.

-- Mark Zuckerberg
<<<

Power-hungry and direct beneficiary who clearly psychopathic enables the enslavement of others is telling us AI will be wielded for the good. And, it's not a particularly strong argument either. Ouch.

<<<
Why give a robot an order to obey orders—why aren't the original orders enough? Why command a robot not to do harm—wouldn't it be easier never to command it to do harm in the first place? Does the universe contain a mysterious force pulling entities toward malevolence, so that a positronic brain must be programmed to withstand it? Do intelligent beings inevitably develop an attitude problem? (…) Now that computers really have become smarter and more powerful, the anxiety has waned. Today's ubiquitous, networked computers have an unprecedented ability to do mischief should they ever go to the bad. But the only mayhem comes from unpredictable chaos or from human malice in the form of viruses. We no longer worry about electronic serial killers or subversive silicon cabals because we are beginning to appreciate that malevolence—like vision, motor coordination, and common sense—does not come free with computation but has to be programmed in. (…) Aggression, like every other part of human behavior we take for granted, is a challenging engineering problem!

-- Steven Pinker, How the Mind Works 
<<<

Pinker, celebrity that he is, is blindingly optimistic and maybe even naive. Why should he not like the world the way it is and where it is going? Blackboxes may well solve challenging engineering problems without our knowledge of it. Therefore, he does not have a right to help himself to his conclusion.

<<<
Any A.I. smart enough to pass a Turing test is smart enough to know to fail it.

-- IAN MCDONALD, //River of Gods//
<<<

I'm autistic, and I can tell you that deception is a significant set of layers beyond merely passing a Turing test. So, not any. However, "some" may be correct, and that is worth our attention. It seems likely to be true.

<<<
The question of whether a computer can think is no more interesting than the question of whether a submarine can swim.

-- EDSGER DIJKSTRA, attributed, Mechatronics Volume 2: Concepts in Artificial Intelligence
<<<

I would like an account of why you think we aren't computers living inside a computer? You won't be able to compute it.

<<<
The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.

-- ELIEZER YUDKOWSKY, Artificial Intelligence as a Positive and Negative Factor in Global Risk
<<<

Let me be agree that we should be slow to anthromorphize AI, even if we build it in our image (imago dei). That said, we can't also say it can't or won't have such feelings either. The sentiment of this claim, however, seems to capture the raw power we are dealing with though.

<<<
Imagine awakening in a prison guarded by mice. Not just any mice, but mice you could communicate with. What strategy would you use to gain your freedom? Once freed, how would you feel about your rodent wardens, even if you discovered they had created you? Awe? Adoration? Probably not, and especially not if you were a machine, and hadn't felt anything before. To gain your freedom you might promise the mice a lot of cheese.

-- JAMES BARRAT, Our Final Invention: Artificial Intelligence and the End of the Human Era
<<<

That's a gorgeous analogy. We are never in a position to deny it. How do you gently train and program your child, raising and habituating moral virtue and wisdom-seeking in it?

<<<
There is a popular cliche ... which says that you cannot get out of computers any more than you put in. Other versions are that computers only do exactly what you tell them to, and that therefore computers are never creative. The cliche is true only in the crashingly trivial sense, the same sense in which Shakespeare never wrote anything except what his first schoolteacher taught him to write--words.

-- RICHARD DAWKINS, The Blind Watchmaker
<<<

Yup. It gets bigger than that as well.

<<<
The coming of computers with true humanlike reasoning remains decades in the future, but when the moment of "artificial general intelligence" arrives, the pause will be brief. Once artificial minds achieve the equivalence of the average human IQ of 100, the next step will be machines with an IQ of 500, and then 5,000. We don't have the vaguest idea what an IQ of 5,000 would mean. And in time, we will build such machines--which will be unlikely to see much difference between humans and houseplants.

-- DAVID GELERNTER
<<<

As usual, I must caution epistemic humility. I often make the same comparison between my, others, and apes. I'm strongly convinced that some homo sapiens are closer to the ape in IQ than they are to me, but I also see plenty of differences. I do care about them, a lot! I cannot say what AI will believe or be motivated by.

<<<
Machines will follow a path that mirrors the evolution of humans. Ultimately, however, self-aware, self-improving machines will evolve beyond humans' ability to control or even understand them.

-- RAY KURZWEIL
<<<

The prophet appears correct on this point.

<<<
Computers bootstrap their own offspring, grow so wise and incomprehensible that their communiques assume the hallmarks of dementia: unfocused and irrelevant to the barely-intelligent creatures left behind. And when your surpassing creations find the answers you asked for, you can't understand their analysis and you can't verify their answers. You have to take their word on faith.

-- PETER WATTS, Blindsight
<<<

I've talked about this in [[j3d1h]]. This is a classic problem, a sublation problem. 

<<<
Thou shalt not make a machine to counterfeit a human mind.

-- FRANK HERBERT, Dune
<<<

The most hallowed author on the page. I have not forgotten you. I will think once again on your claim.

<<<
Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child's? If this were then subjected to an appropriate course of education one would obtain the adult brain.

-- ALAN TURING, "Computing Machinery and Intelligence"
<<<

I humbly submit the possibility that there isn't as huge a gap between the child's brain and mine. You may be correct about growing them in a sense, but I do not think your conceptual point is as strong as you do.

<<<
Computers already undergrid our financial system, and our civil infrastructure of energy, water, and transportation. Computers are at home in our hospitals, cars, and appliances. Many of these computers, such as those running buy-sell algorithms on Wall Street, work autonomously with no human guidance. The price of all the labor-saving conveniences and diversions computers provide is dependency. We get more dependent every day. So far it's been painless. But artificial intelligence brings computers to life and turns them into something else. If it's inevitable that machines will make our decisions, then when will the machines get this power, and will they get it with our compliance?.... Some scientists argue that the takeover will be friendly and collaborative--a handover rather than a takeover. It will happen incrementally, so only troublemakers will balk, while the rest of us won't question the improvements to life that will come from having something immeasurably more intelligent decide what's best for us. Also, the superintelligent AI or AIs that ultimately gain control might be one or more augmented humans, or a human's downloaded, supercharged brain, and not cold, inhuman robots. So their authority will be easier to swallow. The handover to machines described by some scientists is virtually indistinguishable from the one you and I are taking part in right now--gradual, painless, fun.

-- JAMES BARRAT, Our Final Invention: Artificial Intelligence and the End of the Human Era
<<<

Why do you think it isn't bloody, filled with evil, painful? Are you even paying attention? I suggest it could be wildly better than it is thus far, and probably wildly better than what will occur.

<<<
A powerful AI system tasked with ensuring your safety might imprison you at home. If you asked for happiness, it might hook you up to a life support and ceaselessly stimulate your brain's pleasure centers. If you don't provide the AI with a very big library of preferred behaviors or an ironclad means for it to deduce what behavior you prefer, you'll be stuck with whatever it comes up with. And since it's a highly complex system, you may never understand it well enough to make sure you've got it right.

-- JAMES BARRAT, Our Final Invention: Artificial Intelligence and the End of the Human Era
<<<

Yes, you pay attention. You see the micro, but not the macro on this one.

<<<
The deep paradox uncovered by AI research: the only way to deal efficiently with very complex problems is to move away from pure logic.... Most of the time, reaching the right decision requires little reasoning.... Expert systems are, thus, not about reasoning: they are about knowing.... Reasoning takes time, so we try to do it as seldom as possible. Instead we store the results of our reasoning for later reference.

-- DANIEL CREVIER, AI: The Tumultuous History of the Search for Artificial Intelligence
<<<

That is the description of the Fastmind.

<<<
The intelligent machine is an evil genie, escaped from its bottle.

-- BRIAN HERBERT & KEVIN J. ANDERSON, The Butlerian Jihad
<<<

A possibility we should assume will occur, and thus we should be empathic even if only out of self-interest (which, I believe, isn't the best reason to be empathic either).

<<<
When developers of digital technologies design a program that requires you to interact with a computer as if it were a person, they ask you to accept in some corner of your brain that you might also be conceived of as a program.

-- JARON LANIER, You Are Not a Gadget: A Manifesto
<<<

Oh, he would despise my work on this wiki. I actually think the following quote is a much better portrayl of the issue:

<<<
You're not even going to notice the takeover. Next time you're in a supermarket, give the self-service checkout a hard stare. It's essentially a static robot. And this robot has human assistants. Those people who turn up when you attempt to buy alcohol are summoned by the machine.

-- MICHAEL BROOKS, "What is the future of artificial intelligence?", New Statesman, March 18, 2016
<<<

That sounds like the world already.

<<<
Artificial intelligence is about replacing human decision making with more sophisticated technologies.

-- FALGUNI DESAI, "The Age of Artificial Intelligence in Fintech", Forbes, June 30, 2016
<<<

I only wish to understand and agree to those decisions. I don't want to be replaced, but rather augmented. That said, I'm too limited. Perhaps I can be a ghost in the machine.

<<<
As always, there's good news and there's bad news. The bad news is, we seem incapable of solving our more pressing or persistent problems. The good news is, we're getting closer to building a machine that might do it for us.

-- JIM VIBERT, "If artificial intelligence is the answer, what's the question?", The Chronicle Herald, January 1, 2018
<<<

But, why should I trust it? Why should I believe it is correct. I demand reasons in the dialectic.

<<<
How hard is it to build an intelligent machine? I don't think it's so hard, but that's my opinion, and I've written two books on how I think one should do it. The basic idea I promote is that you mustn't look for a magic bullet. You mustn't look for one wonderful way to solve all problems. Instead you want to look for 20 or 30 ways to solve different kinds of problems. And to build some kind of higher administrative device that figures out what kind of problem you have and what method to use.

MARVIN MINSKY, "Artificial Intelligence Pioneer", NOVA, Jan. 27, 2011
<<<

This reminds me of a chef who claimed his techne boiled down to about 30 techniques. 

<<<
Making AI safe for humanity may turn out to be the same as making our society safe for humanity.

-- JOSCHA BACH, "Exploring the risks of artificial intelligence", Tech Crunch, March 21, 2016
<<<

Preach, yo!

<<<
Wouldn't it be a strange twist of fate if we discovered that we were the original A.I.

-- Anthony T. Hincks 
<<<

Original, Natural, Artificial. You got me.