created: 20180712210312399
creator: h0p3
modified: 20180713164919880
modifier: h0p3
title: 2018.07.12 -- PPP: Autism and Modular Minds

//Autism and Modular Minds in Elizabeth Moon’s "The Speed of Dark" -- STEPHEN DOUGHERTY//

While I feared it for a long time, I'm increasingly convinced there is something right about the computational theory of mind. I still resist, however, because my work in logic and epistemology lead me to a [[dialetheist|https://plato.stanford.edu/entries/dialetheism/]] position. Whatever it is that my mind is trying to represent cannot be computed by finite minds (of any size, even larger than our physical universe) by definition. I'm a realist (which is not a popular opinion), so it means I have to admit my mind has some kind of faithful access to that which cannot be computed. 

You say:

<<<
However, if one rejects that there is a proper speed and an appropriate level of intensity for human perception of the world, then matters are quite different. Moon’s ambivalence on this point, I would argue, is thus a multivalent strategy for underscoring what is at stake both in terms of our understanding of autism and in human cognitive development more broadly speaking.
<<<

Science can only give us the instrumental means to our ends, but never the intrinsic ends in themselves. The maladaptivity of autism is contextual. To give a maximally generalized answer requires assuming a particular telos of humankind to give us an "ought" instead of a mere "is." 

<<<
In autism the cognitive functions and behaviours considered to be most seriously compromised are those dealing with “mindreading,” the ability to attribute intentional states to others. Autism is typically described as impairing social intelligence, the powers we normally take for granted to comprehend one another, to connect with one another on an emotional level, and to form human bonds.
<<<

I have a tough time developing affective theories of mind (atypical activations primarily in my rTPJ). I think my ability to cognitively reverse engineer social models helps, but still puts me at a significant disadvantage in most cases. There are contexts where what is normally considered a social disability turns out to be an advantage, especially with minority neurotribes. My wife is autistic, and I think our degree of empathy (modeling each other's minds, acting on the golden rule, etc.) is uncommon in my experience (of course, I could be blind and this is mere anecdote). My conjecture is that we both speak a similar autistic language.

<<<
I argue for the greater value of understanding autism from a fully embodied and intercorporeal perspective; one, that is, that refuses to treat the mind/brain as a computer processor.
<<<

I'm excited to see what you mean. I'm hoping there's some element of qualitative irreducible complexity you're pointing to. Much has transpired since you published this work. Do you still agree to it?

<<<
Modularity also reinforces the belief that, normatively speaking, our abilities to “read other minds,” to understand other people’s intentions and desires, are biologically encoded. But this leaves out of our thinking about the dimension of human sociality any serious consideration of the complex and difficult work involved in understanding other people, and of the incredibly complex ways in which we end up both understanding and not understanding...It would be very convenient to have such a module in our brains, and undoubtedly it would save a lot of trouble. But it simply does not jibe with the fact that we must all learn about other people (and ourselves) through lived experience. In taking aim at modularity theory I am not trying to argue that our minds are blank slates.
<<<

One can accept the computational theory of mind while also accepting that the computer requires input, lived experience, to have the material to compute with and generate the outputs we're interested in.

Is this an attack on modularity or on the computational theory of mind? Turing machines come in lots of varieties and complexities. When I steelman the computational model of the minds, it seems extremely robust. I have a hard time unseeing the world through that lens. 

[[The Good]] and however it is that I perceive the effects of metaphysics in our physical universe, is where the computational mind begins to break down. Serious Platonism and transcendental realism is not a popular view in most circles, but it seems the best candidate (imho) to attack the reductionist philosophy of mind which I believe stems from various kinds of physicalism.

<<<
Thus the important thing about brains in The Speed of Dark is not that they are genetically prewired, and the important thing about human development and behaviour is not that it is programmed in advance. Rather, at issue in the novel is how our experiences give shape to who we are, and even more importantly, what we can become, and how we become.
<<<

The physical universe appears to be a computer, and virtually almost all of who we, as far as we know, is our physical brains (hardware) which give rise to minds (software) which compute about the physical world.<<ref "g">> Insofar as we accept only the physicalist view, I don't see why experience is some radically different kind of computation. It's all prewired, hardwired, causally explained, etc. I agree, however, that experience is special, but it cannot be special on a physicalist's account. Normativity cannot arise from mere description. Experience of [[The Good]] in our physical substrate is exactly what gives normativity to the content of our experience, what makes us compute about something that actually matters.

<<<
Hobson’s is a relational rather than a modular approach to cognition. As he argues, thinking itself is a path, or a pattern, which invariably routes our minds through the minds of others.
<<<

Are these these relations representable as relational/predicate symbols? Are you absolutely sure this isn't reducible to a computational theory? I'm trying to figure out why I'm not allowed to claim that information is transformed as it passes from computational mind to computational mind, and this is simply a larger computer emerging from smaller ones.

<<<
But there is something wrong with this inferential argument: it sets up a closed circuit that essentially precludes the possibility of learning through experience, since the meaning of our interpersonal engagements will always refer back to some preset theory of attitudes by which they are to be accorded value. The most that can be said for our experiences on the modular scheme is that they are triggers for programmed circuits and onboard maps that guide our behaviours and actions in appropriate ways.
<<<

* Why do you think it's a closed circuit? I don't see it.
* Isn't it possible to have preset, innate attitudes in some parts of our brains while also maintaining radical plasticity in others?
** I suggest that our minds aren't even possible without some personally immutable data_structures + algorithms.
* Are you struggling with the problem of freewill from an incompatibilist's standpoint? 
** I do. Perhaps I've completely misunderstood you here (forgive me).
* I'm worried about that normatively loaded word "appropriate" here. That could be the reason I'm failing to understand.

<<<
Thus, perhaps, instead of talking about the autist’s state of emotional sterility, we should talk about the autist’s alternative affective experience, and for etiology there is no reason why we should not consider the possibility that autistic behaviours are conditioned by the field broadly defined—by the physical substrate of the brain in its relation to the rest of the body, and the body in its relation to the people, places, and things with which it is held together in a certain state of belongingness.
<<<

That I agree to. Exactly what counts as autism is continually being redefined, not simply refined. We're still grappling with what it is. Alternative affective and cognitive experience treats autism as different without automatically assuming it's a bad thing. I fear I have missed your argument now. I'm sorry!

<<<
Rather, it is Lou’s rigid insistence on the autonomy of his decision making, on the notion that having the operation is his idea and nobody else’s. (He seems to have forgotten, for example, the coercion he had suffered at the hands of his boss.) From this point on, the book turns into Lou’s quest for, and achievement of, ultimate autonomy, or non-relation.
<<<

So, is he really free? What happens if we set aside this issue? Can we? I've studied the issue a reasonable amount, and I'm at the point where I don't believe I can give a satisfactory answer beyond faith. I'm stuck with only [[hope]] that the world has contingency, that there are other possibilities, that something is up to us in some meaningful way, that we really are good or contribute to [[The Good]].


---
<<footnotes "g" "Insofar as we are not [[The Good]], we are just computers representing [[The Good]] to ourselves. This is the best we can.">>

