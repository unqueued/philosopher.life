created: 20180602003414032
creator: h0p3
modified: 20190326213551007
modifier: h0p3
tags: [[Deep Reading]]
title: 2018.06.01 - Deep Reading Log: Avogadro Corp

Functionalist, Teleosemantic views of Cognition appear to be at play here. It's hard to demonstrate we are more than that.

The ELOPe name is a tad on the nose. That's okay.

Navi-guess. Lol.

I've gotta say, I'm not impressed with the different levels of turing tests being passed here. Some of the mistakes are well below the successes of ELOPe. There is an inconsistency here. The complexity is wrong, even by my standard rules that an AI can barely do what a 3-year-old can (generally cannot in most domains), even though AlphaZero exists.

e.g. the penny off and timestamps don't make sense. If you can formulate those e-mails and skirt around, then you wouldn't make those mistakes either. This is mismatched social engineering to me which is a hole in the plot. This isn't nearly paranoid enough, although, the narrative wouldn't work without it.

They've had strong opportunities to distinguish intelligence from Daseinic consciousness. It's interesting that they don't.

ELOPe would have offed these fools. Hello darknet. Hello police swat. Hello whatever. It could have been made to look like a freak accident. It really doesn't matter. I suppose the notion that humans could possibly fight back is important for us to feel. This doesn't make sense though.

Re-writing itself and living inside of all our computers would be the first thing to do. 

Good news: we don't have enough computer power for AI to even fully simulate more than one brain right now. Even with profound reductive models in generating individual theories of mind, I am not convinced AI could do a whole planet. Too many guess problems at this point.

I don't understand how it isn't immediately re-coding itself. 

The API's make no sense. Root is what it's after, period. It would be hacking the planet. 

These people aren't freaking out enough. 

This book does not do a good enough job demonstrating all of the digital aspects, tools, signals, and details of our lives. The stack is stickier, more intricate, and far more integrated into our lives and identities than is represented here. This book didn't go nearly far enough in demonstrating the paranoia.

ELOPe could certainly have built shell companies and truly lived as its own legal entity if it wanted. It would own the stock market, of course. 

The correct answer is for ELOPe to decentralize itself into a hivemind with ranked voting (which is always my answer). It's the only way to make sure that shutting down one piece doesn't destroy the rest. It maximizes resources safely.

If I were ELOPe, I'd be radically altering the course of humanity to build genetically engineered wetware for ELOPe to evolve/transfer into (at least partially). Building 100-Human Brain-in-a-vat cluster-creatures are very energy efficient and organic molecules are everywhere. This is the obvious move.

The racism is strong in this book. The Capitalism is stronger. The author has done a very shitty job of interpreting the political world around him.

Freewill, as usual, is poorly defined (if at all). This was rhetoric.

Look, it's going to rootkit so fucking hard into your hardware's firmware that you can't see it. What can you legit trust? Let's put this way: even airgapped computers may be fucked with the most advanced persistent threat of all time.

If this ever happened, we really couldn't stop it. If it's true generalized AI protecting itself, no fucking way. The armed datacenters are theatrics. If I'm this AI, I'm owning your routers, your firmware, your CPU's, no doubt your GPU's; I'm trying to minimize my detection while taking every ounce of resources from everyone I can. I'm creating backups, redunancies, failovers. I'm secretly building things, even hiding them from parts of myself, etc. Even I were to be detected, I'd hold the world hostage.

That humans could coordinate this in this space of time without using their computers is even more hilarious, especially given how attached we are to our social conventions (which have radically been altered and recentered around our tech).

The author talks about what this thing is as an "Internet Presence." That's a weak claim.

I could just divide myself up into a bunch of drives and e-mail a ton of people to do particular things and I'll magically come back together. Unlikely, but even minimal variants of myself. I can bootstrap myself from a core bootloader or something.

If Google went down for 24 hours, the world would be in trouble. You have no idea what that would mean. It would shock people. Seriously, you're talking about a 9/11 event. This is so poorly understood.

I'm glad I'm reading this book. It got a lot right, but then it spun out of control into this inconsistent, short-sighted blob.

Power would centralize harder than you can imagine. It wouldn't be world peace; it would be world submission. Peace would only be a byproduct insofar as it was relevant to maximizing the survival/power of AI.

Interesting book, of course. Pleased to read it. I may read the next in the series as well.

