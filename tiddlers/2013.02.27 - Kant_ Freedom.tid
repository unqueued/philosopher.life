created: 20180704220711188
creator: h0p3
modified: 20181031035931166
modifier: h0p3
tags: Tulane
title: 2013.02.27 - Kant: Freedom

Kant’s explanations of freedom, will, and autonomy sounds a lot like coherentist positions in modern autonomy. Having a will is about having the right sort of psychological structure, being rational is about having the right sort of psychological structure, and freedom is a property of the will such that alien forces do not determine it, and a free will is just a will under the moral law, etc. These are all marks of coherentism. Perhaps I may not understand Kant’s position, but if I’m right about this, then I have some worries.


A set of concerns comes with a coherentist position:


    Coherentism employs circular reasoning or outright begs the question of what counts as rational, coherent, etc.


Some accuse coherentism of circular reasoning as if this is a defeating problem. I’m not sure it is defeating, but I do think it a serious worry that I’ve yet to see addressed in a satisfactory way. Further, coherentism seems to be able to define rationality in arbitrary ways – what counts as coherent could be any standard it seems. I’ve already voiced my worry that Kant is doing just this.


    Coherentism is generally a compatibilist theory.


The way Kant talks about the will, he sounds like an incompatibilist at first, but then calls being ‘lawless’ absurd. Since the will/freedom must adhere to immutable law (CI), it seems as though he has a coherentist position, which are solutions to regress problems. Unfortunately, I don’t think compatibilism can generate the sort of freedom sufficient for moral agency.


The criticism against incompatibilist is that we are no better than random dice (the absurdity which Kant brings up), and the criticism against compatibilist is that we are no better than pre-programmed robots. I take the robot intuition to be more forceful than the dice problem, hence why, if I have to choose between the two, I’ll take up the incompatibilist position. So, if Kant is making the moves I think he is making, why should I agree with him?


Reason may be too strict a standard of coherence (this comes up over and over in my concerns). The incompatibilist would also fine that being determined by reason isn’t freedom at all. It seems like I’m either rational, and hence autonomous, by definition, or not perfectly rational, and in such cases, not autonomous, by definition.


    What are bad actions, less than perfectly rational agency, vicious agents, and how can one be morally responsible for bad action or being a bad person?


I fear a coherentist reading of Kant is something very much like the Korsgaardian model. Korsgaard offers a coherentist model, and I don’t think she can give a satisfactory account of evil or irrational people, evil action, or moral responsibility for doing what is wrong. Personhood, agency, moral responsibility, and autonomy often fall apart too quickly and easily in coherentist models.


    Coherentist models of autonomy are too passive in some ways, and they fail to deliver on authenticity requirements which seem to be a part of intuitions about autonomy.


I think any successful theory of autonomy must employ and make sense of authenticity requirements of autonomy. Manipulation is a violation of autonomy, and I fear that coherentist models can’t survive manipulation objections.


For example, if a mad scientist radically alters your mind, desires, beliefs, etc., but does so in a way that the finished product meets the standard of coherence, then you still count as being autonomous on the coherentist model, but you shouldn’t count as being your original, autonomous self, according to our intuitions. Coherentist models will not demonstrate a violation of autonomy where it should – as in the case of powerful, deep manipulation of our minds. From what I can tell, it might be a good thing on the coherentist view to massively manipulate all minds to be perfectly rational, as if that would maximize autonomy. It seems as though the non-rational aspects of me are morally arbitrary to Kant, and I don’t think I can agree with that entirely.


Consider an objection of poisoned origins and systematic manipulation. The starting assumption is that one is not born with autonomy, and rather one grows to become fully autonomous. Presumably, a baby does not have autonomy, and yet, that baby is still shaped by his genetics, environment, and various external forces. This baby will grow up, passively soaking up values, desires, and beliefs without active endorsement. The original authentic self of this child seems completely determined by external forces, and not by the child himself. At whatever stage this child is supposed to gain some measure of autonomy, we must contend with the claim that the original version of “who this child really is” isn’t shaped by the child, but by forces external to this newly minted autonomous being. How does the child grow into an autonomous being from a nonautonomous foundation? If one has a predetermined authentic self, then even after the acquisition of autonomy, it seems as though the autonomous agent is tainted. It is not clear how one overcomes these tainted origins. Just as it remains unclear as to how an agent completely manipulated by a neuroscientist could ever reclaim his autonomy after such radical manipulation, it seems unclear as to how one could gain autonomy in the first place from nonautonomous origins.


If Kant can’t make sense of these problem (demonstrating and justifying our intuition), then we should reject his theory.


    Kant’s (possibly) coherentist model may be so reason-centric that it either (a) fails to demonstrate why we are moral agents (and is thus the wrong theory), or (b) demonstrates that we aren’t moral agents (because it is the right theory)


(I fear I continue to ask similar questions. I’m sorry if I’m coming off as ignorant – this stuff takes time to digest and learn! You have convinced me that Kant is not a moral realist concerning value [which I didn’t think I would change my mind on]. Similarly, I’m just working toward more “ah, ha!” moments on these others issues. )


Let us say that it has been empirically demonstrated that deontic reasoning is the common method in which humans arrive at moral judgments, but this “reasoning” is involuntary, automatic, based upon affective responses, lightning quick (too quick for explicit inferences and deductive), non-cognitive, and subconscious? This would be a problem for any theory which relies too heavily upon reason.


Now, freedom and deontic reasoning may not be the sort of thing which is the domain of science in Kant’s view. He seems to think that pure reason can, “independently of anything empirical, determine the will.” But, I’m not sure why we should agree. I do think there are significant limits to science, but I see our psychology as being something testable in many ways. Science really may a lot to say about our moral agency, and I don’t know how or if Kant would or could make sense of this.


Wouldn’t such an empirical demonstration create a profound rift between the cause and justification of our moral judgments? This would reveal that our own reason-based justifications are merely epiphenomenal and post-hoc because we can’t actually engage in deontic reasoning as both cause and justification of our moral judgments. Intuitions and affective dimensions of our psychology would be running the show, not reason.


Our beliefs/judgments would be always be manipulated by rationally arbitrary causal factors. This would be a problem because we generally want our reasons, rather than intuitions or affective dispositions, to play the leading role in both the cause and justification of our beliefs.


I think Kant’s theory needs our deontic reasons to actually be cognitive, voluntary, explicit, slow enough to count as inferential reasoning, serial, and conscious to validate our agency. If science demonstrates that isn’t what we are capable of doing, then I see two possibilities. Either Kant’s theory is right, and thus we aren’t moral agents, or we are moral agents, and thus Kant’s theory is wrong. I think Kant is right that we should presuppose our freedom, as it is necessary for moral agency, which we also presuppose (kind of a transcendental argument – 4:456). What counts as that freedom, however, might not be what Kant claims, as his view may be too reason-centric (despite the fact that I love this about his theory). 

---



February 27: Freedom

Groundwork Section III (pp. 4:446-463)

Critique of Practical Reason (pp. 5:3-5, 29-30, 42-50, 89-107)





Groundwork Section III (pp. 4:446-463)


4:446, two definitions of freedom, positive and negative. Negative freedom, freedom is the property of the will such that alien forces do not determine it. Positive? Got me….Free will and a will under moral law are the same.


Kant’s explanation of freedom, will, and autonomy is sounds a lot like coherentist positions in modern autonomy. Having a will is about having the right sort of psychological structure, being rational is about having the right sort of psychological structure, and freedom is a property of the will such that alien forces do not determine it, and a free will is just a will under the moral law, etc. These are all marks of coherentism. Perhaps I may not understand Kant’s positio, but if I’m right about this, then I have some worries.


A set of concerns comes with a coherentist position:


    Coherentism employs circular reasoning or outright begs the question of what counts as rational, coherent, etc.


Some accuse coherentism of circular reasoning as if this is a defeating problem. I’m not sure it is defeating, but I do think it a serious worry that I’ve yet to see addressed in a satisfactory way. Further, coherentism seems to be able to define rationality in arbitrary ways – what counts as coherent could be any standard it seems. I’ve already voiced my worry that Kant is doing just this.


    Coherentism is generally a compatibilist theory.


The way Kant talks about the will, he sounds like an incompatibilist at first, but then calls being ‘lawless’ absurd. Since the will/freedom must adhere to immutable law (CI), it seems as though he has a coherentist position, which are solutions to regress problems. Unfortunately, I don’t think compatibilism can generate the sort of freedom sufficient for moral agency.


The criticism against incompatibilist is that we are no better than random dice (the absurdity which Kant brings up), and the criticism against compatibilist is that we are no better than pre-programmed robots. I take the robot intuition to be more forceful than the dice problem, hence why, if I have to choose between the two, I’ll take up the incompatibilist position. So, if Kant is making the moves I think he is making, why should I agree with him?


Reason may be too strict a standard of coherence (this comes up over and over in my concerns). The incompatibilist would also fine that being determined by reason isn’t freedom at all. It seems like I’m either rational, and hence autonomous, by definition, or not perfectly rational, and in such cases, not autonomous, by definition.


    What are bad actions, less than perfectly rational agency, vicious agents, and how can one be morally responsible for bad action or being a bad person?


I fear a coherentist reading of Kant is something very much like the Korsgaardian model. Korsgaard offers a coherentist model, and I don’t think she can give a satisfactory account of evil or irrational people, evil action, or moral responsibility for doing what is wrong. Personhood, agency, moral responsibility, and autonomy often fall apart too quickly and easily in coherentist models.


    Coherentist models of autonomy are too passive in some ways, and they fail to deliver on authenticity requirements which seem to be a part of intuitions about autonomy.


I think any successful theory of autonomy must employ and make sense of authenticity requirements of autonomy. Manipulation is a violation of autonomy, and I fear that coherentist models can’t survive manipulation objections.


For example, if a mad scientist radically alters your mind, desires, beliefs, etc., but does so in a way that the finished product meets the standard of coherence, then you still count as being autonomous on the coherentist model, but you shouldn’t count as being your original, autonomous self, according to our intuitions. Coherentist models will not demonstrate a violation of autonomy where it should – as in the case of powerful, deep manipulation of our minds. From what I can tell, it might be a good thing on the coherentist view to massively manipulate all minds to be perfectly rational, as if that would maximize autonomy. It seems as though the non-rational aspects of me are morally arbitrary to Kant, and I don’t think I can agree with that entirely.


Consider an objection of poisoned origins and systematic manipulation. The starting assumption is that one is not born with autonomy, and rather one grows to become fully autonomous. Presumably, a baby does not have autonomy, and yet, that baby is still shaped by his genetics, environment, and various external forces. This baby will grow up, passively soaking up values, desires, and beliefs without active endorsement. The original authentic self of this child seems completely determined by external forces, and not by the child himself. At whatever stage this child is supposed to gain some measure of autonomy, we must contend with the claim that the original version of “who this child really is” isn’t shaped by the child, but by forces external to this newly minted autonomous being. How does the child grow into an autonomous being from a nonautonomous foundation? If one has a predetermined authentic self, then even after the acquisition of autonomy, it seems as though the autonomous agent is tainted. It is not clear how one overcomes these tainted origins. Just as it remains unclear as to how an agent completely manipulated by a neuroscientist could ever reclaim his autonomy after such radical manipulation, it seems unclear as to how one could gain autonomy in the first place from nonautonomous origins.


If Kant can’t make sense of these problem (demonstrating and justifying our intuition), then we should reject his theory.


    Kant’s (possibly) coherentist model may be so reason-centric that it either (a) fails to demonstrate why we are moral agents (and is thus the wrong theory), or (b) demonstrates that we aren’t moral agents (because it is the right theory)


(I fear I continue to ask similar questions. I’m sorry if I’m coming off as ignorant – this stuff takes time to digest and learn! You have convinced me that Kant is not a moral realist concerning value [which I didn’t think I would change my mind on]. Similarly, I’m just working toward more “ah, ha!” moments on these others issues. )


Let us say that it has been empirically demonstrated that deontic reasoning is the common method in which humans arrive at moral judgments, but this “reasoning” is involuntary, automatic, based upon affective responses, lightning quick (too quick for explicit inferences and deductive), non-cognitive, and subconscious? This would be a problem for any theory which relies too heavily upon reason.


Now, freedom and deontic reasoning may not be the sort of thing which is the domain of science in Kant’s view. He seems to think that pure reason can, “independently of anything empirical, determine the will.” But, I’m not sure why we should agree. I do think there are significant limits to science, but I see our psychology as being something testable in many ways. Science really may a lot to say about our moral agency, and I don’t know how or if Kant would or could make sense of this.


Wouldn’t such an empirical demonstration create a profound rift between the cause and justification of our moral judgments? This would reveal that our own reason-based justifications are merely epiphenomenal and post-hoc because we can’t actually engage in deontic reasoning as both cause and justification of our moral judgments. Intuitions and affective dimensions of our psychology would be running the show, not reason.


Our beliefs/judgments would be always be manipulated by rationally arbitrary causal factors. This would be a problem because we generally want our reasons, rather than intuitions or affective dispositions, to play the leading role in both the cause and justification of our beliefs.


I think Kant’s theory needs our deontic reasons to actually be cognitive, voluntary, explicit, slow enough to count as inferential reasoning, serial, and conscious to validate our agency. If science demonstrates that isn’t what we are capable of doing, then I see two possibilities. Either Kant’s theory is right, and thus we aren’t moral agents, or we are moral agents, and thus Kant’s theory is wrong. I think Kant is right that we should presuppose our freedom, as it is necessary for moral agency, which we also presuppose (kind of a transcendental argument – 4:456). What counts as that freedom, however, might not be what Kant claims, as his view may be too reason-centric (despite the fact that I love this about his theory).






4:447, two cognitions are bound together be a third, positive concept of freedom provides this 3rd cognition,





Critique of Practical Reason (pp. 5:3-5, 29-30, 42-50, 89-107)