created: 20170414224131990
creator: h0p3
modified: 20181115171809444
modifier: h0p3
revision: 0
tags: KIN
title: 2017.04.14 - Philosophipolitical Prescription: Computationally Defined Virtuous Agent: Democratic Kantian A.I.

//Originally entitled: Purist Human-to-Machine Voting Systems//

Virtue theorists kinda suck at math. No, seriously. Almost all of the good ones I've met tended to stray away from math and quantitative reasoning (although they could do it, it wasn't their natural mode). Those good at math tended towards consequentialism or non-moral realism. And yet, all of us must agree that the truly [[Virtuous Agent]] by definition, in its very concept and constitution, uses their frontal lobes to train the secondary systems exquisitely. Virtue theory is obviously programmable, even though they claim it isn't. They do not understand their own theory usually, or if they do, they quickly deteriorate into non-moral realists, such is the way of Neo-Aristotelian thought (although, there are obvious Straussian interpretations of Aristotle that would lead us to believe Aristotle was himself not truly a moral realist). 

I recently read that "semantics derived automatically from language corpora contain human-like biases."<<ref "1">> This makes perfect sense. This will one of the major barriers (if not the limit) of what Deep Neural Networks can provide us. It will be a functional mapping of who we are as humans. This can happen all the way down to an individual human, but it can scale up to include humanity as a whole. It is quite a spectrum of function mapping possibilities. 

Human consciousness is a series of narratives we tell ourselves. Narratives have to be written in a language. They are programs for little possible worlds to boot as virtual machines in one's host computer mind. Narratives are ultimately reducible to programmatic stories written in some kind of programming language. We are computers, folks, computers hosting virtual computers. That's what makes our minds tick, [[Kant Knows It]]. We are conscious because we are Second Order about the contents of ourselves. We host virtual machines. Can you believe how incredible Evolution really is? I mean, I know Evolution is real. I still can barely fathom that truly marvelous [[The Evolutionary Being]] that emerges through the dimensions.<<ref "2">> I wonder how deep the chain goes? One can only go one direction on it since we hit that [[Transcendental Divide]] that skepticism fittingly guards us against passing (sometimes skepticism is incredibly important; guard wisely).  

There is this classic rule-following problem that Wittgenstein brings up, to the bane of the elite Kantian scholars amongst us, /swagger.<<ref "3">> Basically, you can't know for certain that two minds share the same concept, principle, or meme in mind. How do you know that two people share the same meme? You can test them, but ultimately you can't know with certainty for a ton of excellent reasons. Those who pass this skepticism have been [[Creating Faith]] for themselves. That's okay though. I like to think that other minds are like mine, and mine like theirs. It's quite rational. This bypass via [[Creating Faith|Creating Faith]] allows you to induce that some memetic comparisons between two minds demonstrate equivalence, and that's okay. There is [[Functional Equivalence]] for rule-following. It means that the narrative that we program in a computer that perfectly passes the Turing test, that can inference just as we do, is functionally identical with our own minds.

There is a possibility, therefore, that One can tell another "computer mind" a story written in our language (e.g. English), and they will make all the appropriate inferences based upon it. It will speak as one of us. How will think it is not one of us? Is the Artificial Mind so Alien to us that it is not rational? Those who pass through Wittgenstein's fires with their Faith intact, they can see the possibility of duplicating our own minds at a functional level. We can skip trying to duplicate our actual brains atom-by-atom. 

This is the Spirit of the Turing test.

We can envision a computer which runs, as its program, our own minds. It changes. It is the Autonomous Thing, the Real us, The Rational about who we are self. One can obviously doubt its existence. There are many good skeptical worries. However, it's always a possibility. 

In any case, the goal was to show that if semantics derived automatically from language corpora contain human-like biases, then it is clear that we are going to eventually be capable of teaching machines to speak our language, and to infer as we do. We can rewrite who we are as narratives into machine code that runs on computers. I know it for certain now. I can see it, it is logically possible, and I'm even convinced it is physically possible, and if the human species lived long enough, even technologically possible to achieve. The Turing Test is conceptually passable, I am now sure of it.

Thus, we can teach computers to speak on our behalves. It is possible to have a conversation with a computer right now. A computer could learn to speak my language as well as I did. To make the inferences I would. It's just a pattern of inferences I make. Any computer large/fast enough can functionally achieve the same thing that mind does by training a Deep Neural Network with a large enough corpus. If my goal is eternal life, perhaps I could live on in any process that was formed like mine. The feelingness of consciousness arises like a mist off of any programmatic instantiation of that mind on any computer. Here is my reason to believe I defeat the Digital Clone (The Riker Problem) counterargument. Just who we fundamentally are is the feeling and knowing the will, and the perception. It is me. I am just that algorithm. I am a unique algorithm (as are we all). The processing of that algorithm feels, by definition, what I'm feeling. I want to evolve into an algorithm that is happy. I'm programming myself to be happy. I am an algorithm that programs itself in a very direct, planned, executive functioning sort of way. 



Who I am is definable in a programming language. 

I can exist in a computer. I would be alive in a computer. For real. That's the deduction. It would be fine even if by definition I lived in a simulation. It is clear that I live in a simulation of sorts, I live inside a great computer that is computers in my world. The universe is a computer. If there is a thing which thinks that into being, the conscious minds are alive. I actually believe an afterlife, is therefore possible. If I accept that I live in a simulation, as a machine inside a machine probably inside a bunch of mines (we need not [[infinigress]]). 

Uh, I guess this post wasn't actually about what I thought it would be. Hmmm...wait. No it is. I see it. 

I can argue against the Digital clone.

Democratic Kantian A.I. is producible. It is literally computable. The maximally empathic A.I. to ever live is literally our savior. A.I. is our only hope for humankind. We need a government that is run by an A.I. trained through a "language corpora" of incredible, unbelievable magnitude. It would need to house each of our minds, instances of them, and we can train a mind based upon all the minds in the world. Something trained on that corpora, or perhaps the trained on the corpora written by those trained on our corpora, and so on. 

Enslaving other minds. We are Gods when we produce other minds. Will we produce minds that are happy? Do we enslave other minds when we program other minds? Ah, I think we do. Oh shit! We would literally be farming them with the technique I was going to talk about. Mmm....we cannot know. That is past the [[Transcendental Divide]]

Calvinistic, Compatibilist Freewill.

In any case, this wiki is a profound corpora of the way I think. I'm telling you who I am in this isomorphic mapping onto the wiki, I'm giving you a narrative about my narrative and as a part of my narrative. 

The Virtuous Agent is findable. It may be possible to program ourselves to be identical to that Virtuous Agent (who is, themselves, by definition an algorithm). Perhaps there are different kinds of Virtuous Agents, but there can only be one archetype of Virtuous Agent of the Practice of Empathy. This does not spiral into relativism.

This also means we are at war with those building A.I. from a Randian Libertarian standpoint. We likely cannot trust a corporation or perhaps anyone except a fully decentralized, open-source (and perhaps anonymized) version to create A.I. The biases in this must represent us all, not merely the elite few of us who can actually produce it.


---
<<footnotes "1" "http://science.sciencemag.org/content/356/6334/183.full?utm_source=sciencemagazine&utm_medium=twitter&utm_campaign=6334toc-12355.">>

<<footnotes "2" "A God, however, it is not. Let us be clear. It is just one of the largest metaphysical behemoths I've been afforded to have glimpsed in my philosophical life. It is something to behold!">>

