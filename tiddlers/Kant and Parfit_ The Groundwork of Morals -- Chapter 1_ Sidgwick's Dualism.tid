created: 20190412022131877
modified: 20190805171538955
tags: [[Deep Reading]] Philosophy
title: Kant and Parfit: The Groundwork of Morals -- Chapter 1: Sidgwick's Dualism

!! 3

<<<
I attribute this partly to a confusion of thought between what it is reasonable for an individual to desire, when he considers his own existence alone, and what he must recognize as reasonably to be desired, when he takes the point of view of a larger whole: partly, again, to a faith deeply rooted in the moral consciousness of mankind, that there cannot be really and ultimately any conflict between the two kinds of reasonableness. 

Henry Sidgwick, The Methods of Ethics, 404–405
<<<

If we define Reason as [[The Right]], then there cannot be a conflict. This //Dualism of Practical Reason// (DoPR), which may simply be the balancing in reflective equilibrium of individual and collective desires in the [[CI]] computation is one of the hard problems in metaethics. If Aristotle offers us any rule-of-thumb, we should overshoot the mean, and in our context, that means we should aim to be more collectivist. This doesn't solve the conceptual problem though.

Duty (“Rational Benevolence”) and Self-interest (“Rational Egoism”) don't always conflict. It turns out that it is a [[good]] thing for me to give to [[others]] and sacrifice in my relationships even on egoistic stances (as the virtue theorists enjoy telling us). Further, we can imagine actual virtuous agents whose flourishing is no different than duty itself. Yet, in most cases, it's easy to see they do conflict.

One move we might consider is how Self-interested maxims might be cleansed and validated by the [[CI]] insofar as agents as isolated, but as we expand the context and content of the maxim to include more agents in our domain, the acts are no longer universalizable given these extended particularities. What's the difference in the [[CI]]'s computation? Why?

!! 4

I'm not so skeptical of //The Ultimate Derivation// (TUD) because [[The Moral Law]] is logically equivalent to all logical truths. It's only ONE giant truth, or until we hit [[Dialetheia]]s wherein we must quietistly and humbly deny we can see further beyond speculative realism. This is to say, I'm open to claiming that there are consequentialists derivations which are functionally and logically equivalent to the [[CI]]. It's black box computing, and there appears to be an isomorphism. Since we ought to particularize maxims to the point that they look no different than a calculus, we are probably not in a position to deny Parfit absolutely. It seems pointless to try when semantics are boiled down to truth values maintained in all possible worlds.

What I can say is that one side of the moral mountain is more plausible and feasible to heuristically scale than the other in many contexts. Rawls attempted the TUD within his [[ROG]]ian thought experiment, and it still appears to be the most cogent story I've found (which is hardly an argument).

!! 5

It is my contention that Interest is sublated by Duty. Whatever counts as the morally salient features of Interest are already brought to bear upon Duty in the calculation.

Of course, //Sarah Neem// doesn't seem like a crazy hard problem to me. Flesh out the context, say today's world, and I'll tell you that you don't have a right to your wealth and absolute freedom to do whatever makes you happy. That doesn't mean there isn't an egoism to be had, but it is obviously radically contained by the massive set of Hohfeldian rights held by all the other persons on the planet. That's a hard pill to swallow for most people. The sad philanthropist acts from duty, and therefore his actions have moral worth. Merit, in this case, is not hard to point out.

What I find so odd about the thought experiment is that it doesn't appear as though Sarah would be as unhappy if she didn't have the money in the first place. I think this speaks to some possible degree of arbitrariness in desire satisfaction conditions.

Is this really a great example of DoPR? Yuck. See, I think there's a way to talk about Self-Interest that isn't mere egoism, even when we might be the only people in the world. My intuition is that instead of consequentialism with a few deontic side-constraint concessions (super popular), the correct answer is a deontology where often the last straw is decided by utilitarian reasoning. Even Self-Interest of isolated individuals appears regulated by the [[CI]] beyond the dictations of egoism. Thus, the DoPR isn't about balancing egoistic individuals against each other exactly, but rather heavily regulated egoism of the individual balanced against the heavily regulated egoisms of individuals in the collective (and/or also the heavily regulated egoism of the emergent collective). Hedonism and even Eudaimonia were never the sufficient answers. We're really trying to understand justification as a balance between what would otherwise be the justified eudaimonias of the isolated individual and isolated collectives.

!! 6

That threshold of sacrifice is another version of the Utility Monster, and it's another demonstration of the ugliness of utility casuistry. 

Um, what counts as "impartiality?" That is borderline already the definition of [[The Moral Law]]. Step behind the [[VOI]], and you're going to be impartial. Universalize with the [[CI]], and you are being impartial. 

!! 7

So, Parfit claims Sidgwick offers a solution (Sidgwick's Solution):

<<<
the Dualism of Practical Reason: We always have most reason to do whatever would be impartially best, unless some other act would be best for ourselves. In such cases, we would have sufficient reasons to act in either way. If we knew the relevant facts, either act would be rational.
<<<

There is clearly a master/slave dialectic in that duality, and the ego wins. You have not completed practical reason until all cases of egoism/individualism has been fully factored into the ultimate collective analysis. If we knew the relevant facts, we'll find most are not imperfect duties but instead perfectly one or the other. Sidgwick does not buy the greyspace he hopes.

It's absurd to think reason cannot assist Sarah. You need more reason for what counts as Reason here. Sidgwick has already lost if he thinks egoistic and impartial reasons aren't comparable. I agree they aren't always commensurable in some respects, but always commensurable in the ways that matter: impartiality (which just is objectivity) must always provide the [[W5H]] and [[dok]] of the unification of all [[gfwiwcgws]]. 

The idea here is that moral reasons (which are definitionally the only impartial reasons) are not overriding, including against egoistic reasons (which many want to call moral, but I see no reason to grant it). I think Sidgwick has already begged the question against the possibility of impartial morality here.

I find most people are incredibly skilled at denying the strength of impartial reasoning in the Williamsian weighings. Ad hominem: this thesis of incommensurability is the result of not taking not take commensurability strongly enough to fight for the commensurability enough to realize the thesis is false. This is a sign of vice.

Note the difference between "what is to be done" as description and prescription. It needs to say "what ought to be done" to be crystal clear, especially since this is a pluralist, moral imperfectionist, far more relativized, highly egoistic assumption of massive permissibility. It's the popular point of view too. 

!! 8

I'm a stronger believer in non-cognitivist necessities in our moral psychology (and hence epistemology) than I used to be. Both are necessary for each other for likely every possible problem. There is a [[Self-Dialectic]] problem I'm convinced must be regulated by the universality of impartial reason, which includes giving space to qualia, emotion, and self-expression; however, I deny cognition is complete without affectation for Dasein and probably moral agency in all cases.

I will admit that if Raz is correct, then the incommensurability thesis is correct, but I don't think Raz is a moral realist. I don't see how Sidgwick can find a middle ground here. I wonder if the same attack must function on me to any [[dok]]? I buy cognition as the master to which passions ought to be the slave (Hume is disturbed). 

There's something oddly ambiguous in the discussion of the "[[power]] of reason" here. Power to dictate what we ought to do: [[The Moral Law]]? At the tippy-[[infinite]]-top facing down, yup. Bottom-up [[fff]] requires using emotion to get there though. Only reason in metaphysics, [[The Good]] [[Itself]] (and hence [[The Right]]), can define the meaning of anything, including emotions in any computable way.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             

                   

