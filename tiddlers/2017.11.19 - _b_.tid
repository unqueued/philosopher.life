created: 20171119145516806
modified: 20181221013515331
modifier: h0p3
revision: 0
tags: /b/ ehyeh
title: 2017.11.19 - /b/

Look, let's say molecular altruism exists as some emergent property of atomic egoistic desires. How do I know altruism when I see it? You need to give an account for it. It can't be guesswork. It can't be that you just "feel it is." Give me an unbiased method. 

Actions might speak louder than words, but like words, they still don't give us access to your ultimate intentions and motivations. (You are boned.) 

Let's be clear: I've been wrong about my own intentions before. Even when I knew deep down I was right, I have been wrong. This is a postmodern problematic for homo sapiens, of course. I'm not asking you to solve every conceivable epistemic paradox. I think knowing our intentions is extremely difficult; we're good at tricking ourselves. If we can't even understand our own minds, why should we make similar attributions to others? 

Ah, you think I contradict myself. I do not. Egoism is a much better predictor and heuristic for interpreting human beings. Take it from an autist who lacks guttural, affective neurotypical rTPJ activations and relies upon cognitive empathy and empirical investigations to develop increasingly accurate theories of mind. In other words, I'm forced to be more objective, as it is my only recourse; you have the luxury of being lazy and making certain kinds of emotional inferences that I do not (of course, that doesn't mean you are more accurate in this case).

Yes, you are more capable of affectively believing that another mind is like yours because...it is. But, you are very often wrong about your own intentions and motivations, and that reverse fundamental attribution error carries on. Just as you are blind to yourself, you are blind to others. Sometimes, the phenomenology of subjectivity produces critical failures. Understanding the root causes of our motivations is easily one of them. 

What is nefarious, in this case, is that you don't have much access to the unconscious parts of your mind, where your fundamental motivations are found. Again, consciousness is an emergent illusion, not the real control center (Dasein is not ultimately a first-class citizen as we had hoped). 

Consciousness is observing, experiencing, feeling, awareness, and reactive sensitivity. It is not a locus of control, but merely a beautiful expression of our underlying narrative-generating hardware/firmware/software. In a sense, your consciousness is "just there for the ride." 

Essentially, you need to be a scientist about yourself to begin inspecting the unconscious part of your mind. Sometimes you will be very surprised. And, it is here, at this unconscious level that we find the roots of your motivations and intentional will. i.e. You do not have access to what you think you have access to.

This is why the Virtue Theorists are deeply correct in crucial ways about our moral psychology; about how disposition, character, habituated neural networks of the fastmind are really what we boil down to. The ancients knew it; it just took a long time for us to have the science to really see why.

Quantitative Psychology is another way of saying Economics and Computer Science. And, egoism dominates in those worlds. Psychological Egoism has better evidence than your faith. It makes sense from an evolutionary perspective. It's not true because I want it to be true (or, do you think otherwise? How do you know my intentions?). It seems very difficult to get around it. It does have profound intuitive appeal as well, except when we want to think otherwise. We do want to have the hope of seeing more than egoism in humanity. We may even need it to function, to build trust, to construct meaningful relationships (even if only on quicksand). 

Ah, here we move away from alethic epistemic justifications into prudential epistemic justifications. 

The Randian Objectivists have one very strong move to push us from Redpilled Description to Prescription: ought implies can. If you can't be anything but egoist, then why try to do the impossible by being altruistic, not-egoist? The Virtue Theorists are conveniently ignorant on this topic. Consequentialists, as Kant always knew, failed in fundamental metaethics. They can never give the groundwork account. Kant is right on this account, although we must metamodernize it to survive the postmodern perils it faces. Supposing such an account might be possible requires the transcendental inference for autonomy. As any decent Kantian will tell you; belief in our autonomy just is a kind of axiomatic faith. They cannot give you a reason for Reason, except itself. It is circular (albeit, at a much lower level than the circularity of Virtue Theorists). 

Thus, back to our original question then. How do I know altruism when I see it? Alethically, I'm bound to use the best evidence available to me, which generally requires reverse engineering the behaviors of others into why they believe (at least unconsciously, but also to some extent, often consciously) deep down it benefits them (be it short-term, long-term, in some way or kind, degree, or otherwise). 

My tentpegs contradict each other. I need to feel like I can be good, good as human, good qua person, whatever the standard of The Good we need. I need to have hope that I can do the right thing in pursuit of The Good, of happiness, of Eudaimonia. 